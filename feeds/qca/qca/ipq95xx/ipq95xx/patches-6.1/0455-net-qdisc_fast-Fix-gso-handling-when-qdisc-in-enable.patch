From 81736c0f4a321c5aad255449f997a34f9f6a002d Mon Sep 17 00:00:00 2001
From: Sourav Poddar <quic_souravp@quicinc.com>
Date: Tue, 17 Jan 2023 14:27:49 +0530
Subject: [PATCH] net: qdisc_fast: Fix gso handling when qdisc in enabled on
 bottom interface with TSO enabled

Change-Id: Ia12e5becebe96b0628a111e4db825fd335aba867
Signed-off-by: Sourav Poddar <quic_souravp@quicinc.com>
Signed-off-by: Tushar Ganatra <quic_tganatra@quicinc.com>
---
 include/linux/skbuff.h  | 2 ++
 net/core/dev.c          | 1 +
 net/core/skbuff.c       | 1 +
 net/sched/sch_generic.c | 7 +++++--
 4 files changed, 9 insertions(+), 2 deletions(-)

diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index 28453cdbf87c..ad0e4c6d3f7a 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -996,6 +996,8 @@ struct sk_buff {
 	/* Flag for recycle in PPE DS */
 	__u8			recycled_for_ds:1;
 	/* 1 or 3 bit hole */
+	__u8			fast_qdisc:1;
+	/* Packets processed in dev_fast_xmit_qdisc() path */
 
 #ifdef CONFIG_NET_SCHED
 	__u16			tc_index;	/* traffic control index */
diff --git a/net/core/dev.c b/net/core/dev.c
index 99fea51830e3..59fc77389eb4 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -4325,6 +4325,7 @@ bool dev_fast_xmit_qdisc(struct sk_buff *skb, struct net_device *top_qdisc_dev,
 
 	/* Update the dev so that we can transmit to bottom device after qdisc */
 	skb->dev = bottom_dev;
+	skb->fast_qdisc = 1;
 	rc = __dev_xmit_skb_qdisc(skb, q, top_qdisc_dev, txq);
 
 	rcu_read_unlock_bh();
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index fb1490150718..edf0c5814a35 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -723,6 +723,7 @@ struct sk_buff *__netdev_alloc_skb_no_skb_reset(struct net_device *dev,
 		*/
 		skb->truesize = SKB_TRUESIZE(SKB_DATA_ALIGN(len + NET_SKB_PAD));
 		skb->fast_recycled = 0;
+		skb->fast_qdisc = 0;
 		return skb;
 	}
 
diff --git a/net/sched/sch_generic.c b/net/sched/sch_generic.c
index 573999b2ee7e..97dc6f4f7131 100644
--- a/net/sched/sch_generic.c
+++ b/net/sched/sch_generic.c
@@ -467,11 +467,14 @@ static inline bool qdisc_restart(struct Qdisc *q, int *packets)
 		struct sk_buff *next = skb->next;
 		skb->next = NULL;
 
-		if (likely(skb->fast_forwarded)) {
+		if (likely(skb->fast_qdisc)) {
 			/*
-			 * For SFE fast forwarded packets, we send packets directly
+			 * For SFE fast_qdisc marked packets, we send packets directly
 			 * to physical interface pointed to by skb->dev
+			 * We can clear fast_qdisc since we will not re-enqueue packet in this
+			 * path
 			 */
+			skb->fast_qdisc = 0;
 			if (!sch_direct_xmit_fast(skb, q, skb->dev, root_lock)) {
 				return false;
 			}
-- 
2.34.1

