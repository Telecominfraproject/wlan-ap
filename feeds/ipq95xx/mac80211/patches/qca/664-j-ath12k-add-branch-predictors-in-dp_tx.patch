From bf151f6af36369772f77c21db6d411ddd9831bd1 Mon Sep 17 00:00:00 2001
From: Pradeep Kumar Chitrapu <quic_pradeepc@quicinc.com>
Date: Wed, 10 Aug 2022 23:28:06 -0700
Subject: [PATCH 10/12] ath12k: add branch predictors in dp_tx

In datapath, add branch predictors where required in the dp_tx().

Signed-off-by: Pradeep Kumar Chitrapu <quic_pradeepc@quicinc.com>
---
 drivers/net/wireless/ath/ath12k/dp_tx.c | 55 +++++++++++++------------
 1 file changed, 28 insertions(+), 27 deletions(-)

--- a/drivers/net/wireless/ath/ath12k/dp_tx.c
+++ b/drivers/net/wireless/ath/ath12k/dp_tx.c
@@ -93,7 +93,7 @@ static struct ath12k_tx_desc_info *ath12
 	desc = list_first_entry_or_null(&dp->tx_desc_free_list[ring_id],
 					struct ath12k_tx_desc_info,
 					list);
-	if (!desc) {
+	if (unlikely(!desc)) {
 		spin_unlock_bh(&dp->tx_desc_lock[ring_id]);
 		ath12k_warn(dp->ab, "failed to allocate data Tx buffer\n");
 		return NULL;
@@ -142,11 +142,11 @@ int ath12k_dp_tx(struct ath12k *ar, stru
 	bool tcl_ring_retry;
 	bool msdu_ext_desc = false;
 
-	if (test_bit(ATH12K_FLAG_CRASH_FLUSH, &ar->ab->dev_flags))
+	if (unlikely(test_bit(ATH12K_FLAG_CRASH_FLUSH, &ar->ab->dev_flags)))
 		return -ESHUTDOWN;
 
-	if (!(info->flags & IEEE80211_TX_CTL_HW_80211_ENCAP) &&
-	    !ieee80211_is_data(hdr->frame_control))
+	if (unlikely(!(info->flags & IEEE80211_TX_CTL_HW_80211_ENCAP) &&
+	    !ieee80211_is_data(hdr->frame_control)))
 		return -ENOTSUPP;
 
 	/* Let the default ring selection be based on current processor
@@ -168,7 +168,7 @@ tcl_ring_sel:
 	tx_ring = &dp->tx_ring[ti.ring_id];
 
 	tx_desc = ath12k_dp_tx_assign_buffer(dp, ti.ring_id);
-	if (!tx_desc) {
+	if (unlikely(!tx_desc)) {
 		ab->soc_stats.tx_err.txbuf_na[ti.ring_id]++;
 		if (ring_map == (BIT(DP_TCL_NUM_RING_MAX) - 1))
 			return -ENOSPC;
@@ -200,8 +200,8 @@ tcl_ring_sel:
 	ti.bss_ast_idx = arvif->ast_idx;
 	ti.dscp_tid_tbl_idx = 0;
 
-	if (skb->ip_summed == CHECKSUM_PARTIAL &&
-	    ti.encap_type != HAL_TCL_ENCAP_TYPE_RAW) {
+	if (likely(skb->ip_summed == CHECKSUM_PARTIAL &&
+	    ti.encap_type != HAL_TCL_ENCAP_TYPE_RAW)) {
 		ti.flags0 |= FIELD_PREP(HAL_TCL_DATA_CMD_INFO2_IP4_CKSUM_EN, 1) |
 			     FIELD_PREP(HAL_TCL_DATA_CMD_INFO2_UDP4_CKSUM_EN, 1) |
 			     FIELD_PREP(HAL_TCL_DATA_CMD_INFO2_UDP6_CKSUM_EN, 1) |
@@ -235,15 +235,15 @@ tcl_ring_sel:
 	}
 
 	ti.paddr = dma_map_single(ab->dev, skb->data, skb->len, DMA_TO_DEVICE);
-	if (dma_mapping_error(ab->dev, ti.paddr)) {
+	if (unlikely(dma_mapping_error(ab->dev, ti.paddr))) {
 		atomic_inc(&ab->soc_stats.tx_err.misc_fail);
 		ath12k_warn(ab, "failed to DMA map data Tx buffer\n");
 		ret = -ENOMEM;
 		goto fail_remove_tx_buf;
 	}
 
-	if ((arvif->tx_encap_type == HAL_TCL_ENCAP_TYPE_ETHERNET &&
-	    !(info->flags & IEEE80211_TX_CTL_HW_80211_ENCAP))) {
+	if (unlikely((arvif->tx_encap_type == HAL_TCL_ENCAP_TYPE_ETHERNET &&
+	    !(info->flags & IEEE80211_TX_CTL_HW_80211_ENCAP)))) {
 		msdu_ext_desc = true;
 
 		if (skb->protocol == cpu_to_be16(ETH_P_PAE)) {
@@ -252,7 +252,7 @@ tcl_ring_sel:
 		}
 	}
 
-	if (arvif->tx_encap_type == HAL_TCL_ENCAP_TYPE_RAW) {
+	if (unlikely(arvif->tx_encap_type == HAL_TCL_ENCAP_TYPE_RAW)) {
 		if (skb_cb->flags & ATH12K_SKB_CIPHER_SET) {
 			ti.encrypt_type =
 				ath12k_dp_tx_get_encrypt_type(skb_cb->cipher);
@@ -272,7 +272,7 @@ tcl_ring_sel:
 	skb_cb->vif = arvif->vif;
 	skb_cb->ar = ar;
 
-	if (msdu_ext_desc) {
+	if (unlikely(msdu_ext_desc)) {
 		skb_ext_desc = dev_alloc_skb(sizeof(struct hal_tx_msdu_ext_desc));
 		if (!skb_ext_desc) {
 			ret = -ENOMEM;
@@ -307,7 +307,7 @@ tcl_ring_sel:
 	ath12k_hal_srng_access_begin(ab, tcl_ring);
 
 	hal_tcl_desc = (void *)ath12k_hal_srng_src_get_next_entry(ab, tcl_ring);
-	if (!hal_tcl_desc) {
+	if (unlikely(!hal_tcl_desc)) {
 		/* NOTE: It is highly unlikely we'll be running out of tcl_ring
 		 * desc because the desc is directly enqueued onto hw queue.
 		 */
@@ -321,7 +321,7 @@ tcl_ring_sel:
 		 * checking this ring earlier for each pkt tx.
 		 * Restart ring selection if some rings are not checked yet.
 		 */
-		if (ring_map != (BIT(DP_TCL_NUM_RING_MAX) - 1)) {
+		if (unlikely(ring_map != (BIT(DP_TCL_NUM_RING_MAX) - 1))) {
 			tcl_ring_retry = true;
 			ring_selector++;
 		}
@@ -365,7 +365,7 @@ static void ath12k_dp_tx_free_txbuf(stru
 	skb_cb = ATH12K_SKB_CB(msdu);
 
 	dma_unmap_single(ab->dev, skb_cb->paddr, msdu->len, DMA_TO_DEVICE);
-	if (skb_cb->paddr_ext_desc)
+	if (unlikely(skb_cb->paddr_ext_desc))
 		dma_unmap_single(ab->dev, skb_cb->paddr_ext_desc,
 				 sizeof(struct hal_tx_msdu_ext_desc), DMA_TO_DEVICE);
 
@@ -397,7 +397,7 @@ ath12k_dp_tx_htt_tx_complete_buf(struct
 		wake_up(&ar->dp.tx_empty_waitq);
 
 	dma_unmap_single(ab->dev, skb_cb->paddr, msdu->len, DMA_TO_DEVICE);
-	if (skb_cb->paddr_ext_desc)
+	if (unlikely(skb_cb->paddr_ext_desc))
 		dma_unmap_single(ab->dev, skb_cb->paddr_ext_desc,
 				 sizeof(struct hal_tx_msdu_ext_desc), DMA_TO_DEVICE);
 
@@ -652,7 +652,7 @@ static void ath12k_dp_tx_complete_msdu(s
 	u8 flags = 0;
 
 
-	if (WARN_ON_ONCE(buf_rel_source != HAL_WBM_REL_SRC_MODULE_TQM)) {
+	if (unlikely(WARN_ON_ONCE(buf_rel_source != HAL_WBM_REL_SRC_MODULE_TQM))) {
 		/* Must not happen */
 		return;
 	}
@@ -660,7 +660,7 @@ static void ath12k_dp_tx_complete_msdu(s
 	skb_cb = ATH12K_SKB_CB(msdu);
 
 	dma_unmap_single(ab->dev, skb_cb->paddr, msdu->len, DMA_TO_DEVICE);
-	if (skb_cb->paddr_ext_desc)
+	if (unlikely(skb_cb->paddr_ext_desc))
 		dma_unmap_single(ab->dev, skb_cb->paddr_ext_desc,
 				 sizeof(struct hal_tx_msdu_ext_desc), DMA_TO_DEVICE);
 
@@ -686,12 +686,12 @@ static void ath12k_dp_tx_complete_msdu(s
 
 	ath12k_dp_tx_status_parse(ab, tx_status, &ts);
 
-	if (!rcu_access_pointer(ab->pdevs_active[ar->pdev_idx])) {
+	if (unlikely(!rcu_access_pointer(ab->pdevs_active[ar->pdev_idx]))) {
 		dev_kfree_skb_any(msdu);
 		return;
 	}
 
-	if (!skb_cb->vif) {
+	if (unlikely(!skb_cb->vif)) {
 		dev_kfree_skb_any(msdu);
 		return;
 	}
@@ -716,7 +716,8 @@ static void ath12k_dp_tx_complete_msdu(s
 	    (info->flags & IEEE80211_TX_CTL_NO_ACK))
 		info->flags |= IEEE80211_TX_STAT_NOACK_TRANSMITTED;
 
-	if (ath12k_debugfs_is_extd_tx_stats_enabled(ar) || ab->hw_params.single_pdev_only) {
+	if (unlikely(ath12k_debugfs_is_extd_tx_stats_enabled(ar)) ||
+	    ab->hw_params.single_pdev_only) {
 		if (ts.flags & HAL_TX_STATUS_FLAGS_FIRST_MSDU) {
 			if (ar->last_ppdu_id == 0) {
 				ar->last_ppdu_id = ts.ppdu_id;
@@ -741,10 +742,10 @@ static void ath12k_dp_tx_complete_msdu(s
 
 	spin_lock_bh(&ab->base_lock);
 	peer = ath12k_peer_find_by_id(ab, ts.peer_id);
-	if (!peer || !peer->sta) {
-		 ath12k_dbg(ab, ATH12K_DBG_DATA,
-				 "dp_tx: failed to find the peer with peer_id %d\n",
-				 ts.peer_id);
+	if (unlikely(!peer || !peer->sta)) {
+		ath12k_dbg(ab, ATH12K_DBG_DATA,
+			   "dp_tx: failed to find the peer with peer_id %d\n",
+			   ts.peer_id);
 		 spin_unlock_bh(&ab->base_lock);
 		 dev_kfree_skb_any(msdu);
 		 return;
@@ -827,7 +828,7 @@ void ath12k_dp_tx_completion_handler(str
 	while (count--) {
 		tx_status = &tx_ring->tx_status[i++];
 
-		if (FIELD_GET(HAL_WBM_COMPL_TX_INFO0_CC_DONE, tx_status->info0)) {
+		if (likely(FIELD_GET(HAL_WBM_COMPL_TX_INFO0_CC_DONE, tx_status->info0))) {
 			/* HW done cookie conversion */
 			tx_desc = (struct ath12k_tx_desc_info *)(uintptr_t)
 					(tx_status->buf_va_lo |
@@ -839,7 +840,7 @@ void ath12k_dp_tx_completion_handler(str
 
 			tx_desc = ath12k_dp_get_tx_desc(ab, desc_id);
 		}
-		if (!tx_desc) {
+		if (unlikely(!tx_desc)) {
 			ath12k_warn(ab, "unable to retrieve tx_desc!");
 			continue;
 		}
