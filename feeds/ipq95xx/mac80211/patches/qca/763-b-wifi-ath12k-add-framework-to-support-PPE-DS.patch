From e6bab678d9958a961b8d46354dd51e58d1f1a926 Mon Sep 17 00:00:00 2001
From: Ramanathan Choodamani <quic_rchoodam@quicinc.com>
Date: Wed, 12 Apr 2023 16:09:58 -0700
Subject: [PATCH] wifi: ath12k: add framework to support PPE DS

Add framework to support PPE DS. By default ppe ds is disabled.
This can be enabled through writing 1 to module params
(/sys/module/ath12k/parameters/ppe_ds_enable) and wifi restart.
mac80211 tries to invoke driver ops for enabling direct
switching(DS). New rings are used for PPE DS TX and RX path.
Once setup, packet is directly handled by PPE engine skipping
network stack for both TX and RX.

Add compilation flag for PPE_DS_SUPPORT enabling all the
DS specific APIs to be compiled whenever that flag is enabled.

Bring DS related changes under PPE_DS_SUPPORT
compile flag check and fix compilation errors
in DS disabled case

Also additional WMI config is added to route EAPOL packets to
WBM release ring.

Signed-off-by: Balamurugan Mahalingam <quic_bmahalin@quicinc.com>
Signed-off-by: Ramanathan Choodamani <quic_rchoodam@quicinc.com>
Signed-off-by: Pradeep Kumar Chitrapu <quic_pradeepc@quicinc.com>
Signed-off-by: Aloka Dixit <quic_alokad@quicinc.com>
Signed-off-by: Sidhanta Sahu <quic_sidhanta@quicinc.com>
---
 drivers/net/wireless/ath/ath12k/Kconfig    |   8 +
 drivers/net/wireless/ath/ath12k/Makefile   |   1 +
 drivers/net/wireless/ath/ath12k/core.c     |  40 +-
 drivers/net/wireless/ath/ath12k/core.h     |  45 +-
 drivers/net/wireless/ath/ath12k/debug.h    |   5 +-
 drivers/net/wireless/ath/ath12k/debugfs.c  |  93 ++
 drivers/net/wireless/ath/ath12k/dp.c       | 256 +++++-
 drivers/net/wireless/ath/ath12k/dp.h       | 125 ++-
 drivers/net/wireless/ath/ath12k/dp_rx.c    |  78 +-
 drivers/net/wireless/ath/ath12k/dp_rx.h    |  35 +
 drivers/net/wireless/ath/ath12k/dp_tx.c    | 189 ++++
 drivers/net/wireless/ath/ath12k/dp_tx.h    |   6 +-
 drivers/net/wireless/ath/ath12k/hal.c      |  65 +-
 drivers/net/wireless/ath/ath12k/hal.h      |  29 +-
 drivers/net/wireless/ath/ath12k/hal_desc.h |  62 +-
 drivers/net/wireless/ath/ath12k/hal_rx.c   |  15 +
 drivers/net/wireless/ath/ath12k/hal_rx.h   |   4 +
 drivers/net/wireless/ath/ath12k/hal_tx.c   |  10 +
 drivers/net/wireless/ath/ath12k/hal_tx.h   |  16 +
 drivers/net/wireless/ath/ath12k/hif.h      |  49 +
 drivers/net/wireless/ath/ath12k/hw.c       |  43 +-
 drivers/net/wireless/ath/ath12k/hw.h       |  30 +-
 drivers/net/wireless/ath/ath12k/mac.c      |  15 +
 drivers/net/wireless/ath/ath12k/pci.c      |  92 +-
 drivers/net/wireless/ath/ath12k/pci.h      |  13 +
 drivers/net/wireless/ath/ath12k/ppe.c      | 989 +++++++++++++++++++++
 drivers/net/wireless/ath/ath12k/ppe.h      |  43 +
 drivers/net/wireless/ath/ath12k/wmi.c      |  82 ++
 drivers/net/wireless/ath/ath12k/wmi.h      |  68 ++
 local-symbols                              |   1 +
 net/mac80211/iface.c                       |   4 +
 31 files changed, 2406 insertions(+), 105 deletions(-)
 create mode 100644 drivers/net/wireless/ath/ath12k/ppe.c
 create mode 100644 drivers/net/wireless/ath/ath12k/ppe.h

--- a/drivers/net/wireless/ath/ath12k/Kconfig
+++ b/drivers/net/wireless/ath/ath12k/Kconfig
@@ -62,3 +62,11 @@ config ATH12K_PKTLOG
 	log uses ring buffer to dump the data. The buffer size,
 	frame filters can be altered by debugfs entries.
 
+config ATH12K_PPE_DS_SUPPORT
+	bool "QTI ath12k ppe-ds support"
+	depends on ATH12K_DEBUGFS
+	depends on RELAY
+	help
+		Enable ath12k PPE-DS support
+
+		Say Y to enable PPE DS Support. If unsure, say N.
--- a/drivers/net/wireless/ath/ath12k/Makefile
+++ b/drivers/net/wireless/ath/ath12k/Makefile
@@ -32,6 +32,7 @@ ath12k-$(CPTCFG_ATH12K_SPECTRAL) += spec
 ath12k-$(CPTCFG_WANT_DEV_COREDUMP) += coredump.o
 ath12k-$(CPTCFG_ATH12K_PKTLOG) += pktlog.o
 ath12k-$(CPTCFG_ATH12K_AHB) += ahb.o
+ath12k-$(CPTCFG_ATH12K_PPE_DS_SUPPORT) += ppe.o
 
 # for tracing framework to find trace.h
 CFLAGS_trace.o := -I$(src)
--- a/drivers/net/wireless/ath/ath12k/core.c
+++ b/drivers/net/wireless/ath/ath12k/core.c
@@ -19,6 +19,7 @@
 #include "hif.h"
 #include "wow.h"
 #include "sawf.h"
+#include "ppe.h"
 
 unsigned int ath12k_debug_mask;
 module_param_named(debug_mask, ath12k_debug_mask, uint, 0644);
@@ -46,6 +47,10 @@ static unsigned int ath12k_en_fwlog = tr
 module_param_named(en_fwlog, ath12k_en_fwlog, uint, 0644);
 MODULE_PARM_DESC(en_fwlog, "fwlog: 0-disable, 1-enable");
 
+unsigned int ath12k_ppe_ds_enabled = false;
+module_param_named(ppe_ds_enable, ath12k_ppe_ds_enabled, uint, 0644);
+MODULE_PARM_DESC(ppe_ds_enable, "ppe_ds_enable: 0-disable, 1-enable");
+
 static unsigned int ath12k_recovery_mode = ATH12K_MLO_RECOVERY_MODE0;
 
 bool ath12k_mgmt_rx_reordering = false;
@@ -1078,8 +1083,19 @@ static int ath12k_core_pdev_init(struct
 
 	ath12k_sawf_init(ab);
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	ret = ath12k_dp_ppeds_start(ab);
+	if (ret) {
+		ath12k_err(ab, "failed to start DP PPEDS \n");
+		goto err_dp_ppeds_stop;
+	}
+#endif
 	return 0;
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+err_dp_ppeds_stop:
+	ath12k_dp_ppeds_stop(ab);
+#endif
 err_spectral_deinit:
 	ath12k_spectral_deinit(ab);
 err_thermal_unregister:
@@ -1089,6 +1105,9 @@ err_thermal_unregister:
 
 static void ath12k_core_pdev_deinit(struct ath12k_base *ab)
 {
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	ath12k_dp_ppeds_stop(ab);
+#endif
 	ath12k_spectral_deinit(ab);
 	ath12k_thermal_unregister(ab);
 	ath12k_sawf_deinit(ab);
@@ -1368,7 +1387,11 @@ static int ath12k_core_hw_group_start(st
 			goto pdev_cleanup;
 		}
 		ath12k_hif_irq_enable(ab);
-
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+		ath12k_hif_ppeds_irq_enable(ab, PPEDS_IRQ_PPE2TCL);
+		ath12k_hif_ppeds_irq_enable(ab, PPEDS_IRQ_REO2PPE);
+		ath12k_hif_ppeds_irq_enable(ab, PPEDS_IRQ_PPE_WBM2SW_REL);
+#endif
 		ath12k_config_qdss(ab);
 
 		if (ath12k_en_fwlog == true) {
@@ -1478,6 +1501,21 @@ int ath12k_core_qmi_firmware_ready(struc
 		goto err_firmware_stop;
 	}
 
+	if (ath12k_ppe_ds_enabled) {
+		if (ath12k_frame_mode != ATH12K_HW_TXRX_ETHERNET) {
+			ath12k_warn(ab,
+				    "Force enabling Ethernet frame mode in PPE DS for" \
+				    " AP and STA modes.\n");
+			/* MESH and WDS VAPs will still use NATIVE_WIFI mode
+			 * @ath12k_mac_update_vif_offload()
+			 * TODO: add device capability check
+			 */
+			ath12k_frame_mode = ATH12K_HW_TXRX_ETHERNET;
+		}
+		if (ab->hif.bus == ATH12K_BUS_PCI)
+			set_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags);
+	}
+
 	ret = ath12k_dp_alloc(ab);
 	if (ret) {
 		ath12k_err(ab, "failed to init DP: %d\n", ret);
@@ -2301,6 +2339,9 @@ struct ath12k_base *ath12k_core_alloc(st
 	ab->hif.bus = bus;
 	ab->qmi.num_radios = ATH12K_QMI_INVALID_RADIO;
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	ab->ppeds_node_idx = -1;
+#endif
 	return ab;
 
 err_free_wq:
--- a/drivers/net/wireless/ath/ath12k/core.h
+++ b/drivers/net/wireless/ath/ath12k/core.h
@@ -28,6 +28,10 @@
 #include "pktlog.h"
 #include "sawf.h"
 #include "vendor.h"
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+#include <ppe_ds_wlan.h>
+#include <ppe_vp_public.h>
+#endif
 
 #define SM(_v, _f) (((_v) << _f##_LSB) & _f##_MASK)
 
@@ -235,6 +239,7 @@ enum ath12k_dev_flags {
 	ATH12K_FLAG_QMI_HOST_CAP_SENT,
 	ATH12K_FLAG_HW_GROUP_ATTACHED,
 	ATH12K_FLAG_FTM_SEGMENTED,
+	ATH12K_FLAG_PPE_DS_ENABLED,
 };
 
 enum ath12k_monitor_flags {
@@ -1115,6 +1120,30 @@ struct ath12k_soc_dp_stats {
 	struct ath12k_dp_ring_bp_stats bp_stats;
 };
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+struct ath12k_ppeds_stats {
+	u32 tcl_prod_cnt;
+	u32 tcl_cons_cnt;
+	u32 reo_prod_cnt;
+	u32 reo_cons_cnt;
+	u32 get_tx_desc_cnt;
+	u32 tx_desc_allocated;
+	u32 tx_desc_freed;
+	u32 fw2wbm_pkt_drops;
+	u32 enable_intr_cnt;
+	u32 disable_intr_cnt;
+	u32 release_tx_single_cnt;
+	u32 release_rx_desc_cnt;
+	u32 num_rx_desc_freed;
+	u32 num_rx_desc_reused;
+};
+
+struct ath12k_ppeds_napi {
+	struct napi_struct napi;
+	struct net_device ndev;
+};
+#endif
+
 struct ath12k_reg_freq {
          u32 start_freq;
          u32 end_freq;
@@ -1234,7 +1263,7 @@ struct ath12k_base {
 	bool wmi_ready;
 	u32 wlan_init_status;
 	int irq_num[ATH12K_IRQ_NUM_MAX];
-	struct ath12k_ext_irq_grp ext_irq_grp[ATH12K_EXT_IRQ_GRP_NUM_MAX];
+	struct ath12k_ext_irq_grp ext_irq_grp[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
 	struct napi_struct *napi;
 	struct ath12k_targ_cap target_caps;
 	u32 ext_service_bitmap[WMI_SERVICE_EXT_BM_SIZE];
@@ -1321,6 +1350,22 @@ struct ath12k_base {
 	u32 max_msduq_per_tid;
 	u32 default_msduq_per_tid;
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	ppe_ds_wlan_handle_t *ppeds_handle;
+	/* used for per node enumeration*/
+	int ppeds_node_idx;
+	int ppe_vp_tbl_registered[PPE_VP_ENTRIES_MAX];
+	int ppe_vp_search_idx_tbl_set[PPE_VP_ENTRIES_MAX];
+	struct ath12k_ppeds_napi ppeds_napi_ctxt;
+	struct mutex ppe_vp_tbl_lock;
+	u8 num_ppe_vp_profiles;
+	u8 num_ppe_vp_search_idx_entries;
+	u8 num_ppe_vp_entries;
+    u8 ppeds_int_mode_enabled;
+	u8 ppeds_stopped;
+	struct ath12k_ppeds_stats ppeds_stats;
+#endif
+
 	int userpd_id;
 
 	/* must be last */
--- a/drivers/net/wireless/ath/ath12k/debug.h
+++ b/drivers/net/wireless/ath/ath12k/debug.h
@@ -28,7 +28,10 @@ enum ath12k_debug_mask {
 	ATH12K_DBG_DP_RX	= 0x00004000,
 	ATH12K_DBG_OFFSET	= 0x00008000,
 	ATH12K_DBG_RX_REO	= 0x00010000,
-	ATH12K_DBG_SAWF		= 0x80000000,
+
+	/* keep last*/
+	ATH12K_DBG_SAWF		= 0x40000000,
+	ATH12K_DBG_PPE          = 0x80000000,
 	ATH12K_DBG_ANY		= 0xffffffff,
 };
 
--- a/drivers/net/wireless/ath/ath12k/debugfs.c
+++ b/drivers/net/wireless/ath/ath12k/debugfs.c
@@ -2069,6 +2069,94 @@ static const struct file_operations fops
 	.write = ath12k_write_rx_hash_ix3,
 };
 
+
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+static ssize_t ath12k_debugfs_dump_ppeds_stats(struct file *file,
+						const char __user *user_buf,
+						size_t count, loff_t *ppos)
+{
+	struct ath12k_base *ab = file->private_data;
+	struct ath12k_ppeds_stats *ppeds_stats = &ab->ppeds_stats;
+	int len = 0,  retval;
+	const int size = 4096;
+	char *buf;
+
+	buf = kzalloc(size, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	len += scnprintf(buf + len, size - len, "PPEDS STATS\n");
+	len += scnprintf(buf + len, size - len, "-----------\n");
+	len += scnprintf(buf + len, size - len, "tcl_prod_cnt %u\n",
+			 ppeds_stats->tcl_prod_cnt);
+	len += scnprintf(buf + len, size - len, "tcl_cons_cnt %u\n",
+			 ppeds_stats->tcl_cons_cnt);
+	len += scnprintf(buf + len, size - len, "reo_prod_cnt %u\n",
+			 ppeds_stats->reo_prod_cnt);
+	len += scnprintf(buf + len, size - len, "reo_cons_cnt %u\n",
+			 ppeds_stats->reo_cons_cnt);
+	len += scnprintf(buf + len, size - len, "get_tx_desc_cnt %u\n",
+			 ppeds_stats->get_tx_desc_cnt);
+	len += scnprintf(buf + len, size - len, "enable_intr_cnt %u\n",
+			 ppeds_stats->enable_intr_cnt);
+	len += scnprintf(buf + len, size - len, "disable_intr_cnt %u\n",
+			 ppeds_stats->disable_intr_cnt);
+	len += scnprintf(buf + len, size - len, "release_tx_single_cnt %u\n",
+			 ppeds_stats->release_tx_single_cnt);
+	len += scnprintf(buf + len, size - len, "release_rx_desc_cnt %u\n",
+			 ppeds_stats->release_rx_desc_cnt);
+	len += scnprintf(buf + len, size - len, "tx_desc_allocated %u\n",
+			 ppeds_stats->tx_desc_allocated);
+	len += scnprintf(buf + len, size - len, "tx_desc_freed %u\n",
+			 ppeds_stats->tx_desc_freed);
+	len += scnprintf(buf + len, size - len, "fw2wbm_pkt_drops %u\n",
+			 ppeds_stats->fw2wbm_pkt_drops);
+	len += scnprintf(buf + len, size - len, "num_rx_desc_reused %u\n",
+			 ppeds_stats->num_rx_desc_reused);
+	len += scnprintf(buf + len, size - len, "num_rx_desc_freed %u\n",
+			 ppeds_stats->num_rx_desc_freed);
+
+	if (len > size)
+		len = size;
+
+	retval = simple_read_from_buffer(user_buf, count, ppos, buf, len);
+	kfree(buf);
+
+	return retval;
+}
+
+static ssize_t
+ath12k_debugfs_write_ppeds_stats(struct file *file,
+				  const char __user *user_buf,
+				  size_t count, loff_t *ppos)
+{
+	struct ath12k_base *ab = file->private_data;
+	struct ath12k_ppeds_stats *ppeds_stats = &ab->ppeds_stats;
+	char buf[20] = {0};
+	int ret;
+
+	if (count > sizeof(buf))
+		return -EFAULT;
+
+	ret = copy_from_user(buf, user_buf, count);
+	if (ret)
+		return -EFAULT;
+
+	if (strstr(buf, "reset"))
+		memset(ppeds_stats, 0, sizeof(struct ath12k_ppeds_stats));
+
+	return count;
+}
+
+static const struct file_operations fops_ppeds_stats = {
+	.read = ath12k_debugfs_dump_ppeds_stats,
+	.write = ath12k_debugfs_write_ppeds_stats,
+	.open = simple_open,
+	.owner = THIS_MODULE,
+	.llseek = default_llseek,
+};
+#endif
+
 int ath12k_debugfs_pdev_create(struct ath12k_base *ab)
 {
 	if (test_bit(ATH12K_FLAG_REGISTERED, &ab->dev_flags))
@@ -2101,6 +2189,11 @@ int ath12k_debugfs_pdev_create(struct at
 	debugfs_create_file("fw_reset_stats", 0400, ab->debugfs_soc, ab,
 			    &fops_fw_reset_stats);
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	if (test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		debugfs_create_file("ppeds_stats", 0600, ab->debugfs_soc, ab,
+				    &fops_ppeds_stats);
+#endif
 	return 0;
 }
 
--- a/drivers/net/wireless/ath/ath12k/dp.c
+++ b/drivers/net/wireless/ath/ath12k/dp.c
@@ -13,6 +13,9 @@
 #include "dp_rx.h"
 #include "peer.h"
 #include "dp_mon.h"
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+#include "ppe.h"
+#endif
 
 #define ATH12K_DP_LMAC_PEER_ID_LEGACY	2
 #define ATH12K_DP_LMAC_PEER_ID_MLO	3
@@ -84,6 +87,10 @@ int ath12k_dp_peer_default_route_setup(s
 	ath12k_dbg(ab, ATH12K_DBG_DP_RX, "peer %pM set def route id %d sta_link %d\n",
 		   arsta->addr, lmac_peer_routing_id,
 		   hweight16(sta->valid_links));
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	/* keep last - override any PPE DS specific routing config */
+	ath12k_dp_peer_ppeds_route_setup(ar, arvif, arsta);
+#endif
 
 	return 0;
 }
@@ -129,9 +136,10 @@ int ath12k_dp_peer_setup(struct ath12k *
 		goto peer_tid_clean;
 	}
 
-	spin_unlock_bh(&ab->base_lock);
 	/* TODO: Setup other peer specific resource used in data path */
 
+	spin_unlock_bh(&ab->base_lock);
+
 	return 0;
 
 peer_tid_clean:
@@ -164,7 +172,7 @@ static int ath12k_dp_srng_find_ring_in_m
 	int ext_group_num;
 	u8 mask = 1 << ring_num;
 
-	for (ext_group_num = 0; ext_group_num < ATH12K_EXT_IRQ_GRP_NUM_MAX;
+	for (ext_group_num = 0; ext_group_num < ATH12K_EXT_IRQ_DP_NUM_VECTORS;
 	     ext_group_num++) {
 		if (mask & grp_mask[ext_group_num])
 			return ext_group_num;
@@ -183,6 +191,11 @@ static int ath12k_dp_srng_calculate_msi_
 		if (ring_num == HAL_WBM2SW_REL_ERR_RING_NUM) {
 			grp_mask = &ab->hw_params->ring_mask->rx_wbm_rel[0];
 			ring_num = 0;
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+		} else if (ring_num == HAL_WBM2SW_PPEDS_TX_CMPLN_RING_NUM) {
+			grp_mask = &ab->hw_params->ring_mask->wbm2sw6_ppeds_tx_cmpln[0];
+			ring_num = 0;
+#endif
 		} else {
 			grp_mask = &ab->hw_params->ring_mask->tx[0];
 		}
@@ -206,6 +219,12 @@ static int ath12k_dp_srng_calculate_msi_
 	case HAL_RXDMA_BUF:
 		grp_mask = &ab->hw_params->ring_mask->host2rxdma[0];
 		break;
+	case HAL_PPE2TCL:
+		grp_mask = &ab->hw_params->ring_mask->ppe2tcl[0];
+		break;
+	case HAL_REO2PPE:
+		grp_mask = &ab->hw_params->ring_mask->reo2ppe[0];
+		break;
 	case HAL_RXDMA_MONITOR_BUF:
 	case HAL_TCL_DATA:
 	case HAL_TCL_CMD:
@@ -231,6 +250,7 @@ static void ath12k_dp_srng_msi_setup(str
 	int msi_group_number, msi_data_count;
 	u32 msi_data_start, msi_irq_start, addr_lo, addr_hi;
 	int ret;
+	int vector;
 
 	ret = ath12k_hif_get_user_msi_vector(ab, "DP",
 					     &msi_data_count, &msi_data_start,
@@ -262,6 +282,12 @@ static void ath12k_dp_srng_msi_setup(str
 	ring_params->msi_data = (msi_group_number % msi_data_count)
 		+ msi_data_start;
 	ring_params->flags |= HAL_SRNG_FLAGS_MSI_INTR;
+
+	vector = msi_irq_start  + (msi_group_number % msi_data_count);
+
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	ath12k_hif_ppeds_register_interrupts(ab, type, vector, ring_num);
+#endif
 }
 
 int ath12k_dp_srng_setup(struct ath12k_base *ab, struct dp_srng *ring,
@@ -316,6 +342,7 @@ int ath12k_dp_srng_setup(struct ath12k_b
 
 	switch (type) {
 	case HAL_REO_DST:
+	case HAL_REO2PPE:
 		params.intr_batch_cntr_thres_entries =
 					HAL_SRNG_INT_BATCH_THRESHOLD_RX;
 		params.intr_timer_thres_us = HAL_SRNG_INT_TIMER_THRESHOLD_RX;
@@ -345,6 +372,12 @@ int ath12k_dp_srng_setup(struct ath12k_b
 			params.intr_timer_thres_us =
 					HAL_SRNG_INT_TIMER_THRESHOLD_TX;
 			break;
+		} else if (ring_num == HAL_WBM2SW_PPEDS_TX_CMPLN_RING_NUM) {
+			params.intr_batch_cntr_thres_entries =
+					HAL_SRNG_INT_BATCH_THRESHOLD_PPE_WBM2SW_REL;
+			params.intr_timer_thres_us = HAL_SRNG_INT_TIMER_THRESHOLD_TX;
+
+				break;
 		}
 		/* follow through when ring_num != HAL_WBM2SW_REL_ERR_RING_NUM */
 		fallthrough;
@@ -365,6 +398,11 @@ int ath12k_dp_srng_setup(struct ath12k_b
 		break;
 	case HAL_RXDMA_DIR_BUF:
 		break;
+	case HAL_PPE2TCL:
+		params.intr_batch_cntr_thres_entries =
+					HAL_SRNG_INT_BATCH_THRESHOLD_PPE2TCL;
+		params.intr_timer_thres_us = HAL_SRNG_INT_TIMER_THRESHOLD_PPE2TCL;
+		break;
 	default:
 		ath12k_warn(ab, "Not a valid ring type in dp :%d\n", type);
 		return -EINVAL;
@@ -548,6 +586,10 @@ static void ath12k_dp_srng_common_cleanu
 	ath12k_dp_srng_cleanup(ab, &dp->reo_except_ring);
 	ath12k_dp_srng_cleanup(ab, &dp->reo_cmd_ring);
 	ath12k_dp_srng_cleanup(ab, &dp->reo_status_ring);
+
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	ath12k_dp_srng_ppeds_cleanup(ab);
+#endif
 }
 
 static int ath12k_dp_srng_common_setup(struct ath12k_base *ab)
@@ -665,6 +707,14 @@ static int ath12k_dp_srng_common_setup(s
 
 	ath12k_hal_reo_hw_setup(ab, ring_hash_map);
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	ret = ath12k_dp_srng_ppeds_setup(ab);
+	if (ret) {
+		ath12k_warn(ab, "failed to set up ppe-ds srngs :%d\n", ret);
+		goto err;
+	}
+#endif
+
 	return 0;
 
 err:
@@ -1124,12 +1174,41 @@ void ath12k_dp_pdev_pre_alloc(struct ath
 	}
 }
 
+static int ath12k_dp_ppe_rxole_rxdma_cfg(struct ath12k_base *ab)
+{
+	struct ath12k_dp_htt_rxdma_ppe_cfg_param param = {0};
+	int ret;
+
+	param.override = 1;
+	param.reo_dst_ind = HAL_REO2PPE_DST_IND;
+	param.multi_buffer_msdu_override_en = 0;
+
+	/* Override use_ppe to 0 in RxOLE for the following cases */
+	param.intra_bss_override = 1;
+	param.decap_raw_override = 1;
+	param.decap_nwifi_override = 1;
+	param.ip_frag_override = 1;
+
+	ret = ath12k_dp_rx_htt_rxdma_rxole_ppe_cfg_set(ab, &param);
+	if (ret)
+		ath12k_err(ab, "RxOLE and RxDMA PPE config failed %d\n", ret);
+
+	return ret;
+}
+
 int ath12k_dp_pdev_alloc(struct ath12k_base *ab)
 {
 	struct ath12k *ar;
 	int ret;
 	int i;
 
+	ret = ath12k_dp_ppe_rxole_rxdma_cfg(ab);
+	if (ret) {
+		ath12k_err(ab, "Failed to send htt RxOLE and RxDMA messages to target :%d\n",
+			   ret);
+		goto out;
+	}
+
 	ret = ath12k_dp_rx_htt_setup(ab);
 	if (ret)
 		goto out;
@@ -1269,6 +1348,18 @@ static void ath12k_dp_cc_cleanup(struct
 		dev_kfree_skb_any(skb);
 	}
 
+	list_for_each_entry_safe(desc_info, tmp, &dp->rx_ppeds_reuse_list, list) {
+		list_del(&desc_info->list);
+		skb = desc_info->skb;
+
+		if (!skb)
+			continue;
+
+		dma_unmap_single(ab->dev, ATH12K_SKB_RXCB(skb)->paddr,
+				 skb->len + skb_tailroom(skb), DMA_FROM_DEVICE);
+		dev_kfree_skb_any(skb);
+	}
+
 	for (i = 0; i < ATH12K_NUM_RX_SPT_PAGES; i++) {
 		if (!dp->spt_info->rxbaddr[i])
 			continue;
@@ -1319,6 +1410,11 @@ static void ath12k_dp_cc_cleanup(struct
 		spin_unlock_bh(&dp->tx_desc_lock[pool_id]);
 	}
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	if (test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		ath12k_ppeds_detach(ab);
+#endif
+
 	/* unmap SPT pages */
 	for (i = 0; i < dp->num_spt_pages; i++) {
 		if (!dp->spt_info[i].vaddr)
@@ -1470,6 +1566,17 @@ struct ath12k_tx_desc_info *ath12k_dp_ge
 	return *(struct ath12k_tx_desc_info **)desc_addr_ptr;
 }
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+struct ath12k_ppeds_tx_desc_info *ath12k_dp_get_ppeds_tx_desc(struct ath12k_base *ab,
+						  u32 desc_id)
+{
+	u8 *desc_addr_ptr;
+
+	desc_addr_ptr = ath12k_dp_cc_find_desc(ab, desc_id, false);
+	return *(struct ath12k_ppeds_tx_desc_info **)desc_addr_ptr;
+}
+#endif
+
 static void ath12k_dp_tx_cmem_init(struct ath12k_base *ab, struct ath12k_dp *dp)
 {
 	u32 cmem_base;
@@ -1477,7 +1584,8 @@ static void ath12k_dp_tx_cmem_init(struc
 
 	cmem_base = ab->qmi.dev_mem[ATH12K_QMI_DEVMEM_CMEM_INDEX].start;
 
-	for (i = 0; i < ATH12K_NUM_TX_SPT_PAGES; i++) {
+	for (i = ATH12K_TX_SPT_PAGE_OFFSET;
+	     i < (ATH12K_TX_SPT_PAGE_OFFSET + ATH12K_NUM_TX_SPT_PAGES); i++) {
 		/* Write to PPT in CMEM */
 		if (ab->hif.ops->cmem_write32)
 			ath12k_hif_cmem_write32(ab, cmem_base + ATH12K_PPT_ADDR_OFFSET(i),
@@ -1508,6 +1616,139 @@ static void ath12k_dp_rx_cmem_init(struc
 	}
 }
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+void ath12k_dp_ppeds_tx_cmem_init(struct ath12k_base *ab, struct ath12k_dp *dp)
+{
+	u32 cmem_base;
+	int i;
+
+	cmem_base = ab->qmi.dev_mem[ATH12K_QMI_DEVMEM_CMEM_INDEX].start;
+
+	for (i = ATH12K_PPEDS_TX_SPT_PAGE_OFFSET;
+	     i < (ATH12K_PPEDS_TX_SPT_PAGE_OFFSET + ATH12K_NUM_PPEDS_TX_SPT_PAGES); i++) {
+		/* Write to PPT in CMEM */
+		if (ab->hif.ops->cmem_write32)
+			ath12k_hif_cmem_write32(ab, cmem_base + ATH12K_PPT_ADDR_OFFSET(i),
+						dp->spt_info[i].paddr >> ATH12K_SPT_4K_ALIGN_OFFSET);
+		else
+			ath12k_hif_write32(ab, cmem_base + ATH12K_PPT_ADDR_OFFSET(i),
+					   dp->spt_info[i].paddr >> ATH12K_SPT_4K_ALIGN_OFFSET);
+	}
+}
+
+int ath12k_dp_cc_ppeds_desc_cleanup(struct ath12k_base *ab)
+{
+	struct ath12k_ppeds_tx_desc_info *ppeds_tx_desc_info, *tmp2;
+	struct ath12k_dp *dp = &ab->dp;
+	struct sk_buff *skb;
+	int i;
+	u32  pool_id, ppeds_tx_spt_page;
+
+	if (!dp->spt_info) {
+		ath12k_err(ab,"ath12k_dp_cc_ppeds_desc_cleanup failed");
+		return -EINVAL;
+	}
+
+	/* PPEDS TX Descriptor cleanup */
+	for (i = 0; i < ATH12K_HW_MAX_QUEUES_PPEDS; i++) {
+		spin_lock_bh(&dp->ppeds_tx_desc_lock[i]);
+
+		/* clean up used desc list */
+		list_for_each_entry_safe(ppeds_tx_desc_info, tmp2,
+					 &dp->ppeds_tx_desc_used_list[i],
+					 list) {
+			list_del(&ppeds_tx_desc_info->list);
+			skb = ppeds_tx_desc_info->skb;
+			if (!skb)
+				continue;
+
+			dma_unmap_single(ab->dev, ATH12K_SKB_CB(skb)->paddr,
+					 skb->len, DMA_TO_DEVICE);
+			dev_kfree_skb_any(skb);
+		}
+
+		/* clean up descriptors and skbs from reuse list */
+		list_for_each_entry_safe(ppeds_tx_desc_info, tmp2,
+					 &dp->ppeds_tx_desc_reuse_list[i],
+					 list) {
+			list_del(&ppeds_tx_desc_info->list);
+			skb = ppeds_tx_desc_info->skb;
+			if (!skb)
+				continue;
+
+			dma_unmap_single(ab->dev, ppeds_tx_desc_info->paddr,
+					 skb->len, DMA_TO_DEVICE);
+			dev_kfree_skb_any(skb);
+		}
+
+		spin_unlock_bh(&dp->ppeds_tx_desc_lock[i]);
+	}
+
+	for (pool_id = 0; pool_id < ATH12K_HW_MAX_QUEUES_PPEDS; pool_id++) {
+		spin_lock_bh(&dp->ppeds_tx_desc_lock[pool_id]);
+
+		for (i = 0; i < ATH12K_PPEDS_TX_SPT_PAGES_PER_POOL; i++) {
+			ppeds_tx_spt_page = i + pool_id * ATH12K_PPEDS_TX_SPT_PAGES_PER_POOL;
+			if (!dp->spt_info->ppedstxbaddr[ppeds_tx_spt_page])
+				continue;
+
+			kfree(dp->spt_info->ppedstxbaddr[ppeds_tx_spt_page]);
+		}
+
+		spin_unlock_bh(&dp->ppeds_tx_desc_lock[pool_id]);
+	}
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "ath12k_dp_cc_ppeds_desc_cleanup success\n");
+
+	return 0;
+}
+
+int ath12k_dp_cc_ppeds_desc_init(struct ath12k_base *ab)
+{
+	struct ath12k_dp *dp = &ab->dp;
+	struct ath12k_ppeds_tx_desc_info *ppeds_tx_descs;
+	struct ath12k_spt_info *ppeds_tx_spt_pages;
+	u32 i, j, pool_id, ppeds_tx_spt_page;
+	u32 ppt_idx;
+
+	/* pointer to start of TX pages */
+	ppeds_tx_spt_pages = &dp->spt_info[ATH12K_PPEDS_TX_SPT_PAGE_OFFSET];
+
+	for (pool_id = 0; pool_id < ATH12K_HW_MAX_QUEUES_PPEDS; pool_id++) {
+		spin_lock_bh(&dp->ppeds_tx_desc_lock[pool_id]);
+		for (i = 0; i < ATH12K_PPEDS_TX_SPT_PAGES_PER_POOL; i++) {
+			ppeds_tx_descs = kcalloc(ATH12K_MAX_SPT_ENTRIES, sizeof(*ppeds_tx_descs),
+					   GFP_ATOMIC);
+
+			if (!ppeds_tx_descs) {
+				spin_unlock_bh(&dp->ppeds_tx_desc_lock[pool_id]);
+				ath12k_dp_cc_ppeds_desc_cleanup(ab);
+				return -ENOMEM;
+			}
+
+			ppeds_tx_spt_page = i + pool_id * ATH12K_PPEDS_TX_SPT_PAGES_PER_POOL;
+			dp->spt_info->ppedstxbaddr[ppeds_tx_spt_page] = &ppeds_tx_descs[0];
+
+			for (j = 0; j < ATH12K_MAX_SPT_ENTRIES; j++) {
+				ppt_idx = ATH12K_PPEDS_TX_SPT_PAGE_OFFSET + ppeds_tx_spt_page;
+				ppeds_tx_descs[j].desc_id = ath12k_dp_cc_cookie_gen(ppt_idx, j);
+				ppeds_tx_descs[j].pool_id = pool_id;
+				list_add_tail(&ppeds_tx_descs[j].list,
+					      &dp->ppeds_tx_desc_free_list[pool_id]);
+
+				/* Update descriptor VA in SPT */
+				*(struct ath12k_ppeds_tx_desc_info **)
+					((u8 *)ppeds_tx_spt_pages[ppeds_tx_spt_page].vaddr +
+					 (j * sizeof(u64))) = &ppeds_tx_descs[j];
+			}
+		}
+		spin_unlock_bh(&dp->ppeds_tx_desc_lock[pool_id]);
+	}
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "ath12k_dp_cc_ppeds_desc_init success\n");
+
+	return 0;
+}
+#endif
+
 static int ath12k_dp_cc_desc_init(struct ath12k_base *ab)
 {
 	struct ath12k_dp *dp = &ab->dp;
@@ -1572,6 +1813,7 @@ static int ath12k_dp_cc_desc_init(struct
 		for (j = 0; j < ATH12K_MAX_SPT_ENTRIES; j++) {
 			rx_descs[j].cookie = ath12k_dp_cc_cookie_gen(ppt_idx, j);
 			rx_descs[j].magic = ATH12K_DP_RX_DESC_MAGIC;
+			rx_descs[j].ab = ab;
 			list_add_tail(&rx_descs[j].list, &dp->rx_desc_free_list);
 
 			/* Update descriptor VA in SPT */
@@ -1610,6 +1852,7 @@ static int ath12k_dp_cc_init(struct ath1
 
 	INIT_LIST_HEAD(&dp->rx_desc_free_list);
 	INIT_LIST_HEAD(&dp->rx_desc_used_list);
+	INIT_LIST_HEAD(&dp->rx_ppeds_reuse_list);
 	spin_lock_init(&dp->rx_desc_lock);
 
 	for (i = 0; i < ATH12K_HW_MAX_QUEUES; i++) {
@@ -1661,6 +1904,19 @@ static int ath12k_dp_cc_init(struct ath1
 		goto free;
 	}
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	if (test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags)) {
+		for (i = 0; i < ATH12K_HW_MAX_QUEUES_PPEDS; i++) {
+			INIT_LIST_HEAD(&dp->ppeds_tx_desc_free_list[i]);
+			INIT_LIST_HEAD(&dp->ppeds_tx_desc_reuse_list[i]);
+			INIT_LIST_HEAD(&dp->ppeds_tx_desc_used_list[i]);
+			spin_lock_init(&dp->ppeds_tx_desc_lock[i]);
+			dp->ppeds_tx_desc_reuse_list_len[i] = 0;
+		}
+		ath12k_ppeds_attach(ab);
+	}
+#endif
+
 	return 0;
 free:
 	ath12k_dp_cc_cleanup(ab);
--- a/drivers/net/wireless/ath/ath12k/dp.h
+++ b/drivers/net/wireless/ath/ath12k/dp.h
@@ -41,6 +41,15 @@ struct dp_rxdma_ring {
 	int bufs_max;
 };
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+struct dp_ppeds_tx_comp_ring {
+	struct dp_srng ppe_wbm2sw_ring;
+	struct hal_wbm_completion_ring_tx *tx_status;
+	int tx_status_head;
+	int tx_status_tail;
+};
+#endif
+
 struct dp_tx_ring {
 	u8 tcl_data_ring_id;
 	struct dp_srng tcl_data_ring;
@@ -180,6 +189,11 @@ struct ath12k_pdev_dp {
 #define DP_RX_BUFFER_SIZE_LITE	1024
 #define DP_RX_BUFFER_ALIGN_SIZE	128
 
+#define DP_REO2PPE_RING_SIZE 8192
+#define DP_PPE2TCL_RING_SIZE 2048
+#define DP_PPE_WBM2SW_RING_SIZE 8192
+#define HAL_REO2PPE_DST_IND 6
+
 #define DP_DIR_BUF_COOKIE_BUF_ID	GENMASK(17, 0)
 #define DP_DIR_BUF_COOKIE_PDEV_ID	GENMASK(19, 18)
 
@@ -197,6 +211,12 @@ struct ath12k_pdev_dp {
 
 #define ATH12K_NUM_POOL_TX_DESC	32768
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+#define ATH12K_NUM_POOL_PPEDS_TX_DESC 0x10000
+#else
+#define ATH12K_NUM_POOL_PPEDS_TX_DESC 0
+#endif
+
 /* TODO revisit this count during testing */
 #define ATH12K_RX_DESC_COUNT	(12288)
 
@@ -215,9 +235,19 @@ struct ath12k_pdev_dp {
 #define ATH12K_TX_SPT_PAGES_PER_POOL (ATH12K_NUM_POOL_TX_DESC / \
 					  ATH12K_MAX_SPT_ENTRIES)
 #define ATH12K_NUM_TX_SPT_PAGES	(ATH12K_TX_SPT_PAGES_PER_POOL * ATH12K_HW_MAX_QUEUES)
-#define ATH12K_TX_SPT_PAGE_OFFSET 0
-#define ATH12K_RX_SPT_PAGE_OFFSET ATH12K_NUM_TX_SPT_PAGES
-#define ATH12K_NUM_SPT_PAGES	(ATH12K_NUM_TX_SPT_PAGES + ATH12K_NUM_RX_SPT_PAGES)
+
+#define ATH12K_PPEDS_TX_SPT_PAGE_OFFSET 0
+#define ATH12K_TX_SPT_PAGE_OFFSET ATH12K_NUM_PPEDS_TX_SPT_PAGES
+#define ATH12K_RX_SPT_PAGE_OFFSET ATH12K_NUM_PPEDS_TX_SPT_PAGES + ATH12K_NUM_TX_SPT_PAGES
+
+
+#define ATH12K_PPEDS_TX_SPT_PAGES_PER_POOL (ATH12K_NUM_POOL_PPEDS_TX_DESC / \
+					    ATH12K_MAX_SPT_ENTRIES)
+#define ATH12K_NUM_PPEDS_TX_SPT_PAGES (ATH12K_PPEDS_TX_SPT_PAGES_PER_POOL *\
+				       ATH12K_HW_MAX_QUEUES_PPEDS)
+
+#define ATH12K_NUM_SPT_PAGES	(ATH12K_NUM_TX_SPT_PAGES + ATH12K_NUM_RX_SPT_PAGES + \
+				 ATH12K_NUM_PPEDS_TX_SPT_PAGES)
 
 /* The SPT pages are divided for RX and TX, first block for RX
  * and remaining for TX
@@ -282,6 +312,7 @@ struct ath12k_rx_desc_info {
 	struct sk_buff *skb;
 	u32 cookie;
 	u32 magic;
+	struct ath12k_base *ab;
 };
 
 struct ath12k_tx_desc_info {
@@ -294,11 +325,24 @@ struct ath12k_tx_desc_info {
 	u8 recycler_fast_xmit;
 };
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+struct ath12k_ppeds_tx_desc_info {
+	struct list_head list;
+	struct sk_buff *skb;
+	dma_addr_t paddr;
+	u32 desc_id; /* Cookie */
+	u8 mac_id;
+	u8 pool_id;
+	u8 flags;
+};
+#endif
+
 struct ath12k_spt_info {
 	dma_addr_t paddr;
 	u32 *vaddr;
 	struct ath12k_rx_desc_info *rxbaddr[ATH12K_NUM_RX_SPT_PAGES];
 	struct ath12k_tx_desc_info *txbaddr[ATH12K_NUM_TX_SPT_PAGES];
+	struct ath12k_ppeds_tx_desc_info *ppedstxbaddr[ATH12K_NUM_PPEDS_TX_SPT_PAGES];
 };
 
 struct ath12k_reo_queue_ref {
@@ -321,6 +365,21 @@ struct host_link_stats {
 	u32 tx_desc_type[HAL_TCL_DESC_TYPE_MAX];
 };
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+#define PPE_VP_ENTRIES_MAX 32
+#define MAX_PPEDS_IRQ_NAME_LEN 20
+#define MAX_PPEDS_IRQS 3
+struct dp_ppe_vp_profile {
+	bool is_configured;
+	u8 vp_num;
+	u8 ppe_vp_num_idx;
+	u8 search_idx_reg_num;
+	u8 drop_prec_enable;
+	u8 to_fw;
+	u8 use_ppe_int_pri;
+};
+#endif
+
 struct ath12k_dp {
 	struct ath12k_base *ab;
 	u8 num_bank_profiles;
@@ -341,6 +400,11 @@ struct ath12k_dp {
 	struct dp_srng rx_rel_ring;
 	struct dp_srng reo_except_ring;
 	struct dp_srng reo_cmd_ring;
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	struct dp_srng reo2ppe_ring;
+	struct dp_srng ppe2tcl_ring;
+	struct dp_ppeds_tx_comp_ring ppeds_comp_ring;
+#endif
 	struct dp_srng reo_status_ring;
 	struct dp_srng reo_dst_ring[DP_REO_DST_RING_MAX];
 	struct dp_tx_ring tx_ring[DP_TCL_NUM_RING_MAX];
@@ -368,6 +432,7 @@ struct ath12k_dp {
 	u32 rx_spt_base;
 	struct list_head rx_desc_free_list;
 	struct list_head rx_desc_used_list;
+	struct list_head rx_ppeds_reuse_list;
 	/* protects the free and used desc list */
 	spinlock_t rx_desc_lock;
 
@@ -376,6 +441,19 @@ struct ath12k_dp {
 	/* protects the free and used desc lists */
 	spinlock_t tx_desc_lock[ATH12K_HW_MAX_QUEUES];
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	struct list_head ppeds_tx_desc_free_list[ATH12K_HW_MAX_QUEUES_PPEDS];
+	struct list_head ppeds_tx_desc_reuse_list[ATH12K_HW_MAX_QUEUES_PPEDS];
+	struct list_head ppeds_tx_desc_used_list[ATH12K_HW_MAX_QUEUES_PPEDS];
+	int ppeds_tx_desc_reuse_list_len[ATH12K_HW_MAX_QUEUES_PPEDS];
+	/* protects the free and used desc lists */
+	spinlock_t ppeds_tx_desc_lock[ATH12K_HW_MAX_QUEUES_PPEDS];
+
+	struct dp_ppe_vp_profile ppe_vp_profile[PPE_VP_ENTRIES_MAX];
+	char ppeds_irq_name[MAX_PPEDS_IRQS][MAX_PPEDS_IRQ_NAME_LEN];
+	int ppeds_irq[MAX_PPEDS_IRQS];
+#endif
+
 	struct dp_rxdma_ring rx_refill_buf_ring;
 	struct dp_srng rx_mac_buf_ring[MAX_RXDMA_PER_PDEV];
 	struct dp_srng rxdma_err_dst_ring[MAX_RXDMA_PER_PDEV];
@@ -449,6 +527,7 @@ enum htt_h2t_msg_type {
 	HTT_H2T_MSG_TYPE_RX_RING_SELECTION_CFG	= 0xc,
 	HTT_H2T_MSG_TYPE_EXT_STATS_CFG		= 0x10,
 	HTT_H2T_MSG_TYPE_PPDU_STATS_CFG		= 0x11,
+	HTT_H2T_MSG_TYPE_RXDMA_RXOLE_PPE_CFG	= 0x19,
 	HTT_H2T_MSG_TYPE_VDEV_TXRX_STATS_CFG	= 0x1a,
 	HTT_H2T_MSG_TYPE_TX_MONITOR_CFG		= 0x1b,
 	HTT_H2T_MSG_TYPE_SAWF_DEF_Q_MAP_REQ	= 0x1c,
@@ -2099,6 +2178,19 @@ struct htt_h2t_msg_type_vdev_txrx_stats_
 	u32 vdev_id_hi_bitmask;
 };
 
+#define HTT_H2T_RXOLE_PPE_CFG_MSG_TYPE			GENMASK(7, 0)
+#define HTT_H2T_RXOLE_PPE_CFG_OVERRIDE			BIT(8)
+#define HTT_H2T_RXOLE_PPE_CFG_REO_DST_IND		GENMASK(13, 9)
+#define HTT_H2T_RXOLE_PPE_CFG_MULTI_BUF_MSDU_OVRD_EN	BIT(14)
+#define HTT_H2T_RXOLE_PPE_CFG_INTRA_BUS_OVRD		BIT(15)
+#define HTT_H2T_RXOLE_PPE_CFG_DECAP_RAW_OVRD		BIT(16)
+#define HTT_H2T_RXOLE_PPE_CFG_NWIFI_OVRD		BIT(17)
+#define HTT_H2T_RXOLE_PPE_CFG_IP_FRAG_OVRD		BIT(18)
+
+struct htt_h2t_msg_type_rxdma_rxole_ppe_cfg {
+	u32 info0;
+};
+
 /* @brief target -> host extended statistics upload
  *
  * @details
@@ -2239,6 +2331,26 @@ struct ath11k_htt_mlo_peer_unmap_msg {
 	u32 info0;
 } __packed;
 
+/**
+ * struct ath12k_dp_htt_rxdma_ppe_cfg_param - Rx DMA and RxOLE PPE config
+ * @override: RxDMA override to override the reo_destinatoin_indication
+ * @reo_dst_ind: REO destination indication value
+ * @multi_buffer_msdu_override_en: Override the indication for SG
+ * @intra_bss_override: Rx OLE IntraBSS override
+ * @decap_raw_override: Rx Decap Raw override
+ * @decap_nwifi_override: Rx Native override
+ * @ip_frag_override: IP fragments override
+ */
+struct ath12k_dp_htt_rxdma_ppe_cfg_param {
+	u8 override;
+	u8 reo_dst_ind;
+	u8 multi_buffer_msdu_override_en;
+	u8 intra_bss_override;
+	u8 decap_raw_override;
+	u8 decap_nwifi_override;
+	u8 ip_frag_override;
+};
+
 int ath12k_dp_service_srng(struct ath12k_base *ab,
 			   struct ath12k_ext_irq_grp *irq_grp,
 			   int budget);
@@ -2275,4 +2387,11 @@ struct ath12k_rx_desc_info *ath12k_dp_ge
 struct ath12k_tx_desc_info *ath12k_dp_get_tx_desc(struct ath12k_base *ab,
 						  u32 desc_id);
 void ath12k_dp_tx_update_bank_profile(struct ath12k_link_vif *arvif);
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+struct ath12k_ppeds_tx_desc_info *ath12k_dp_get_ppeds_tx_desc(struct ath12k_base *ab,
+						 	      u32 desc_id);
+int ath12k_dp_cc_ppeds_desc_init(struct ath12k_base *ab);
+int ath12k_dp_cc_ppeds_desc_cleanup(struct ath12k_base *ab);
+void ath12k_dp_ppeds_tx_cmem_init(struct ath12k_base *ab, struct ath12k_dp *dp);
+#endif
 #endif
--- a/drivers/net/wireless/ath/ath12k/dp_rx.c
+++ b/drivers/net/wireless/ath/ath12k/dp_rx.c
@@ -2795,7 +2795,7 @@ static void ath12k_dp_rx_h_mpdu(struct a
 	u32 err_bitmap;
 	u8 tid;
 #ifdef CPTCFG_MAC80211_PPE_SUPPORT
-	u32 vp;
+	int vp;
 #endif
 	struct wireless_dev *wdev = NULL;
 
@@ -2830,7 +2830,7 @@ static void ath12k_dp_rx_h_mpdu(struct a
 				ath12k_dp_rx_h_csum_offload(ar, msdu);
 				msdu->dev = wdev->netdev;
 #ifdef CPTCFG_MAC80211_PPE_SUPPORT
-				if (vp) {
+				if (vp > 0) {
 					if (likely(ppe_vp_tx_to_ppe(vp, msdu)))
 						return;
 				}
@@ -3360,6 +3360,31 @@ static void ath12k_dp_rx_process_receive
 	rcu_read_unlock();
 }
 
+/* Sends WMI config to filter packets to route packets to WBM release ring */
+int ath12k_dp_rx_pkt_type_filter(struct ath12k *ar,
+				 enum ath12k_routing_pkt_type pkt_type,
+				 u32 meta_data)
+{
+	struct ath12k_wmi_pkt_route_param param;
+	int ret;
+
+	/* Routing Eapol packets to CCE is only allowed now */
+	if (pkt_type != ATH12K_PKT_TYPE_EAP)
+		return -EINVAL;
+
+	param.opcode = ATH12K_WMI_PKTROUTE_ADD;
+	param.meta_data = meta_data;
+	param.dst_ring = ATH12K_ROUTE_WBM_RELEASE;
+	param.dst_ring_handler = ATH12K_WMI_PKTROUTE_USE_CCE;
+	param.route_type_bmap = 1 << pkt_type;
+
+	ret = ath12k_wmi_send_pdev_pkt_route(ar, &param);
+	if (ret)
+		ath12k_warn(ar->ab, "failed to configure pkt route %d", ret);
+
+	return ret;
+}
+
 int ath12k_dp_rx_process(struct ath12k_base *ab, int ring_id,
 			 struct napi_struct *napi, int budget)
 {
@@ -4954,6 +4979,55 @@ int ath12k_dp_rxdma_ring_sel_config_wcn7
 	return ret;
 }
 
+int
+ath12k_dp_rx_htt_rxdma_rxole_ppe_cfg_set(struct ath12k_base *ab,
+					 struct ath12k_dp_htt_rxdma_ppe_cfg_param *param)
+{
+	struct htt_h2t_msg_type_rxdma_rxole_ppe_cfg *cmd;
+	struct ath12k_dp *dp = &ab->dp;
+	struct sk_buff *skb;
+	int len = sizeof(*cmd), ret, val;
+
+	skb = ath12k_htc_alloc_skb(ab, len);
+	if (!skb)
+		return -ENOMEM;
+
+	skb_put(skb, len);
+
+	cmd = (struct htt_h2t_msg_type_rxdma_rxole_ppe_cfg *)skb->data;
+	memset(cmd, 0, sizeof(*cmd));
+
+	cmd->info0 =
+		u32_encode_bits(HTT_H2T_MSG_TYPE_RXDMA_RXOLE_PPE_CFG,
+				HTT_H2T_RXOLE_PPE_CFG_MSG_TYPE) |
+		u32_encode_bits(param->override, HTT_H2T_RXOLE_PPE_CFG_OVERRIDE) |
+		u32_encode_bits(param->reo_dst_ind,
+				HTT_H2T_RXOLE_PPE_CFG_REO_DST_IND) |
+		u32_encode_bits(param->multi_buffer_msdu_override_en,
+				HTT_H2T_RXOLE_PPE_CFG_MULTI_BUF_MSDU_OVRD_EN) |
+		u32_encode_bits(param->intra_bss_override,
+				HTT_H2T_RXOLE_PPE_CFG_INTRA_BUS_OVRD) |
+		u32_encode_bits(param->decap_raw_override,
+				HTT_H2T_RXOLE_PPE_CFG_DECAP_RAW_OVRD) |
+		u32_encode_bits(param->decap_nwifi_override,
+				HTT_H2T_RXOLE_PPE_CFG_NWIFI_OVRD) |
+		u32_encode_bits(param->ip_frag_override,
+				HTT_H2T_RXOLE_PPE_CFG_IP_FRAG_OVRD);
+
+	val = cmd->info0;
+	ret = ath12k_htc_send(&ab->htc, dp->eid, skb);
+	if(ret) {
+		ath12k_warn(ab, "failed to send htt type H2T rx ole ppe config request: %d",
+			ret);
+		dev_kfree_skb_any(skb);
+		return ret;
+	}
+
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "RXOLE ppe config request sent val 0x%x\n", val);
+
+	return 0;
+}
+
 int ath12k_dp_rx_htt_setup(struct ath12k_base *ab)
 {
 	struct ath12k_dp *dp = &ab->dp;
--- a/drivers/net/wireless/ath/ath12k/dp_rx.h
+++ b/drivers/net/wireless/ath/ath12k/dp_rx.h
@@ -12,6 +12,35 @@
 
 #define DP_MAX_NWIFI_HDR_LEN	30
 
+
+/* different supported pkt types for routing */
+enum ath12k_routing_pkt_type {
+	ATH12K_PKT_TYPE_ARP_IPV4,
+	ATH12K_PKT_TYPE_NS_IPV6,
+	ATH12K_PKT_TYPE_IGMP_IPV4,
+	ATH12K_PKT_TYPE_MLD_IPV6,
+	ATH12K_PKT_TYPE_DHCP_IPV4,
+	ATH12K_PKT_TYPE_DHCP_IPV6,
+	ATH12K_PKT_TYPE_DNS_TCP_IPV4,
+	ATH12K_PKT_TYPE_DNS_TCP_IPV6,
+	ATH12K_PKT_TYPE_DNS_UDP_IPV4,
+	ATH12K_PKT_TYPE_DNS_UDP_IPV6,
+	ATH12K_PKT_TYPE_ICMP_IPV4,
+	ATH12K_PKT_TYPE_ICMP_IPV6,
+	ATH12K_PKT_TYPE_TCP_IPV4,
+	ATH12K_PKT_TYPE_TCP_IPV6,
+	ATH12K_PKT_TYPE_UDP_IPV4,
+	ATH12K_PKT_TYPE_UDP_IPV6,
+	ATH12K_PKT_TYPE_IPV4,
+	ATH12K_PKT_TYPE_IPV6,
+	ATH12K_PKT_TYPE_EAP,
+	ATH12K_PKT_TYPE_MAX
+};
+
+#define ATH12K_RX_PROTOCOL_TAG_START_OFFSET  128
+#define ATH12K_ROUTE_WBM_RELEASE        3
+#define ATH12K_ROUTE_EAP_METADATA       (ATH12K_RX_PROTOCOL_TAG_START_OFFSET + ATH12K_PKT_TYPE_EAP)
+
 struct ath12k_dp_rx_tid {
 	u8 tid;
 	u32 *vaddr;
@@ -180,4 +209,10 @@ u8 ath12k_dp_rx_h_decap_type(struct ath1
 u32 ath12k_dp_rx_h_mpdu_err(struct ath12k_base *ab,
 			    struct hal_rx_desc *desc);
 void ath12k_dp_rx_h_ppdu(struct ath12k *ar, struct ath12k_dp_rx_info *rx_info);
+int
+ath12k_dp_rx_htt_rxdma_rxole_ppe_cfg_set(struct ath12k_base *ab,
+					 struct ath12k_dp_htt_rxdma_ppe_cfg_param *param);
+int ath12k_dp_rx_pkt_type_filter(struct ath12k *ar,
+				 enum ath12k_routing_pkt_type pkt_type,
+				 u32 meta_data);
 #endif /* ATH12K_DP_RX_H */
--- a/drivers/net/wireless/ath/ath12k/dp_tx.c
+++ b/drivers/net/wireless/ath/ath12k/dp_tx.c
@@ -10,6 +10,7 @@
 #include "debugfs_sta.h"
 #include "hw.h"
 #include "peer.h"
+#include "ppe.h"
 #include <linux/dma-mapping.h>
 #include <asm/cacheflush.h>
 
@@ -98,6 +99,73 @@ enum hal_encrypt_type ath12k_dp_tx_get_e
 	}
 }
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+#define ATH12K_PPEDS_HOTLIST_LEN_MAX 1024
+struct sk_buff *
+ath12k_dp_ppeds_tx_release_desc_nolock(struct ath12k_dp *dp,
+				struct ath12k_ppeds_tx_desc_info *tx_desc,
+				u8 ring_id)
+{
+	struct sk_buff *skb = NULL;
+
+	lockdep_assert_held(&dp->ppeds_tx_desc_lock[ATH12K_PPEDS_DEFAULT_POOL_ID]);
+	if (dp->ppeds_tx_desc_reuse_list_len[ring_id] < ATH12K_PPEDS_HOTLIST_LEN_MAX &&
+	    tx_desc->skb) {
+		list_move_tail(&tx_desc->list, &dp->ppeds_tx_desc_reuse_list[ring_id]);
+		dp->ppeds_tx_desc_reuse_list_len[ring_id]++;
+	} else {
+		skb = tx_desc->skb;
+		tx_desc->skb = NULL;
+		list_move_tail(&tx_desc->list, &dp->ppeds_tx_desc_free_list[ring_id]);
+	}
+
+	return skb;
+}
+
+struct ath12k_ppeds_tx_desc_info *
+ath12k_dp_ppeds_tx_assign_desc_nolock(struct ath12k_dp *dp,
+				      u8 ring_id)
+{
+	struct ath12k_ppeds_tx_desc_info *desc, *next;
+
+	lockdep_assert_held(&dp->ppeds_tx_desc_lock[ATH12K_PPEDS_DEFAULT_POOL_ID]);
+	/* first try to fetch descriptor from hotlist if not use free list */
+	desc = list_first_entry_or_null(&dp->ppeds_tx_desc_reuse_list[ring_id],
+					struct ath12k_ppeds_tx_desc_info,
+					list);
+	if (desc) {
+		list_move_tail(&desc->list, &dp->ppeds_tx_desc_used_list[ring_id]);
+		dp->ppeds_tx_desc_reuse_list_len[ring_id]--;
+		/* Prefetch next hotlist descriptor */
+		if (dp->ppeds_tx_desc_reuse_list_len[ring_id])
+			next = list_first_entry_or_null(&dp->ppeds_tx_desc_reuse_list[ring_id],
+							struct ath12k_ppeds_tx_desc_info,
+							list);
+		else
+			next = list_first_entry_or_null(&dp->ppeds_tx_desc_free_list[ring_id],
+							struct ath12k_ppeds_tx_desc_info,
+							list);
+		prefetch(next);
+
+		return desc;
+	}
+
+	/* Fetch desc from Freelist if hotlist is empty */
+	desc = list_first_entry_or_null(&dp->ppeds_tx_desc_free_list[ring_id],
+					struct ath12k_ppeds_tx_desc_info,
+					list);
+	if (unlikely(!desc)) {
+		ath12k_warn(dp->ab, "failed to allocate data Tx buffer\n");
+		return NULL;
+	}
+
+	list_move_tail(&desc->list, &dp->ppeds_tx_desc_used_list[ring_id]);
+
+	return desc;
+}
+
+#endif
+
 static void ath12k_dp_tx_release_txbuf(struct ath12k_dp *dp,
 				       struct ath12k_tx_desc_info *tx_desc,
 				       u8 ring_id)
@@ -1093,6 +1161,143 @@ static inline bool ath12k_dp_tx_completi
 	return true;
 }
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+static inline
+void ath12k_dp_ppeds_tx_comp_get_desc(struct ath12k_base *ab,
+				      struct hal_wbm_completion_ring_tx *tx_status,
+				      struct ath12k_ppeds_tx_desc_info **tx_desc)
+{
+        u64 desc_va = 0;
+	u32 desc_id;
+
+	if (likely(HAL_WBM_COMPL_TX_INFO0_CC_DONE & tx_status->info0)) {
+		/* HW done cookie conversion */
+		desc_va = ((u64)tx_status->buf_va_hi << 32 |
+			   tx_status->buf_va_lo);
+		*tx_desc = (struct ath12k_ppeds_tx_desc_info *)((unsigned long)desc_va);
+	} else {
+		/* SW does cookie conversion to VA */
+		desc_id = u32_get_bits(tx_status->buf_va_hi,
+				       BUFFER_ADDR_INFO1_SW_COOKIE);
+
+		*tx_desc = ath12k_dp_get_ppeds_tx_desc(ab, desc_id);
+	}
+}
+
+int ath12k_ppeds_tx_completion_handler(struct ath12k_base *ab, int budget)
+{
+	struct ath12k_dp *dp = &ab->dp;
+	struct dp_ppeds_tx_comp_ring *tx_ring = &dp->ppeds_comp_ring.ppe_wbm2sw_ring;
+	int hal_ring_id = tx_ring->ppe_wbm2sw_ring.ring_id;
+	struct hal_srng *status_ring = &ab->hal.srng_list[hal_ring_id];
+	struct ath12k_ppeds_tx_desc_info *tx_desc = NULL;
+	struct sk_buff *msdu;
+	u32 *desc;
+	u8 mac_id;
+	int valid_entries, count = 0, i = 0;
+	struct hal_wbm_completion_ring_tx *tx_status;
+	struct htt_tx_wbm_completion *status_desc;
+	enum hal_wbm_rel_src_module buf_rel_source;
+	struct sk_buff_head free_list_head;
+	int work_done = 0, htt_status;
+	size_t stat_size;
+
+	if (likely(ab->stats_disable))
+		/* only need buf_addr_info and info0 */
+		stat_size = 3 * sizeof(u32);
+	else
+		stat_size = sizeof(struct hal_wbm_release_ring);
+
+	spin_lock_bh(&status_ring->lock);
+
+	ath12k_hal_srng_access_dst_ring_begin_nolock(ab, status_ring);
+
+	valid_entries = ath12k_hal_srng_dst_num_free(ab, status_ring, false);
+	if (!valid_entries) {
+		ath12k_hal_srng_access_dst_ring_end_nolock(status_ring);
+		spin_unlock_bh(&status_ring->lock);
+		return work_done;
+	}
+
+	if (valid_entries >= budget)
+		valid_entries = budget;
+
+	ath12k_hal_srng_ppeds_dst_inv_entry(ab, status_ring, valid_entries);
+	skb_queue_head_init(&free_list_head);
+
+	while (likely(valid_entries--)) {
+		desc = ath12k_hal_srng_dst_get_next_cache_entry(ab, status_ring);
+		if (!desc || !ath12k_dp_tx_completion_valid(desc))
+			continue;
+
+		memcpy(&tx_ring->tx_status[count], desc, stat_size);
+		count++;
+
+		if (count == valid_entries)
+			break;
+	}
+
+	ath12k_hal_srng_access_dst_ring_end_nolock(status_ring);
+
+	spin_unlock_bh(&status_ring->lock);
+
+	spin_lock_bh(&dp->ppeds_tx_desc_lock[ATH12K_PPEDS_DEFAULT_POOL_ID]);
+	while (count--) {
+		tx_status = &tx_ring->tx_status[i++];
+
+		ath12k_dp_ppeds_tx_comp_get_desc(ab, tx_status, &tx_desc);
+		if (unlikely(!tx_desc)) {
+			ath12k_warn(ab, "unable to retrieve ppe ds tx_desc!");
+			continue;
+		}
+
+		mac_id = tx_desc->mac_id;
+
+		/* Release descriptor as soon as extracting necessary info
+		 * to reduce contention
+		 */
+		msdu = ath12k_dp_ppeds_tx_release_desc_nolock(dp, tx_desc,
+							      ATH12K_PPEDS_DEFAULT_POOL_ID);
+		buf_rel_source = FIELD_GET(HAL_WBM_RELEASE_INFO0_REL_SRC_MODULE,
+					   tx_status->info0);
+		if (unlikely(buf_rel_source == HAL_WBM_REL_SRC_MODULE_FW)) {
+			status_desc = ((void *)tx_status) + HTT_TX_WBM_COMP_STATUS_OFFSET;
+			htt_status = u32_get_bits(status_desc->info0,
+						  HTT_TX_WBM_COMP_INFO0_STATUS);
+			if (htt_status != HAL_WBM_REL_HTT_TX_COMP_STATUS_OK &&
+			    !ab->stats_disable) {
+				ab->ppeds_stats.fw2wbm_pkt_drops++;
+			}
+			dev_kfree_skb_any(msdu);
+			ath12k_warn(ab, "ath12k: Frame received from unexpected source %d status %d!\n",
+				 buf_rel_source, htt_status);
+			continue;
+		}
+
+		/* is skb is being reused, avoid freeing it */
+		if (!msdu)
+			continue;
+
+		if (skb_has_frag_list(msdu)) {
+			kfree_skb_list(skb_shinfo(msdu)->frag_list);
+			skb_shinfo(msdu)->frag_list = NULL;
+		}
+
+		if (likely(msdu->is_from_recycler)) {
+			__skb_queue_head(&free_list_head, msdu);
+		} else {
+			dev_kfree_skb(msdu);
+		}
+
+		work_done++;
+	}
+	spin_unlock_bh(&dp->ppeds_tx_desc_lock[ATH12K_PPEDS_DEFAULT_POOL_ID]);
+	dev_kfree_skb_list_fast(&free_list_head);
+
+	return work_done;
+}
+#endif
+
 int ath12k_dp_tx_completion_handler(struct ath12k_base *ab, int ring_id,
 				    int budget)
 {
@@ -1122,7 +1327,7 @@ int ath12k_dp_tx_completion_handler(stru
 
 	valid_entries = ath12k_hal_srng_dst_num_free(ab, status_ring, false);
 	if (!valid_entries) {
-		ath12k_hal_srng_access_umac_dst_ring_end_nolock(status_ring);
+		ath12k_hal_srng_access_dst_ring_end_nolock(status_ring);
 		return 0;
 	}
 
@@ -1229,7 +1434,7 @@ int ath12k_dp_tx_completion_handler(stru
 						   tx_ring->tcl_data_ring_id);
 		}
 	}
-	ath12k_hal_srng_access_umac_dst_ring_end_nolock(status_ring);
+	ath12k_hal_srng_access_dst_ring_end_nolock(status_ring);
 	dev_kfree_skb_list_fast(&free_list_head);
 
 	return (orig_budget - budget);
--- a/drivers/net/wireless/ath/ath12k/dp_tx.h
+++ b/drivers/net/wireless/ath/ath12k/dp_tx.h
@@ -220,7 +220,12 @@ int ath12k_dp_tx(struct ath12k *ar, stru
 		 bool gsn_valid, int mcbc_gsn);
 int ath12k_dp_tx_completion_handler(struct ath12k_base *ab, int ring_id,
 				    int tx_comp_budget);
-
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+int ath12k_ppeds_tx_completion_handler(struct ath12k_base *ab, int ring_id);
+struct ath12k_ppeds_tx_desc_info *
+ath12k_dp_ppeds_tx_assign_desc_nolock(struct ath12k_dp *dp,
+				      u8 ring_id);
+#endif
 int ath12k_dp_tx_htt_h2t_ppdu_stats_req(struct ath12k *ar, u32 mask);
 int
 ath12k_dp_tx_htt_h2t_ext_stats_req(struct ath12k *ar, u8 type,
--- a/drivers/net/wireless/ath/ath12k/hal.c
+++ b/drivers/net/wireless/ath/ath12k/hal.c
@@ -4,6 +4,7 @@
  * Copyright (c) 2021-2022 Qualcomm Innovation Center, Inc. All rights reserved.
  */
 #include <linux/dma-mapping.h>
+#include <asm/cacheflush.h>
 #include "hal_tx.h"
 #include "hal_rx.h"
 #include "debug.h"
@@ -57,6 +58,14 @@ static const struct hal_srng_config hw_s
 		.ring_dir = HAL_SRNG_DIR_DST,
 		.max_size = HAL_REO_STATUS_RING_BASE_MSB_RING_SIZE,
 	},
+	[HAL_REO2PPE] = {
+		.start_ring_id = HAL_SRNG_RING_ID_REO2PPE,
+		.max_rings = 1,
+		.entry_size = sizeof(struct hal_reo_dest_ring) >> 2,
+		.mac_type = ATH12K_HAL_SRNG_UMAC,
+		.ring_dir = HAL_SRNG_DIR_DST,
+		.max_size = HAL_REO2PPE_RING_BASE_MSB_RING_SIZE,
+	},
 	[HAL_TCL_DATA] = {
 		.start_ring_id = HAL_SRNG_RING_ID_SW2TCL1,
 		.max_rings = 6,
@@ -168,15 +177,15 @@ static const struct hal_srng_config hw_s
 		.start_ring_id = HAL_SRNG_RING_ID_PPE2TCL1,
 		.max_rings = 1,
 		.entry_size = sizeof(struct hal_tcl_entrance_from_ppe_ring) >> 2,
-		.mac_type = ATH12K_HAL_SRNG_PMAC,
+		.mac_type = ATH12K_HAL_SRNG_UMAC,
 		.ring_dir = HAL_SRNG_DIR_SRC,
-		.max_size = HAL_SW2TCL1_RING_BASE_MSB_RING_SIZE,
+		.max_size = HAL_PPE2TCL_RING_BASE_MSB_RING_SIZE,
 	},
 	[HAL_PPE_RELEASE] = {
 		.start_ring_id = HAL_SRNG_RING_ID_WBM_PPE_RELEASE,
 		.max_rings = 1,
 		.entry_size = sizeof(struct hal_wbm_release_ring) >> 2,
-		.mac_type = ATH12K_HAL_SRNG_PMAC,
+		.mac_type = ATH12K_HAL_SRNG_UMAC,
 		.ring_dir = HAL_SRNG_DIR_SRC,
 		.max_size = HAL_WBM2PPE_RELEASE_RING_BASE_MSB_RING_SIZE,
 	},
@@ -531,6 +540,12 @@ static int ath12k_hal_srng_create_config
 	s->reg_start[0] = HAL_SEQ_WCSS_UMAC_REO_REG + HAL_REO_STATUS_RING_BASE_LSB(ab);
 	s->reg_start[1] = HAL_SEQ_WCSS_UMAC_REO_REG + HAL_REO_STATUS_HP;
 
+	s = &hal->srng_config[HAL_REO2PPE];
+	s->reg_start[0] = HAL_SEQ_WCSS_UMAC_REO_REG + HAL_REO2PPE_RING_BASE_LSB(ab);
+	s->reg_start[1] = HAL_SEQ_WCSS_UMAC_REO_REG + HAL_REO2PPE_HP;
+	s->reg_size[0] = HAL_REO2_RING_BASE_LSB(ab) - HAL_REO1_RING_BASE_LSB(ab);
+	s->reg_size[1] = HAL_REO2_RING_HP - HAL_REO1_RING_HP;
+
 	s = &hal->srng_config[HAL_TCL_DATA];
 	s->reg_start[0] = HAL_SEQ_WCSS_UMAC_TCL_REG + HAL_TCL1_RING_BASE_LSB(ab);
 	s->reg_start[1] = HAL_SEQ_WCSS_UMAC_TCL_REG + HAL_TCL1_RING_HP;
@@ -598,10 +613,6 @@ static int ath12k_hal_srng_create_config
 	s->reg_start[0] = HAL_SEQ_WCSS_UMAC_TCL_REG + HAL_TCL_PPE2TCL1_RING_BASE_LSB;
 	s->reg_start[1] = HAL_SEQ_WCSS_UMAC_TCL_REG + HAL_TCL_PPE2TCL1_RING_HP;
 
-	s = &hal->srng_config[HAL_PPE_RELEASE];
-	s->reg_start[0] = HAL_SEQ_WCSS_UMAC_WBM_REG + HAL_WBM_PPE_RELEASE_RING_BASE_LSB(ab);
-	s->reg_start[1] = HAL_SEQ_WCSS_UMAC_WBM_REG + HAL_WBM_PPE_RELEASE_RING_HP;
-
 	return 0;
 }
 
@@ -1646,6 +1657,38 @@ u32 *ath12k_hal_srng_dst_get_next_cache_
 	return desc;
 }
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+void ath12k_hal_srng_ppeds_dst_inv_entry(struct ath12k_base *ab,
+					 struct hal_srng *srng, int entries)
+{
+	u32 *desc, *last_desc;
+	u32 tp, hp;
+	u32 remaining_entries;
+
+	if (!(srng->flags & HAL_SRNG_FLAGS_CACHED) || !entries)
+		return;
+
+	tp = srng->u.dst_ring.tp;
+	hp = srng->u.dst_ring.cached_hp;
+
+	desc = srng->ring_base_vaddr + tp;
+	if (hp > tp) {
+		last_desc = ((void *)desc + entries * srng->entry_size * sizeof(u32));
+		dmac_inv_range_no_dsb((void *)desc,
+				      (void *)last_desc);
+	} else {
+		remaining_entries = srng->ring_size - tp;
+		last_desc = ((void *)desc + remaining_entries * sizeof(u32));
+		dmac_inv_range_no_dsb((void *)desc, (void *)last_desc);
+
+		last_desc = ((void *)srng->ring_base_vaddr + hp * sizeof(u32));
+		dmac_inv_range_no_dsb((void *)srng->ring_base_vaddr, (void *)last_desc);
+	}
+
+	dsb(st);
+}
+#endif
+
 void ath12k_hal_srng_dst_invalidate_entry(struct ath12k_base *ab,
 					  struct hal_srng *srng, int entries)
 {
@@ -2197,6 +2240,15 @@ void ath12k_hal_srng_shadow_config(struc
 	}
 }
 
+void ath12k_hal_reo_config_reo2ppe_dest_info(struct ath12k_base *ab)
+{
+	u32 reo_base = HAL_SEQ_WCSS_UMAC_REO_REG;
+	u32 val = HAL_REO1_REO2PPE_DST_VAL;
+
+	ath12k_hif_write32(ab, reo_base + HAL_REO1_REO2PPE_DST_INFO,
+                          val);
+}
+
 void ath12k_hal_srng_get_shadow_config(struct ath12k_base *ab,
 				       u32 **cfg, u32 *len)
 {
--- a/drivers/net/wireless/ath/ath12k/hal.h
+++ b/drivers/net/wireless/ath/ath12k/hal.h
@@ -139,11 +139,6 @@ struct ath12k_base;
 #define HAL_TCL_PPE2TCL1_RING_BASE_LSB		0x00000c48
 #define HAL_TCL_PPE2TCL1_RING_HP		0x00002038
 
-/* WBM PPE Release Ring address */
-#define HAL_WBM_PPE_RELEASE_RING_BASE_LSB(ab) \
-		((ab)->hw_params->regs->hal_ppe_rel_ring_base)
-#define HAL_WBM_PPE_RELEASE_RING_HP		0x00003020
-
 /* REO2SW(x) R0 ring configuration address */
 #define HAL_REO1_GEN_ENABLE			0x00000000
 #define HAL_REO1_MISC_CTRL_ADDR(ab) \
@@ -194,6 +189,9 @@ struct ath12k_base;
 #define HAL_REO1_RING_MISC_OFFSET \
 		(HAL_REO1_RING_MISC(ab) - HAL_REO1_RING_BASE_LSB(ab))
 
+#define HAL_REO1_REO2PPE_DST_VAL		0x2000
+#define HAL_REO1_REO2PPE_DST_INFO		0x00000cf0
+
 /* REO2SW(x) R2 ring pointers (head/tail) address */
 #define HAL_REO1_RING_HP			0x00003048
 #define HAL_REO1_RING_TP			0x0000304c
@@ -240,6 +238,12 @@ struct ath12k_base;
 		((ab)->hw_params->regs->hal_reo_status_ring_base)
 #define HAL_REO_STATUS_HP			0x000030a8
 
+
+/* REO2PPE address */
+#define HAL_REO2PPE_RING_BASE_LSB(ab) \
+		((ab)->hw_params->regs->hal_reo2ppe_ring_base)
+#define HAL_REO2PPE_HP				0x00003090
+
 /* WBM Idle R0 address */
 #define HAL_WBM_IDLE_LINK_RING_BASE_LSB(ab) \
 	((ab)->hw_params->regs->hal_wbm_idle_ring_base_lsb)
@@ -307,6 +311,7 @@ struct ath12k_base;
 #define HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW2_EN		BIT(3)
 #define HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW3_EN		BIT(4)
 #define HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW4_EN		BIT(5)
+#define HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW6_EN		BIT(7)
 #define HAL_WBM_SW_COOKIE_CONV_CFG_GLOBAL_EN		BIT(8)
 
 /* TCL ring feild mask and offset */
@@ -388,6 +393,8 @@ struct ath12k_base;
 #define HAL_REO_SW2REO_RING_BASE_MSB_RING_SIZE		0x0000ffff
 #define HAL_REO_CMD_RING_BASE_MSB_RING_SIZE		0x0000ffff
 #define HAL_REO_STATUS_RING_BASE_MSB_RING_SIZE		0x0000ffff
+#define HAL_REO2PPE_RING_BASE_MSB_RING_SIZE		0xffffffff
+#define HAL_PPE2TCL_RING_BASE_MSB_RING_SIZE		0x000fffff
 #define HAL_SW2TCL1_RING_BASE_MSB_RING_SIZE		0x000fffff
 #define HAL_SW2TCL1_CMD_RING_BASE_MSB_RING_SIZE		0x000fffff
 #define HAL_TCL_STATUS_RING_BASE_MSB_RING_SIZE		0x0000ffff
@@ -399,9 +406,11 @@ struct ath12k_base;
 #define HAL_WBM2SW_RELEASE_RING_BASE_MSB_RING_SIZE	0x000fffff
 #define HAL_RXDMA_RING_MAX_SIZE				0x0000ffff
 #define HAL_RXDMA_RING_MAX_SIZE_BE			0x000fffff
-#define HAL_WBM2PPE_RELEASE_RING_BASE_MSB_RING_SIZE	0x000fffff
+#define HAL_WBM2PPE_RELEASE_RING_BASE_MSB_RING_SIZE	0x0000ffff
 
 #define HAL_WBM2SW_REL_ERR_RING_NUM 3
+#define HAL_WBM2SW_PPEDS_TX_CMPLN_MAP_ID 11
+#define HAL_WBM2SW_PPEDS_TX_CMPLN_RING_NUM 6
 /* Add any other errors here and return them in
  * ath12k_hal_rx_desc_get_err().
  */
@@ -560,6 +569,7 @@ enum hal_ring_type {
 	HAL_REO_REINJECT,
 	HAL_REO_CMD,
 	HAL_REO_STATUS,
+	HAL_REO2PPE,
 	HAL_TCL_DATA,
 	HAL_TCL_CMD,
 	HAL_TCL_STATUS,
@@ -791,13 +801,16 @@ struct hal_srng {
 };
 
 /* Interrupt mitigation - Batch threshold in terms of numer of frames */
+#define HAL_SRNG_INT_BATCH_THRESHOLD_PPE_WBM2SW_REL 256
 #define HAL_SRNG_INT_BATCH_THRESHOLD_TX 64
 #define HAL_SRNG_INT_BATCH_THRESHOLD_RX 128
+#define HAL_SRNG_INT_BATCH_THRESHOLD_PPE2TCL 0
 #define HAL_SRNG_INT_BATCH_THRESHOLD_OTHER 1
 
 /* Interrupt mitigation - timer threshold in us */
 #define HAL_SRNG_INT_TIMER_THRESHOLD_TX 200
 #define HAL_SRNG_INT_TIMER_THRESHOLD_RX 500
+#define HAL_SRNG_INT_TIMER_THRESHOLD_PPE2TCL 30
 #define HAL_SRNG_INT_TIMER_THRESHOLD_OTHER 256
 
 enum hal_srng_mac_type {
@@ -1197,6 +1210,10 @@ void ath12k_hal_srng_shadow_update_hp_tp
 					 struct hal_srng *srng);
 u32 *ath12k_hal_srng_dst_get_next_cache_entry(struct ath12k_base *ab,
 					      struct hal_srng *srng);
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+void ath12k_hal_srng_ppeds_dst_inv_entry(struct ath12k_base *ab,
+					  struct hal_srng *srng, int entries);
+#endif
 void ath12k_hal_srng_dst_invalidate_entry(struct ath12k_base *ab,
 					  struct hal_srng *srng, int entries);
 void ath12k_hal_reo_ring_ctrl_hash_ix3_setup(struct ath12k_base *ab,
@@ -1206,6 +1223,7 @@ void ath12k_hal_reo_ring_ctrl_hash_ix2_s
 void ath12k_hal_reo_shared_qaddr_cache_clear(struct ath12k_base *ab);
 void ath12k_hal_srng_prefetch_desc(struct ath12k_base *ab,
 				   struct hal_srng *srng);
+void ath12k_hal_reo_config_reo2ppe_dest_info(struct ath12k_base *ab);
 
 static inline
 u32 *ath12k_hal_srng_src_get_next_entry_nolock(struct ath12k_base *ab,
@@ -1265,7 +1283,7 @@ void ath12k_hal_srng_access_umac_src_rin
 }
 
 static inline
-void ath12k_hal_srng_access_umac_dst_ring_end_nolock(struct hal_srng *srng)
+void ath12k_hal_srng_access_dst_ring_end_nolock(struct hal_srng *srng)
 {
 	srng->u.dst_ring.last_hp = *srng->u.dst_ring.hp_addr;
 	writel_relaxed(srng->u.dst_ring.tp, srng->u.dst_ring.tp_addr_direct);
--- a/drivers/net/wireless/ath/ath12k/hal_desc.h
+++ b/drivers/net/wireless/ath/ath12k/hal_desc.h
@@ -923,53 +923,6 @@ struct hal_reo_dest_ring {
  *		this ring has looped around the ring.
  */
 
-#define HAL_REO_TO_PPE_RING_INFO0_DATA_LENGTH	GENMASK(15, 0)
-#define HAL_REO_TO_PPE_RING_INFO0_DATA_OFFSET	GENMASK(23, 16)
-#define HAL_REO_TO_PPE_RING_INFO0_POOL_ID	GENMASK(28, 24)
-#define HAL_REO_TO_PPE_RING_INFO0_PREHEADER	BIT(29)
-#define HAL_REO_TO_PPE_RING_INFO0_TSO_EN	BIT(30)
-#define HAL_REO_TO_PPE_RING_INFO0_MORE	BIT(31)
-
-struct hal_reo_to_ppe_ring {
-	u32 buffer_addr;
-	u32 info0; /* %HAL_REO_TO_PPE_RING_INFO0_ */
-} __packed;
-
-/* hal_reo_to_ppe_ring
- *
- *		Producer: REO
- *		Consumer: PPE
- *
- * buf_addr_info
- *		Details of the physical address of a buffer or MSDU
- *		link descriptor.
- *
- * data_length
- *		Length of valid data in bytes
- *
- * data_offset
- *		Offset to the data from buffer pointer. Can be used to
- *		strip header in the data for tunnel termination etc.
- *
- * pool_id
- *		REO has global configuration register for this field.
- *		It may have several free buffer pools, each
- *		RX-Descriptor ring can fetch free buffer from specific
- *		buffer pool; pool id will indicate which pool the buffer
- *		will be released to; POOL_ID Zero returned to SW
- *
- * preheader
- *		Disabled: 0 (Default)
- *		Enabled: 1
- *
- * tso_en
- *		Disabled: 0 (Default)
- *		Enabled: 1
- *
- * more
- *		More Segments followed
- */
-
 enum hal_reo_entr_rxdma_push_reason {
 	HAL_REO_ENTR_RING_RXDMA_PUSH_REASON_ERR_DETECTED,
 	HAL_REO_ENTR_RING_RXDMA_PUSH_REASON_ROUTING_INSTRUCTION,
@@ -2936,18 +2889,15 @@ struct hal_reo_desc_thresh_reached_statu
  *		entries into this Ring has looped around the ring.
  */
 
-#define HAL_TCL_ENTRANCE_FROM_PPE_RING_INFO0_DATA_LENGTH	GENMASK(13, 0)
-#define HAL_TCL_ENTRANCE_FROM_PPE_RING_INFO0_L4_CSUM_STATUS	BIT(14)
-#define HAL_TCL_ENTRANCE_FROM_PPE_RING_INFO0_L3_CSUM_STATUS	BIT(15)
-#define HAL_TCL_ENTRANCE_FROM_PPE_RING_INFO0_PID		GENMASK(27, 24)
-#define HAL_TCL_ENTRANCE_FROM_PPE_RING_INFO0_QDISC		BIT(28)
-#define HAL_TCL_ENTRANCE_FROM_PPE_RING_INFO0_MULTICAST	BIT(29)
-#define HAL_TCL_ENTRANCE_FROM_PPE_RING_INFO0_MORE		BIT(30)
-#define HAL_TCL_ENTRANCE_FROM_PPE_RING_INFO0_VALID_TOGGLE	BIT(31)
-
 struct hal_tcl_entrance_from_ppe_ring {
 	u32 buffer_addr;
 	u32 info0;
+	u32 opaque_lo;
+	u32 opaque_hi;
+	u32 info1;
+	u32 info2;
+	u32 info3;
+	u32 info4;
 } __packed;
 
 struct hal_mon_buf_ring {
--- a/drivers/net/wireless/ath/ath12k/hal_rx.c
+++ b/drivers/net/wireless/ath/ath12k/hal_rx.c
@@ -835,6 +835,20 @@ void ath12k_hal_reo_init_cmd_ring(struct
 	}
 }
 
+void ath12k_hal_reo_ring_ctrl_hash_ix0_setup(struct ath12k_base *ab)
+{
+	u32 reo_base = HAL_SEQ_WCSS_UMAC_REO_REG;
+	u32 curr, val;
+
+	curr = ath12k_hif_read32(ab, reo_base + HAL_REO1_DEST_RING_CTRL_IX_0);
+	val = curr & ~(REO_DEST_CTRL_IX_0_RING6_MAP_MASK <<
+		       REO_DEST_CTRL_IX_0_RING6_MAP_SHFT);
+	val |= (REO2PPE_DST_RING_MAP << REO_DEST_CTRL_IX_0_RING6_MAP_SHFT);
+
+	ath12k_hif_write32(ab, reo_base + HAL_REO1_DEST_RING_CTRL_IX_0,
+			   val);
+}
+
 void ath12k_hal_reo_ring_ctrl_hash_ix2_setup(struct ath12k_base *ab,
 					     u32 ring_hash_map)
 {
@@ -883,6 +897,7 @@ void ath12k_hal_reo_hw_setup(struct ath1
 	ath12k_hif_write32(ab, reo_base + HAL_REO1_AGING_THRESH_IX_3(ab),
 			   HAL_DEFAULT_VO_REO_TIMEOUT_USEC);
 
+	ath12k_hal_reo_ring_ctrl_hash_ix0_setup(ab);
 	ath12k_hal_reo_ring_ctrl_hash_ix2_setup(ab, ring_hash_map);
 	ath12k_hal_reo_ring_ctrl_hash_ix3_setup(ab, ring_hash_map);
 
--- a/drivers/net/wireless/ath/ath12k/hal_rx.h
+++ b/drivers/net/wireless/ath/ath12k/hal_rx.h
@@ -959,6 +959,10 @@ enum ath12k_eht_ru_size {
 	ATH12K_EHT_RU_INVALID,
 };
 
+#define REO2PPE_DST_RING_MAP 11
+#define REO_DEST_CTRL_IX_0_RING6_MAP_MASK 0xF
+#define REO_DEST_CTRL_IX_0_RING6_MAP_SHFT 24
+
 void ath12k_hal_reo_status_queue_stats(struct ath12k_base *ab, u32 *reo_desc,
 				       struct hal_reo_status *status);
 void ath12k_hal_reo_flush_queue_status(struct ath12k_base *ab, u32 *reo_desc,
--- a/drivers/net/wireless/ath/ath12k/hal_tx.c
+++ b/drivers/net/wireless/ath/ath12k/hal_tx.c
@@ -99,6 +99,16 @@ void ath12k_hal_tx_configure_bank_regist
 			   bank_config);
 }
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+void ath12k_hal_tx_set_ppe_vp_entry(struct ath12k_base *ab, u32 ppe_vp_config,
+				    u32 ppe_vp_idx)
+{
+	ath12k_hif_write32(ab, HAL_TX_PPE_VP_CONFIG_TABLE_ADDR +
+			   HAL_TX_PPE_VP_CONFIG_TABLE_OFFSET * ppe_vp_idx,
+			   ppe_vp_config);
+}
+#endif
+
 void ath12k_hal_tx_config_rbm_mapping(struct ath12k_base *ab,u8 ring_num,
 				      u8 rbm_id, int ring_type)
 {
--- a/drivers/net/wireless/ath/ath12k/hal_tx.h
+++ b/drivers/net/wireless/ath/ath12k/hal_tx.h
@@ -182,6 +182,22 @@ struct hal_tx_fes_status_end {
 /* STA mode will have MCAST_PKT_CTRL instead of DSCP_TID_MAP bitfield */
 #define HAL_TX_BANK_CONFIG_DSCP_TIP_MAP_ID	GENMASK(22, 17)
 
+#define HAL_TX_PPE_VP_CONFIG_TABLE_ADDR		0x00a44194
+#define HAL_TX_PPE_VP_CONFIG_TABLE_OFFSET	4
+
+#define HAL_TX_PPE_VP_CFG_VP_NUM		GENMASK(7, 0)
+#define HAL_TX_PPE_VP_CFG_PMAC_ID		GENMASK(9, 8)
+#define HAL_TX_PPE_VP_CFG_BANK_ID		GENMASK(15, 10)
+#define HAL_TX_PPE_VP_CFG_VDEV_ID		GENMASK(23, 16)
+#define HAL_TX_PPE_VP_CFG_SRCH_IDX_REG_NUM	GENMASK(26, 24)
+#define HAL_TX_PPE_VP_CFG_USE_PPE_INT_PRI	BIT(27)
+#define HAL_TX_PPE_VP_CFG_TO_FW			BIT(28)
+#define HAL_TX_PPE_VP_CFG_DROP_PREC_EN		BIT(29)
+
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+void ath12k_hal_tx_set_ppe_vp_entry(struct ath12k_base *ab, u32 ppe_vp_config,
+                                    u32 ppe_vp_index);
+#endif
 void ath12k_hal_tx_set_dscp_tid_map(struct ath12k_base *ab, int id);
 int ath12k_hal_reo_cmd_send(struct ath12k_base *ab, struct hal_srng *srng,
 			    enum hal_reo_cmd_type type,
--- a/drivers/net/wireless/ath/ath12k/hif.h
+++ b/drivers/net/wireless/ath/ath12k/hif.h
@@ -8,6 +8,7 @@
 #define ATH12K_HIF_H
 
 #include "core.h"
+#include "pci.h"
 
 struct ath12k_hif_ops {
 	u32 (*read32)(struct ath12k_base *sc, u32 address);
@@ -34,8 +35,56 @@ struct ath12k_hif_ops {
 	void (*get_ce_msi_idx)(struct ath12k_base *ab, u32 ce_id, u32 *msi_idx);
 	int (*ssr_notifier_reg)(struct ath12k_base *ab);
 	int (*ssr_notifier_unreg)(struct ath12k_base *ab);
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	int (*ppeds_register_interrupts)(struct ath12k_base *ab, int type, int vector,
+					 int ring_num);
+	void (*ppeds_free_interrupts)(struct ath12k_base *ab);
+	void (*ppeds_irq_enable)(struct ath12k_base *ab, enum ppeds_irq_type type);
+	void (*ppeds_irq_disable)(struct ath12k_base *ab, enum ppeds_irq_type type);
+#endif
 };
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+static inline int ath12k_hif_ppeds_register_interrupts(struct ath12k_base *ab, int type, int vector,
+						       int ring_num)
+{
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return 0;
+
+	if (ab->hif.ops->ppeds_register_interrupts)
+		return ab->hif.ops->ppeds_register_interrupts(ab, type, vector,
+							      ring_num);
+	return 0;
+}
+
+static inline void ath12k_hif_ppeds_free_interrupts(struct ath12k_base *ab)
+{
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return;
+
+	if (ab->hif.ops->ppeds_register_interrupts)
+		ab->hif.ops->ppeds_free_interrupts(ab);
+}
+
+static inline void ath12k_hif_ppeds_irq_enable(struct ath12k_base *ab, enum ppeds_irq_type type)
+{
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return;
+
+	if (ab->hif.ops->ppeds_irq_enable)
+		ab->hif.ops->ppeds_irq_enable(ab, type);
+}
+
+static inline void ath12k_hif_ppeds_irq_disable(struct ath12k_base *ab, enum ppeds_irq_type type)
+{
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return;
+
+	if (ab->hif.ops->ppeds_irq_disable)
+		ab->hif.ops->ppeds_irq_disable(ab, type);
+}
+#endif
+
 static inline int ath12k_hif_map_service_to_pipe(struct ath12k_base *ab, u16 service_id,
 						 u8 *ul_pipe, u8 *dl_pipe)
 {
--- a/drivers/net/wireless/ath/ath12k/hw.c
+++ b/drivers/net/wireless/ath/ath12k/hw.c
@@ -158,6 +158,10 @@ static const struct ath12k_hw_ops ipq533
 #define ATH12K_TX_MON_RING_MASK_0 0x1
 #define ATH12K_TX_MON_RING_MASK_1 0x2
 
+#define ATH12K_PPE2TCL_RING_MASK_0 0x1
+#define ATH12K_REO2PPE_RING_MASK_0 0x1
+#define ATH12K_PPE_WBM2SW_RELEASE_RING_MASK_0 0x1
+
 /* Target firmware's Copy Engine configuration. */
 static const struct ce_pipe_config ath12k_target_ce_config_wlan_qcn9274[] = {
 	/* CE0: host->target HTC control and raw streams */
@@ -793,13 +797,14 @@ static const struct ath12k_hw_ring_mask
 		ATH12K_TX_RING_MASK_2,
 		0, 0, 0, 0, 0, 0, 0, 0,
 		ATH12K_TX_RING_MASK_4,
+		0, 0, 0
 	},
 	.rx_mon_dest = {
 		0, 0, 0, 0, 0, 0, 0, 0,
 		ATH12K_RX_MON_RING_MASK_0,
 		ATH12K_RX_MON_RING_MASK_1,
 		ATH12K_RX_MON_RING_MASK_2,
-		0,
+		0, 0, 0, 0
 	},
 	.rx = {
 		0, 0, 0, 0,
@@ -808,32 +813,52 @@ static const struct ath12k_hw_ring_mask
 		ATH12K_RX_RING_MASK_2,
 		ATH12K_RX_RING_MASK_3,
 		0, 0, 0, 0,
+		0, 0, 0
 	},
 	.rx_err = {
 		0, 0, 0,
 		ATH12K_RX_ERR_RING_MASK_0,
 		0, 0, 0, 0, 0, 0, 0, 0,
+		0, 0, 0
 	},
 	.rx_wbm_rel = {
 		0, 0, 0,
 		ATH12K_RX_WBM_REL_RING_MASK_0,
 		0, 0, 0, 0, 0, 0, 0, 0,
+		0, 0, 0
 	},
 	.reo_status = {
 		0, 0, 0,
 		ATH12K_REO_STATUS_RING_MASK_0,
 		0, 0, 0, 0, 0, 0, 0, 0,
+		0, 0, 0
 	},
 	.host2rxdma = {
 		0, 0, 0,
 		ATH12K_HOST2RXDMA_RING_MASK_0,
 		0, 0, 0, 0, 0, 0, 0, 0,
+		0, 0, 0
 	},
 	.tx_mon_dest = {
 		ATH12K_TX_MON_RING_MASK_0,
 		ATH12K_TX_MON_RING_MASK_1,
-		0, 0, 0, 0, 0, 0, 0, 0, 0, 0
+		0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+		0, 0, 0
 	},
+	.ppe2tcl = {
+		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+		ATH12K_PPE2TCL_RING_MASK_0, 0, 0
+	},
+	.reo2ppe = {
+		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+		0, ATH12K_REO2PPE_RING_MASK_0, 0
+	},
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	.wbm2sw6_ppeds_tx_cmpln = {
+		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+		0, 0, ATH12K_PPE_WBM2SW_RELEASE_RING_MASK_0
+	},
+#endif
 };
 
 static const struct ath12k_hw_ring_mask ath12k_hw_ring_mask_ipq5332 = {
@@ -990,8 +1015,8 @@ static const struct ath12k_hw_regs qcn92
 	.hal_wbm0_release_ring_base_lsb = 0x00000dd8,
 	.hal_wbm1_release_ring_base_lsb = 0x00000e50,
 
-	/* PPE release ring address */
-	.hal_ppe_rel_ring_base = 0x0000043c,
+	/* reo2ppe ring address */
+	.hal_reo2ppe_ring_base = 0x00000938,
 
 	/* PCIe base address */
 	.pcie_qserdes_sysclk_en_sel = 0x01e0c0a8,
@@ -1081,8 +1106,8 @@ const struct ath12k_hw_regs qcn9274_v2_r
 	.hal_wbm0_release_ring_base_lsb = 0x00000e08,
 	.hal_wbm1_release_ring_base_lsb = 0x00000e80,
 
-	/* PPE release ring address */
-	.hal_ppe_rel_ring_base = 0x0000046c,
+	/* reo2ppe ring base address */
+	.hal_reo2ppe_ring_base = 0x00000938,
 
 	/* PCIe base address */
 	.pcie_qserdes_sysclk_en_sel = 0x01e0c0a8,
@@ -1171,9 +1196,6 @@ const struct ath12k_hw_regs ipq5332_regs
 	.hal_wbm0_release_ring_base_lsb = 0x00000e08,
 	.hal_wbm1_release_ring_base_lsb = 0x00000e80,
 
-	/* PPE release ring address */
-	.hal_ppe_rel_ring_base = 0x0000046c,
-
 	/* CE base address */
 	.hal_umac_ce0_src_reg_base = 0x00740000,
 	.hal_umac_ce0_dest_reg_base = 0x00741000,
@@ -1235,7 +1257,8 @@ static const struct ath12k_hw_hal_params
 			    HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW1_EN |
 			    HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW2_EN |
 			    HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW3_EN |
-			    HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW4_EN,
+			    HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW4_EN |
+			    HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW6_EN,
 };
 
 static const struct ath12k_hw_hal_params ath12k_hw_hal_params_wcn7850 = {
--- a/drivers/net/wireless/ath/ath12k/hw.h
+++ b/drivers/net/wireless/ath/ath12k/hw.h
@@ -73,6 +73,7 @@
 #define ATH12K_HW_DEFAULT_QUEUE		0
 
 #define ATH12K_HW_MAX_QUEUES		4
+#define ATH12K_HW_MAX_QUEUES_PPEDS	1
 #define ATH12K_QUEUE_LEN		4096
 
 #define ATH11k_HW_RATECODE_CCK_SHORT_PREAM_MASK  0x4
@@ -116,22 +117,28 @@ enum ath12k_bus {
 	ATH12K_BUS_AHB,
 };
 
-#define ATH12K_EXT_IRQ_GRP_NUM_MAX 13
-
+/* Regular 12 Host DP interrupts + 3 PPEDS interrupts */
+#define ATH12K_EXT_IRQ_DP_NUM_VECTORS 15
+#define ATH12K_EXT_IRQ_GRP_NUM_MAX 12
 struct hal_rx_desc;
 struct hal_tcl_data_cmd;
 struct htt_rx_ring_tlv_filter;
 enum hal_encrypt_type;
 
 struct ath12k_hw_ring_mask {
-	u8 tx[ATH12K_EXT_IRQ_GRP_NUM_MAX];
-	u8 rx_mon_dest[ATH12K_EXT_IRQ_GRP_NUM_MAX];
-	u8 rx[ATH12K_EXT_IRQ_GRP_NUM_MAX];
-	u8 rx_err[ATH12K_EXT_IRQ_GRP_NUM_MAX];
-	u8 rx_wbm_rel[ATH12K_EXT_IRQ_GRP_NUM_MAX];
-	u8 reo_status[ATH12K_EXT_IRQ_GRP_NUM_MAX];
-	u8 host2rxdma[ATH12K_EXT_IRQ_GRP_NUM_MAX];
-	u8 tx_mon_dest[ATH12K_EXT_IRQ_GRP_NUM_MAX];
+	u8 tx[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+	u8 rx_mon_dest[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+	u8 rx[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+	u8 rx_err[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+	u8 rx_wbm_rel[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+	u8 reo_status[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+	u8 host2rxdma[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+	u8 tx_mon_dest[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+	u8 ppe2tcl[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+	u8 reo2ppe[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	u8 wbm2sw6_ppeds_tx_cmpln[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
+#endif
 };
 
 struct ath12k_hw_hal_params {
@@ -321,6 +328,7 @@ struct ath12k_hw_regs {
 	u32 hal_tcl_status_ring_base_lsb;
 
 	u32 hal_reo2_ring_base;
+	u32 hal_reo2ppe_ring_base;
 	u32 hal_reo1_misc_ctrl_addr;
 	u32 hal_reo1_sw_cookie_cfg0;
 	u32 hal_reo1_sw_cookie_cfg1;
@@ -370,8 +378,6 @@ struct ath12k_hw_regs {
 	u32 hal_wbm0_release_ring_base_lsb;
 	u32 hal_wbm1_release_ring_base_lsb;
 
-	u32 hal_ppe_rel_ring_base;
-
 	u32 pcie_qserdes_sysclk_en_sel;
 	u32 pcie_pcs_osc_dtct_config_base;
 
--- a/drivers/net/wireless/ath/ath12k/mac.c
+++ b/drivers/net/wireless/ath/ath12k/mac.c
@@ -23,6 +23,7 @@
 #include "testmode.h"
 #include "peer.h"
 #include "debugfs_sta.h"
+#include "ppe.h"
 
 #define CHAN2G(_channel, _freq, _flags) { \
 	.band                   = NL80211_BAND_2GHZ, \
@@ -9053,6 +9054,16 @@ static int ath12k_mac_radio_start(struct
 		}
 	}
 
+	/* PPE DS requires eapol packets to be routed to wbm release ring */
+	if (test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ar->ab->dev_flags)) {
+		ret = ath12k_dp_rx_pkt_type_filter(ar, ATH12K_PKT_TYPE_EAP,
+						   ATH12K_ROUTE_EAP_METADATA);
+		if (ret) {
+			ath12k_err(ar->ab, "failed to configure EAP pkt route: %d\n", ret);
+			goto err;
+		}
+	}
+
 	__ath12k_set_antenna(ar, ar->cfg_tx_chainmask, ar->cfg_rx_chainmask);
 
 	/* TODO: Do we need to enable ANI? */
@@ -14122,6 +14133,10 @@ static const struct ieee80211_ops ath12k
 #endif
 	.get_txpower			= ath12k_mac_op_get_txpower,
 	.set_radar_background		= ath12k_mac_op_set_radar_background,
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	.ppeds_attach_vdev		= ath12k_mac_op_ppeds_attach_vdev,
+	.ppeds_detach_vdev		= ath12k_mac_op_ppeds_detach_vdev,
+#endif
 };
 
 static void ath12k_mac_update_ch_list(struct ath12k *ar,
--- a/drivers/net/wireless/ath/ath12k/pci.c
+++ b/drivers/net/wireless/ath/ath12k/pci.c
@@ -14,6 +14,7 @@
 #include "hif.h"
 #include "mhi.h"
 #include "debug.h"
+#include "ppe.h"
 
 #define ATH12K_PCI_BAR_NUM		0
 #define ATH12K_PCI_DMA_MASK		32
@@ -52,7 +53,7 @@ EXPORT_SYMBOL(tx_comp_budget);
 module_param_named(tx_comp_budget, tx_comp_budget, uint, 0644);
 MODULE_PARM_DESC(tx_comp_budget, "tx_comp_budget");
 
-char dp_irq_name[ATH12K_MAX_PCI_DOMAINS + 1][ATH12K_EXT_IRQ_GRP_NUM_MAX][DP_IRQ_NAME_LEN] = {};
+char dp_irq_name[ATH12K_MAX_PCI_DOMAINS + 1][ATH12K_EXT_IRQ_DP_NUM_VECTORS][DP_IRQ_NAME_LEN] = {};
 
 unsigned int ath12k_fw_mem_seg;
 EXPORT_SYMBOL(ath12k_fw_mem_seg);
@@ -85,7 +86,7 @@ static const struct ath12k_msi_config at
 		.users = (struct ath12k_msi_user[]) {
 			{ .name = "MHI", .num_vectors = 3, .base_vector = 0 },
 			{ .name = "CE", .num_vectors = 5, .base_vector = 3 },
-			{ .name = "DP", .num_vectors = 12, .base_vector = 8 },
+			{ .name = "DP", .num_vectors = 15, .base_vector = 8 },
 		},
 	},
 };
@@ -545,6 +546,11 @@ static int ath12k_pci_ext_irq_config(str
 		    ab->hw_params->ring_mask->rx_wbm_rel[i] ||
 		    ab->hw_params->ring_mask->reo_status[i] ||
 		    ab->hw_params->ring_mask->host2rxdma[i] ||
+		    ab->hw_params->ring_mask->ppe2tcl[i] ||
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+		    ab->hw_params->ring_mask->wbm2sw6_ppeds_tx_cmpln[i] ||
+#endif
+		    ab->hw_params->ring_mask->reo2ppe[i] ||
 		    ab->hw_params->ring_mask->rx_mon_dest[i]) {
 			num_irq = 1;
 		}
@@ -590,6 +596,88 @@ static int ath12k_pci_ext_irq_config(str
 	return 0;
 }
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+int ath12k_pci_ppeds_register_interrupts(struct ath12k_base *ab, int type, int vector,
+					int ring_num)
+{
+	struct ath12k_pci *ar_pci = (struct ath12k_pci *)ab->drv_priv;
+	int irq;
+	u8 bus_id = pci_domain_nr(ar_pci->pdev->bus);
+	int ret;
+
+	if (type != HAL_REO2PPE && type != HAL_PPE2TCL &&
+	    !(type == HAL_WBM2SW_RELEASE &&
+	    ring_num == HAL_WBM2SW_PPEDS_TX_CMPLN_RING_NUM)) {
+		return 0;
+	}
+
+	if (ab->ppeds_node_idx == -1) {
+		ath12k_err(ab, "invalid ppeds_node_idx in ppeds_register_interrupts\n");
+		return -EINVAL;
+	}
+
+	irq = ath12k_pci_get_msi_irq(ab->dev, vector);
+
+	irq_set_status_flags(irq, IRQ_DISABLE_UNLAZY);
+	if (type == HAL_PPE2TCL) {
+		snprintf(&ab->dp.ppeds_irq_name[PPEDS_IRQ_PPE2TCL], sizeof(ab->dp.ppeds_irq_name),
+			 "pci%d_ppe2tcl_%d", bus_id, ab->ppeds_node_idx);
+		ret = request_irq(irq,  ath12k_ds_ppe2tcl_irq_handler,
+				  IRQF_SHARED,
+			    ab->dp.ppeds_irq_name[PPEDS_IRQ_PPE2TCL], (void *)ath12k_dp_get_ppe_ds_ctxt(ab));
+		if (ret)
+			goto irq_fail;
+		ab->dp.ppeds_irq[PPEDS_IRQ_PPE2TCL] = irq;
+	} else if (type == HAL_REO2PPE) {
+		snprintf(&ab->dp.ppeds_irq_name[PPEDS_IRQ_REO2PPE], sizeof(ab->dp.ppeds_irq_name),
+			 "pci%d_reo2ppe_%d", bus_id, ab->ppeds_node_idx);
+		ret = request_irq(irq,  ath12k_ds_reo2ppe_irq_handler,
+				  IRQF_SHARED,
+				  ab->dp.ppeds_irq_name[PPEDS_IRQ_REO2PPE], (void *)ath12k_dp_get_ppe_ds_ctxt(ab));
+		if (ret)
+			goto irq_fail;
+		ab->dp.ppeds_irq[PPEDS_IRQ_REO2PPE] = irq;
+	} else if (type == HAL_WBM2SW_RELEASE && ring_num == HAL_WBM2SW_PPEDS_TX_CMPLN_RING_NUM) {
+		snprintf(&ab->dp.ppeds_irq_name[PPEDS_IRQ_PPE_WBM2SW_REL], sizeof(ab->dp.ppeds_irq_name),
+			 "pci%d_ppe_wbm_rel_%d", bus_id, ab->ppeds_node_idx);
+		ret = request_irq(irq,  ath12k_dp_ppeds_handle_tx_comp,
+				  IRQF_SHARED,
+				  ab->dp.ppeds_irq_name[PPEDS_IRQ_PPE_WBM2SW_REL],(void *)ab);
+		if (ret)
+			goto irq_fail;
+		ab->dp.ppeds_irq[PPEDS_IRQ_PPE_WBM2SW_REL] = irq;
+	}
+	disable_irq_nosync(irq);
+
+	return 0;
+
+irq_fail:
+	return ret;
+}
+
+void ath12k_pci_ppeds_irq_disable(struct ath12k_base *ab, enum ppeds_irq_type type)
+{
+	disable_irq_nosync(ab->dp.ppeds_irq[type]);
+}
+
+void ath12k_pci_ppeds_irq_enable(struct ath12k_base *ab, enum ppeds_irq_type type)
+{
+	enable_irq(ab->dp.ppeds_irq[type]);
+}
+
+void ath12k_pci_ppeds_free_interrupts(struct ath12k_base *ab)
+{
+	disable_irq_nosync(ab->dp.ppeds_irq[PPEDS_IRQ_PPE2TCL]);
+	free_irq(ab->dp.ppeds_irq[PPEDS_IRQ_PPE2TCL], ath12k_dp_get_ppe_ds_ctxt(ab));
+
+	disable_irq_nosync(ab->dp.ppeds_irq[PPEDS_IRQ_REO2PPE]);
+	free_irq(ab->dp.ppeds_irq[PPEDS_IRQ_REO2PPE], ath12k_dp_get_ppe_ds_ctxt(ab));
+
+	disable_irq_nosync(ab->dp.ppeds_irq[PPEDS_IRQ_PPE_WBM2SW_REL]);
+	free_irq(ab->dp.ppeds_irq[PPEDS_IRQ_PPE_WBM2SW_REL], ab);
+}
+#endif
+
 static int ath12k_pci_config_irq(struct ath12k_base *ab)
 {
 	struct ath12k_ce_pipe *ce_pipe;
@@ -1266,6 +1354,12 @@ static const struct ath12k_hif_ops ath12
 	.ce_irq_enable = ath12k_pci_hif_ce_irq_enable,
 	.ce_irq_disable = ath12k_pci_hif_ce_irq_disable,
 	.get_ce_msi_idx = ath12k_pci_get_ce_msi_idx,
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+	.ppeds_register_interrupts = ath12k_pci_ppeds_register_interrupts,
+	.ppeds_free_interrupts = ath12k_pci_ppeds_free_interrupts,
+	.ppeds_irq_enable = ath12k_pci_ppeds_irq_enable,
+	.ppeds_irq_disable = ath12k_pci_ppeds_irq_disable,
+#endif
 };
 
 static int ath12k_pci_probe(struct pci_dev *pdev,
--- a/drivers/net/wireless/ath/ath12k/pci.h
+++ b/drivers/net/wireless/ath/ath12k/pci.h
@@ -68,6 +68,12 @@
 #define QRTR_PCI_DOMAIN_NR_MASK		GENMASK(7, 4)
 #define QRTR_PCI_BUS_NUMBER_MASK	GENMASK(3, 0)
 
+enum ppeds_irq_type {
+	PPEDS_IRQ_PPE2TCL,
+	PPEDS_IRQ_REO2PPE,
+	PPEDS_IRQ_PPE_WBM2SW_REL,
+};
+
 struct ath12k_msi_user {
 	char *name;
 	int num_vectors;
@@ -133,4 +139,11 @@ void ath12k_pci_stop(struct ath12k_base
 int ath12k_pci_start(struct ath12k_base *ab);
 int ath12k_pci_power_up(struct ath12k_base *ab);
 void ath12k_pci_power_down(struct ath12k_base *ab);
+void ath12k_pci_ppeds_free_interrupts(struct ath12k_base *ab);
+int ath12k_pci_ppeds_register_interrupts(struct ath12k_base *ab, int type,
+					int vector, int ring_num);
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+void ath12k_pci_ppeds_irq_enable(struct ath12k_base *ab, enum ppeds_irq_type type);
+void ath12k_pci_ppeds_irq_disable(struct ath12k_base *ab, enum ppeds_irq_type type);
+#endif
 #endif /* ATH12K_PCI_H */
--- /dev/null
+++ b/drivers/net/wireless/ath/ath12k/ppe.c
@@ -0,0 +1,997 @@
+// SPDX-License-Identifier: BSD-3-Clause-Clear
+/*
+ * Copyright (c) 2023 Qualcomm Innovation Center, Inc. All rights reserved.
+ */
+#include "core.h"
+#include "dp_tx.h"
+#include "debug.h"
+#include "debugfs_sta.h"
+#include "hw.h"
+#include "peer.h"
+#include <ppe_ds_wlan.h>
+#include <ppe_vp_public.h>
+#include <ppe_drv_sc.h>
+#include <linux/dma-mapping.h>
+#include <asm/cacheflush.h>
+#include "hif.h"
+#include "ppe.h"
+
+static atomic_t num_ppeds_nodes;
+extern struct sk_buff *
+ath12k_dp_ppeds_tx_release_desc_nolock(struct ath12k_dp *dp,
+				struct ath12k_ppeds_tx_desc_info *tx_desc,
+				u8 ring_id);
+
+irqreturn_t ath12k_ds_ppe2tcl_irq_handler(int irq, void *ctxt)
+{
+	ppe_ds_ppe2tcl_wlan_handle_intr(ctxt);
+
+	return IRQ_HANDLED;
+}
+
+irqreturn_t ath12k_ds_reo2ppe_irq_handler(int irq, void *ctxt)
+{
+	ppe_ds_reo2ppe_wlan_handle_intr(ctxt);
+
+	return IRQ_HANDLED;
+}
+
+void *ath12k_dp_get_ppe_ds_ctxt(struct ath12k_base *ab)
+{
+	if (!ab || !ab->ppeds_handle)
+		return NULL;
+
+	return ppe_ds_wlan_get_intr_ctxt(ab->ppeds_handle);
+}
+
+static void ath12k_ppeds_set_tcl_prod_idx(ppe_ds_wlan_handle_t *ppeds_handle, u16 tcl_prod_idx)
+{
+	struct ath12k_base *ab = *(struct ath12k_base **)ppe_ds_wlan_priv(ppeds_handle);
+	struct ath12k_dp *dp = &ab->dp;
+	struct hal_srng *srng;
+
+	srng = &ab->hal.srng_list[dp->ppe2tcl_ring.ring_id];
+	if (!ab->stats_disable)
+		ab->ppeds_stats.tcl_prod_cnt++;
+
+	srng->u.src_ring.hp = tcl_prod_idx * srng->entry_size;
+	ath12k_hal_srng_access_end(ab, srng);
+}
+
+static u16 ath12k_ppeds_get_tcl_cons_idx(ppe_ds_wlan_handle_t *ppeds_handle)
+{
+	struct ath12k_base *ab = *(struct ath12k_base **)ppe_ds_wlan_priv(ppeds_handle);
+	struct ath12k_dp *dp = &ab->dp;
+	struct hal_srng *srng;
+	u32 tp;
+
+	if (!ab->stats_disable)
+		ab->ppeds_stats.tcl_cons_cnt++;
+
+	srng = &ab->hal.srng_list[dp->ppe2tcl_ring.ring_id];
+	tp = *(volatile u32 *)(srng->u.src_ring.tp_addr);
+
+	return tp / srng->entry_size;
+}
+
+static void ath12k_ppeds_set_reo_cons_idx(ppe_ds_wlan_handle_t *ppeds_handle,
+                                      u16 reo_cons_idx)
+{
+	struct ath12k_base *ab = *(struct ath12k_base **)ppe_ds_wlan_priv(ppeds_handle);
+	struct ath12k_dp *dp = &ab->dp;
+	struct hal_srng *srng;
+
+	srng = &ab->hal.srng_list[dp->reo2ppe_ring.ring_id];
+	if (!ab->stats_disable)
+		ab->ppeds_stats.reo_cons_cnt++;
+
+	srng->u.src_ring.hp = reo_cons_idx * srng->entry_size;
+	ath12k_hal_srng_access_end(ab, srng);
+}
+
+static u16 ath12k_ppeds_get_reo_prod_idx(ppe_ds_wlan_handle_t *ppeds_handle)
+{
+	struct ath12k_base *ab = *(struct ath12k_base **)ppe_ds_wlan_priv(ppeds_handle);
+	struct ath12k_dp *dp = &ab->dp;
+	struct hal_srng *srng;
+	u32 hp;
+
+	srng = &ab->hal.srng_list[dp->reo2ppe_ring.ring_id];
+	hp = *(volatile u32 *)(srng->u.dst_ring.hp_addr);
+ 	if (!ab->stats_disable)
+		ab->ppeds_stats.reo_prod_cnt++;
+	return hp / srng->entry_size;
+}
+
+/* enable/disable PPE2TCL irq */
+static inline void ath12k_ppeds_enable_srng_intr(ppe_ds_wlan_handle_t *ppeds_handle, bool enable)
+{
+	struct ath12k_base *ab = *(struct ath12k_base **)ppe_ds_wlan_priv(ppeds_handle);
+
+	if (enable) {
+		if (!ab->stats_disable)
+			ab->ppeds_stats.enable_intr_cnt++;
+
+		ath12k_hif_ppeds_irq_enable(ab, PPEDS_IRQ_PPE2TCL);
+	}
+	else {
+		if (!ab->stats_disable)
+			ab->ppeds_stats.disable_intr_cnt++;
+
+		ath12k_hif_ppeds_irq_disable(ab, PPEDS_IRQ_PPE2TCL);
+	}
+}
+
+int ath12k_dp_rx_bufs_replenish_ppeds(struct ath12k_base *ab,
+				      struct dp_rxdma_ring *rx_ring,
+				      int req_entries,
+				      enum hal_rx_buf_return_buf_manager mgr)
+{
+	struct hal_srng *rxdma_srng;
+	u32 *rxdma_desc;
+	u32 cookie;
+	dma_addr_t paddr;
+	struct sk_buff *skb;
+	struct ath12k_rx_desc_info *rx_desc, *cur;
+	int count = 0, num_remain;
+
+	rxdma_srng = &ab->hal.srng_list[rx_ring->refill_buf_ring.ring_id];
+
+	spin_lock_bh(&rxdma_srng->lock);
+	ath12k_hal_srng_access_begin(ab, rxdma_srng);
+
+	num_remain = req_entries;
+	while (num_remain > 0) {
+		spin_lock_bh(&ab->dp.rx_desc_lock);
+
+		rx_desc = list_first_entry_or_null(&ab->dp.rx_ppeds_reuse_list,
+						   struct ath12k_rx_desc_info,
+						   list);
+		if (!rx_desc) {
+			spin_unlock_bh(&ab->dp.rx_desc_lock);
+			break;
+		}
+
+		skb = rx_desc->skb;
+		if (!skb) {
+			ath12k_err(ab, "ppeds rx desc with no skb when reusing!\n");
+			spin_unlock_bh(&ab->dp.rx_desc_lock);
+			break;
+		}
+		cookie = rx_desc->cookie;
+		list_move_tail(&rx_desc->list, &ab->dp.rx_desc_used_list);
+		spin_unlock_bh(&ab->dp.rx_desc_lock);
+
+		rxdma_desc = ath12k_hal_srng_src_get_next_entry(ab, rxdma_srng);
+		if (!rxdma_desc) {
+			/* Remove desc from used list when no rxdma entry is available */
+			spin_lock_bh(&ab->dp.rx_desc_lock);
+			list_move_tail(&rx_desc->list, &ab->dp.rx_ppeds_reuse_list);
+			spin_unlock_bh(&ab->dp.rx_desc_lock);
+			break;
+		}
+
+		paddr = ATH12K_SKB_RXCB(skb)->paddr;
+		ath12k_hal_rx_buf_addr_info_set(rxdma_desc, paddr, cookie, mgr);
+
+		num_remain--;
+		count++;
+	}
+        ath12k_hal_srng_access_end(ab, rxdma_srng);
+        spin_unlock_bh(&rxdma_srng->lock);
+
+	if (!ab->stats_disable)
+		ab->ppeds_stats.num_rx_desc_reused += count;
+
+	if (count == req_entries)
+		return 0;
+
+	/* move any remaining descriptors to free list */
+	count = 0;
+	while (num_remain) {
+		spin_lock_bh(&ab->dp.rx_desc_lock);
+		cur = list_first_entry_or_null(&ab->dp.rx_ppeds_reuse_list,
+					       struct ath12k_rx_desc_info,
+					       list);
+		if (!cur) {
+			/* break the loop as soon as list is empty */
+			spin_unlock_bh(&ab->dp.rx_desc_lock);
+			break;
+		}
+
+		skb = cur->skb;
+		cur->skb= NULL;
+		list_move_tail(&cur->list, &ab->dp.rx_desc_free_list);
+		spin_unlock_bh(&ab->dp.rx_desc_lock);
+		num_remain--;
+		count++;
+
+		if (!skb) {
+			ath12k_err(ab, "ppeds rx desc with no skb when freeing\n");
+			continue;
+		}
+
+		/* When recycled_for_ds is set, packet is used by DS rings and never has
+		 * touched by host. So, buffer unmap can be skipped. */
+		if (!skb->recycled_for_ds) {
+			dmac_inv_range_no_dsb(skb->data, skb->data + (skb->len +
+					      skb_tailroom(skb)));
+			dma_unmap_single_attrs(ab->dev, ATH12K_SKB_RXCB(skb)->paddr,
+					       skb->len + skb_tailroom(skb),
+					       DMA_FROM_DEVICE, DMA_ATTR_SKIP_CPU_SYNC);
+		}
+
+		skb->recycled_for_ds = 0;
+		skb->fast_recycled = 0;
+		dev_kfree_skb_any(skb);
+	}
+
+	if (!ab->stats_disable)
+		ab->ppeds_stats.num_rx_desc_freed += count;
+
+	return 0;
+}
+
+static void ath12k_ppeds_release_rx_desc(ppe_ds_wlan_handle_t *ppeds_handle,
+                                        struct ppe_ds_wlan_rxdesc_elem *arr, u16 count)
+{
+	struct ath12k_base *ab = *(struct ath12k_base **)ppe_ds_wlan_priv(ppeds_handle);
+	struct ath12k_base *src_ab = NULL;
+	u32 rx_bufs_reaped[ATH12K_MAX_SOCS] = {0};
+	struct ath12k_rx_desc_info *rx_desc;
+	struct dp_rxdma_ring *rx_ring;
+	int chip_id;
+	int i = 0;
+
+	if (!ab->stats_disable)
+		ab->ppeds_stats.release_rx_desc_cnt += count;
+
+	for (i = 0; i < count; i++) {
+		rx_desc = (struct ath12k_rx_desc_info *)arr[i].cookie;
+		if (rx_desc == NULL) {
+			ath12k_err(ab,"error: rx desc is null\n");
+			continue;
+		}
+		src_ab = rx_desc->ab;
+		/* TODO: review split phy */
+		rx_bufs_reaped[src_ab->chip_id]++;
+
+		spin_lock_bh(&src_ab->dp.rx_desc_lock);
+		list_move_tail(&rx_desc->list, &src_ab->dp.rx_ppeds_reuse_list);
+		spin_unlock_bh(&src_ab->dp.rx_desc_lock);
+	}
+
+	for (chip_id = 0; chip_id < ATH12K_MAX_SOCS; chip_id++) {
+		if (!rx_bufs_reaped[chip_id])
+			continue;
+
+		src_ab = ab->ag->ab[chip_id];
+		rx_ring = &src_ab->dp.rx_refill_buf_ring;
+		ath12k_dp_rx_bufs_replenish_ppeds(src_ab, rx_ring,
+						  rx_bufs_reaped[chip_id],
+						  src_ab->hw_params->hal_params->rx_buf_rbm);
+	}
+
+	return;
+}
+
+static
+void ath12k_ppeds_release_tx_desc_single(ppe_ds_wlan_handle_t *ppeds_handle,
+                                     u32 cookie)
+{
+	struct ath12k_base *ab = *(struct ath12k_base **)ppe_ds_wlan_priv(ppeds_handle);
+
+	if (!ab->stats_disable)
+		ab->ppeds_stats.release_tx_single_cnt++;
+
+        return;
+}
+
+static u32 ath12k_ppeds_get_batched_tx_desc(ppe_ds_wlan_handle_t *ppeds_handle,
+                                      struct ppe_ds_wlan_txdesc_elem *arr,
+                                      u32 num_buff_req,
+                                      u32 buff_size,
+                                      u32 headroom)
+{
+	struct ath12k_base *ab = *(struct ath12k_base **)ppe_ds_wlan_priv(ppeds_handle);
+	struct ath12k_dp *dp = &ab->dp;
+	int i;
+	int allocated = 0;
+	struct sk_buff *skb = NULL;
+	int flags = GFP_ATOMIC;
+	dma_addr_t paddr;
+	struct ath12k_ppeds_tx_desc_info *tx_desc = NULL;
+
+#if LINUX_VERSION_IS_GEQ(4,4,0)
+	flags = flags & ~__GFP_KSWAPD_RECLAIM;
+#endif
+
+	spin_lock_bh(&dp->ppeds_tx_desc_lock[ATH12K_PPEDS_DEFAULT_POOL_ID]);
+	for (i = 0; i < num_buff_req; i++) {
+		tx_desc = ath12k_dp_ppeds_tx_assign_desc_nolock(dp, ATH12K_PPEDS_DEFAULT_POOL_ID);
+		if (unlikely(!tx_desc)) {
+			ath12k_err(ab, "ran out of ppeds tx desc!\n");
+			dsb(st);
+			break;
+		}
+
+		/* allocate new skb only if one was not already found from reuse list */
+		if (!tx_desc->skb) {
+			/* In skb recycler, if recyler module allocates the buffers
+			 * already used by DS module to DS, then memzero, shinfo
+			 * reset can be avoided, since the DS packets were not
+			 * processed by SW
+			 */
+			skb = __netdev_alloc_skb_no_skb_reset(NULL, buff_size, flags);
+			if (unlikely(!skb)) {
+				ath12k_dp_ppeds_tx_release_desc_nolock(dp, tx_desc,
+								ATH12K_PPEDS_DEFAULT_POOL_ID);
+				break;
+			}
+
+			skb_reserve(skb, headroom);
+			if (!skb->recycled_for_ds) {
+				dmac_inv_range_no_dsb((void *)skb->data,
+						(void *)skb->data + buff_size - headroom);
+				skb->recycled_for_ds = 1;
+			}
+
+			paddr = virt_to_phys(skb->data);
+
+			tx_desc->skb = skb;
+			tx_desc->paddr = paddr;
+		}
+
+		arr[i].opaque_lo = tx_desc->desc_id;
+		arr[i].opaque_hi = 0;
+		arr[i].buff_addr = tx_desc->paddr;
+		allocated++;
+	}
+	spin_unlock_bh(&dp->ppeds_tx_desc_lock[ATH12K_PPEDS_DEFAULT_POOL_ID]);
+
+	dsb(st);
+
+	if (!ab->stats_disable) {
+		ab->ppeds_stats.get_tx_desc_cnt++;
+		ab->ppeds_stats.tx_desc_allocated += allocated;
+	}
+
+	return allocated;
+}
+
+static int ath12k_dp_ppeds_tx_comp_poll(struct napi_struct *napi, int budget)
+{
+	struct ath12k_base *ab = container_of(napi, struct ath12k_base, ppeds_napi_ctxt.napi);
+	int total_budget = (budget << 2) - 1;
+	int work_done;
+
+	work_done = ath12k_ppeds_tx_completion_handler(ab, total_budget);
+	if (!ab->stats_disable)
+		ab->ppeds_stats.tx_desc_freed += work_done;
+
+	work_done = (work_done + 1) >> 2;
+
+	if ( budget > work_done){
+		napi_complete(napi);
+		ath12k_hif_ppeds_irq_enable(ab, PPEDS_IRQ_PPE_WBM2SW_REL);
+	}
+
+	return (work_done > budget) ? budget : work_done;
+}
+
+/* PPE-DS release interrupt */
+irqreturn_t ath12k_dp_ppeds_handle_tx_comp(int irq, void *ctxt)
+{
+	struct ath12k_base *ab = (struct ath12k_base *)ctxt;
+	struct ath12k_ppeds_napi *napi_ctxt = &ab->ppeds_napi_ctxt;
+
+	ath12k_hif_ppeds_irq_disable(ab, PPEDS_IRQ_PPE_WBM2SW_REL);
+	napi_schedule(&napi_ctxt->napi);
+	return IRQ_HANDLED;
+}
+
+int ath12k_ppe_napi_budget = NAPI_POLL_WEIGHT;
+static int ath12k_dp_ppeds_add_napi_ctxt(struct ath12k_base *ab)
+{
+	struct ath12k_ppeds_napi *napi_ctxt = &ab->ppeds_napi_ctxt;
+	int ret;
+
+	ret = init_dummy_netdev((struct net_device *)&napi_ctxt->ndev);
+	if (ret){
+		ath12k_err(ab,"dummy netdev init fail\n");
+		return -ENOSR;
+	}
+	netif_napi_add(&napi_ctxt->ndev, &napi_ctxt->napi,
+                ath12k_dp_ppeds_tx_comp_poll, ath12k_ppe_napi_budget);
+
+	return 0;
+}
+
+static void ath12k_dp_ppeds_del_napi_ctxt(struct ath12k_base *ab)
+{
+	struct ath12k_ppeds_napi *napi_ctxt = &ab->ppeds_napi_ctxt;
+
+	netif_napi_del(&napi_ctxt->napi);
+	ath12k_dbg(ab, ATH12K_DBG_PPE, " ath12k_dp_ppeds_del_napi_ctxt success\n");
+}
+
+static struct ppe_ds_wlan_ops ppeds_ops = {
+	.get_tx_desc_many = ath12k_ppeds_get_batched_tx_desc,
+	.release_tx_desc_single = ath12k_ppeds_release_tx_desc_single,
+	.enable_tx_consume_intr = ath12k_ppeds_enable_srng_intr,
+	.set_tcl_prod_idx  = ath12k_ppeds_set_tcl_prod_idx,
+	.set_reo_cons_idx = ath12k_ppeds_set_reo_cons_idx,
+	.get_tcl_cons_idx = ath12k_ppeds_get_tcl_cons_idx,
+	.get_reo_prod_idx = ath12k_ppeds_get_reo_prod_idx,
+	.release_rx_desc = ath12k_ppeds_release_rx_desc,
+};
+
+void ath12k_dp_peer_ppeds_route_setup(struct ath12k *ar, struct ath12k_link_vif *arvif,
+				      struct ath12k_link_sta *arsta)
+{
+	struct ath12k_base *ab = ar->ab;
+	u32 service_code = PPE_DRV_SC_SPF_BYPASS;
+	int ppe_routing_enable = 1;
+	u32 priority_valid = 0, src_info = arvif->vif->ppe_vp_num;
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags) ||
+	    src_info == -1)
+		return;
+
+	ath12k_wmi_config_peer_ppeds_routing(ar, arsta->addr, arvif->vdev_id,
+			service_code, priority_valid, src_info,
+			ppe_routing_enable);
+}
+
+static int ath12k_dp_ppeds_alloc_ppe_vp_profile(struct ath12k_base *ab,
+						struct ath12k_dp_ppe_vp_profile **vp_profile)
+{
+	int i;
+
+	mutex_lock(&ab->ppe_vp_tbl_lock);
+	if (ab->num_ppe_vp_profiles == PPE_VP_ENTRIES_MAX) {
+		mutex_unlock(&ab->ppe_vp_tbl_lock);
+		ath12k_err(ab, "Maximum ppe_vp count reached for soc\n");
+		return -ENOSR;
+	}
+
+	ab->num_ppe_vp_profiles++;
+
+	for (i = 0; i < PPE_VP_ENTRIES_MAX; i++) {
+		if (!ab->dp.ppe_vp_profile[i].is_configured)
+			break;
+	}
+
+	if (i == PPE_VP_ENTRIES_MAX) {
+		WARN_ONCE(1, "All ppe vp profile entries are in use!");
+		return -ENOSR;
+	}
+
+	ab->dp.ppe_vp_profile[i].is_configured = true;
+	*vp_profile = &ab->dp.ppe_vp_profile[i];
+	mutex_unlock(&ab->ppe_vp_tbl_lock);
+
+	return i;
+}
+
+static void
+ath12k_dp_ppeds_dealloc_ppe_vp_profile(struct ath12k_base *ab,
+					 int ppe_vp_profile_idx)
+{
+	if (ppe_vp_profile_idx < 0 || ppe_vp_profile_idx >= PPE_VP_ENTRIES_MAX) {
+		ath12k_err(ab, "Invalid PPE VP profile free index");
+		return;
+	}
+
+	mutex_lock(&ab->ppe_vp_tbl_lock);
+	if (!ab->dp.ppe_vp_profile[ppe_vp_profile_idx].is_configured) {
+		mutex_unlock(&ab->ppe_vp_tbl_lock);
+		ath12k_err(ab, "PPE VP profile is not configured at idx:%d", ppe_vp_profile_idx);
+		return;
+	}
+
+	ab->dp.ppe_vp_profile[ppe_vp_profile_idx].is_configured = false;
+	ab->num_ppe_vp_profiles--;
+	mutex_unlock(&ab->ppe_vp_tbl_lock);
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "ath12k_dp_ppeds_dealloc_ppe_vp_profile success\n");
+}
+
+static int ath12k_dp_ppeds_alloc_vp_tbl_entry(struct ath12k_base *ab)
+{
+	int i;
+
+	mutex_lock(&ab->ppe_vp_tbl_lock);
+	if (ab->num_ppe_vp_profiles == PPE_VP_ENTRIES_MAX) {
+		mutex_unlock(&ab->ppe_vp_tbl_lock);
+		ath12k_err(ab, "Maximum ppe_vp count reached for soc\n");
+		return -ENOSR;
+	}
+
+	ab->num_ppe_vp_entries++;
+
+	for (i = 0; i < PPE_VP_ENTRIES_MAX; i++) {
+		if (!ab->ppe_vp_tbl_registered[i])
+			break;
+	}
+
+	if (i == PPE_VP_ENTRIES_MAX) {
+		WARN_ONCE(1, "All ppe vp table entries are in use!");
+		return -ENOSR;
+	}
+
+	ab->ppe_vp_tbl_registered[i] = true;
+	mutex_unlock(&ab->ppe_vp_tbl_lock);
+
+	return i;
+}
+
+static void ath12k_dp_ppeds_dealloc_vp_tbl_entry(struct ath12k_base *ab,
+						 int ppe_vp_num_idx)
+{
+	u32 vp_cfg = 0;
+
+	if (ppe_vp_num_idx < 0 || ppe_vp_num_idx >= PPE_VP_ENTRIES_MAX) {
+		ath12k_err(ab, "Invalid PPE VP free index");
+		return;
+	}
+
+	ath12k_hal_tx_set_ppe_vp_entry(ab, vp_cfg, ppe_vp_num_idx);
+
+	mutex_lock(&ab->ppe_vp_tbl_lock);
+	if (!ab->ppe_vp_tbl_registered[ppe_vp_num_idx]) {
+		mutex_unlock(&ab->ppe_vp_tbl_lock);
+		ath12k_err(ab, "PPE VP is not configured at idx:%d", ppe_vp_num_idx);
+		return;
+	}
+
+	ab->ppe_vp_tbl_registered[ppe_vp_num_idx] = false;
+	ab->num_ppe_vp_entries--;
+	mutex_unlock(&ab->ppe_vp_tbl_lock);
+}
+
+static int ath12k_dp_ppeds_alloc_vp_search_idx_tbl_entry(struct ath12k_base *ab)
+{
+	int i;
+
+	mutex_lock(&ab->ppe_vp_tbl_lock);
+	if (ab->num_ppe_vp_profiles == PPE_VP_ENTRIES_MAX) {
+		mutex_unlock(&ab->ppe_vp_tbl_lock);
+		ath12k_err(ab, "Maximum ppe_vp count reached for soc\n");
+		return -ENOSR;
+	}
+
+	ab->num_ppe_vp_search_idx_entries++;
+
+	for (i = 0; i < PPE_VP_ENTRIES_MAX; i++) {
+		if (!ab->ppe_vp_search_idx_tbl_set[i])
+			break;
+	}
+
+	if (i == PPE_VP_ENTRIES_MAX) {
+		WARN_ONCE(1, "All ppe vp table entries are in use!");
+		return -ENOSR;
+	}
+
+	ab->ppe_vp_search_idx_tbl_set[i] = true;
+	mutex_unlock(&ab->ppe_vp_tbl_lock);
+
+	return i;
+}
+
+static void
+ath12k_dp_ppeds_dealloc_vp_search_idx_tbl_entry(struct ath12k_base *ab,
+                                              int ppe_vp_search_idx)
+{
+	if (ppe_vp_search_idx < 0 || ppe_vp_search_idx >= PPE_VP_ENTRIES_MAX) {
+		ath12k_err(ab,"Invalid PPE VP search table free index");
+		return;
+	}
+
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "dealloc ppe_vp_search_idx %d\n", ppe_vp_search_idx);
+
+	mutex_lock(&ab->ppe_vp_tbl_lock);
+	if (!ab->ppe_vp_search_idx_tbl_set[ppe_vp_search_idx]) {
+		mutex_unlock(&ab->ppe_vp_tbl_lock);
+		ath12k_err(ab,"PPE VP search idx table is not configured at idx:%d", ppe_vp_search_idx);
+		return;
+	}
+
+	ab->ppe_vp_search_idx_tbl_set[ppe_vp_search_idx] = false;
+	ab->num_ppe_vp_search_idx_entries--;
+	mutex_unlock(&ab->ppe_vp_tbl_lock);
+
+	return;
+}
+
+static void ath12k_dp_ppeds_setup_vp_entry(struct ath12k_base *ab,
+					   struct ath12k *ar,
+					   struct ath12k_link_vif *arvif,
+					   struct ath12k_dp_ppe_vp_profile *ppe_vp_profile)
+{
+	u32 ppe_vp_config = 0;
+
+	ppe_vp_config |=
+		u32_encode_bits(ppe_vp_profile->vp_num,
+				HAL_TX_PPE_VP_CFG_VP_NUM) |
+		u32_encode_bits(ppe_vp_profile->search_idx_reg_num,
+				HAL_TX_PPE_VP_CFG_SRCH_IDX_REG_NUM) |
+		u32_encode_bits(ppe_vp_profile->use_ppe_int_pri,
+				HAL_TX_PPE_VP_CFG_USE_PPE_INT_PRI) |
+		u32_encode_bits(ppe_vp_profile->to_fw,
+				HAL_TX_PPE_VP_CFG_TO_FW) |
+		u32_encode_bits(ppe_vp_profile->drop_prec_enable,
+				HAL_TX_PPE_VP_CFG_DROP_PREC_EN) |
+		u32_encode_bits(arvif->bank_id, HAL_TX_PPE_VP_CFG_BANK_ID) |
+		u32_encode_bits(ar->lmac_id, HAL_TX_PPE_VP_CFG_PMAC_ID) |
+		u32_encode_bits(arvif->vdev_id, HAL_TX_PPE_VP_CFG_VDEV_ID);
+
+	ath12k_hal_tx_set_ppe_vp_entry(ab, ppe_vp_config,
+				       ppe_vp_profile->ppe_vp_num_idx);
+
+	ath12k_dbg(ab, ATH12K_DBG_PPE,
+		   "ppeds_setup_vp_entry vp_num %d search_idx_reg_num %d" \
+		   " use_ppe_int_pri %d to_fw %d drop_prec_enable %d bank_id %d" \
+		   " lmac_id %d vdev_id %d ppe_vp_num_idx %d\n",
+		   ppe_vp_profile->vp_num, ppe_vp_profile->search_idx_reg_num,
+		   ppe_vp_profile->use_ppe_int_pri, ppe_vp_profile->to_fw,
+		   ppe_vp_profile->drop_prec_enable, arvif->bank_id, ar->lmac_id,
+		   arvif->vdev_id, ppe_vp_profile->ppe_vp_num_idx);
+	return;
+}
+
+int ath12k_mac_op_ppeds_attach_vdev(struct ieee80211_hw *hw,
+				struct ieee80211_vif *vif,
+				void *vp_arg, int *ppe_vp_num,
+				struct ieee80211_ppe_vp_ds_params *vp_params)
+{
+	struct ath12k_hw *ah = hw->priv;
+	struct ath12k_vif *ahvif = (void *)vif->drv_priv;
+	//TODO: handle MLO
+	struct ath12k_link_vif *arvif = &ahvif->link[0];
+	struct ath12k *ar = ah->radio;
+	//TODO: Handle split phy
+	struct ath12k_base *ab = ar->ab;
+	struct ath12k_dp_ppe_vp_profile *vp_profile = NULL;
+	int ppe_vp_profile_idx, ppe_vp_idx, vp_num;
+	int ppe_vp_search_tbl_idx = -1;
+	int vdev_id = arvif->vdev_id;
+	int ret;
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags)) {
+		ppe_vp_num = -1;
+		return -ENOSR;
+	}
+
+	if (!ab->ppeds_handle) {
+		ath12k_err(ab, "DS not enabled on this chip\n");
+		return -EINVAL;
+	}
+
+	if (vif->type != NL80211_IFTYPE_AP) {
+		return -EINVAL;
+	}
+
+	vp_num = ppe_ds_wlan_vp_alloc(ab->ppeds_handle, vp_params->dev, vp_arg);
+	if (vp_num < 0) {
+		ath12k_err(ab," vp alloc failed\n");
+		return -EFAULT;
+	}
+
+	/*Allocate a ppe vp profile for a vap */
+	ppe_vp_profile_idx = ath12k_dp_ppeds_alloc_ppe_vp_profile(ab, &vp_profile);
+	if (!vp_profile) {
+		ath12k_err(ab, "Failed to allocate PPE VP idx for vdev_id:%d", vdev_id);
+		ret = -ENOSR;
+		goto vp_free;
+	}
+
+	ppe_vp_idx = ath12k_dp_ppeds_alloc_vp_tbl_entry(ab);
+	if (ppe_vp_idx < 0) {
+		ath12k_err(ab, "Failed to allocate PPE VP idx for vdev_id:%d", vdev_id);
+		ret = -ENOSR;
+		goto dealloc_vp_profile;
+	}
+
+	if (vif->type == NL80211_IFTYPE_STATION) {
+		ppe_vp_search_tbl_idx = ath12k_dp_ppeds_alloc_vp_search_idx_tbl_entry(ab);
+		if (ppe_vp_search_tbl_idx < 0) {
+			ath12k_err(ab,
+				   "Failed to allocate PPE VP search table idx for vdev_id:%d", vdev_id);
+			ret = -ENOSR;
+			goto dealloc_vp_tbl_entry;
+		}
+		vp_profile->search_idx_reg_num = ppe_vp_search_tbl_idx;
+	}
+
+	vp_profile->vp_num = vp_num;
+	vp_profile->ppe_vp_num_idx = ppe_vp_idx;
+	vp_profile->to_fw = 0;
+	vp_profile->use_ppe_int_pri = 0;
+	vp_profile->drop_prec_enable = 0;
+
+	/* For the sta mode fill up the index reg number */
+	ath12k_dp_ppeds_setup_vp_entry(ab, ar, arvif, vp_profile);
+
+	vp_params->ppe_vp_profile_idx = ppe_vp_profile_idx;
+	*ppe_vp_num = vp_num;
+	ath12k_dbg(ab, ATH12K_DBG_PPE,
+		   "PPEDS vdev attach success vpnum %d ppe_vp_idx %d ppe_vp_profile_idx %d\n",
+		   vp_num, ppe_vp_idx, ppe_vp_profile_idx);
+
+	return 0;
+
+dealloc_vp_tbl_entry:
+	ath12k_dp_ppeds_dealloc_vp_tbl_entry(ab, vp_profile->ppe_vp_num_idx);
+dealloc_vp_profile:
+	ath12k_dp_ppeds_dealloc_ppe_vp_profile(ab, ppe_vp_profile_idx);
+vp_free:
+	ppe_ds_wlan_vp_free(ab->ppeds_handle, vp_num);
+
+	return ret;
+}
+
+void ath12k_mac_op_ppeds_detach_vdev(struct ieee80211_hw *hw,
+				     struct ieee80211_vif *vif,
+				     struct ieee80211_ppe_vp_ds_params *vp_params)
+{
+	struct ath12k_hw *ah = hw->priv;
+	struct ath12k *ar = ah->radio;
+	struct ath12k_base *ab = ar->ab;
+	struct ath12k_vif *ahvif = (void *)vif->drv_priv;
+	struct ath12k_link_vif *arvif = &ahvif->link[0];
+	struct ath12k_dp_ppe_vp_profile *vp_profile;
+	int ppe_vp_profile_idx = -1;
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return;
+
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "PPEDS vdev detach\n");
+	ppe_vp_profile_idx = vp_params->ppe_vp_profile_idx;
+
+	vp_profile = &ab->dp.ppe_vp_profile[ppe_vp_profile_idx];
+	if (!vp_profile->is_configured) {
+		ath12k_err(ab, "Invalid PPE VP profile for vdev_id:%d",
+			   arvif->vdev_id);
+		return;
+	}
+
+	ppe_ds_wlan_vp_free(ab->ppeds_handle, vp_profile->vp_num);
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "ppe_ds_wlan_vp_free\n");
+
+	/* For STA mode ast index table reg also needs to be cleaned */
+	if (vif->type == NL80211_IFTYPE_STATION)
+		ath12k_dp_ppeds_dealloc_vp_search_idx_tbl_entry(ab, vp_profile->search_idx_reg_num);
+
+	ath12k_dp_ppeds_dealloc_vp_tbl_entry(ab, vp_profile->ppe_vp_num_idx);
+	ath12k_dp_ppeds_dealloc_ppe_vp_profile(ab, ppe_vp_profile_idx);
+	ath12k_dbg(ab, ATH12K_DBG_PPE,
+		   "PPEDS vdev detach success vpnum %d  ppe_vp_profile_idx %d\n",
+		   vp_profile->vp_num, ppe_vp_profile_idx);
+}
+
+int ath12k_ppeds_attach(struct ath12k_base *ab)
+{
+	struct ath12k_base **abptr;
+	int i, ret;
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return 0;
+
+	ath12k_dp_ppeds_tx_cmem_init(ab, &ab->dp);
+	ret = ath12k_dp_cc_ppeds_desc_init(ab);
+	if (ret) {
+		ath12k_err(ab, "Failed to allocate ppe-ds descriptors\n");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < PPE_VP_ENTRIES_MAX; i++) {
+		ab->ppe_vp_tbl_registered[i] = 0;
+		ab->ppe_vp_search_idx_tbl_set[i] = 0;
+		ab->dp.ppe_vp_profile[i].is_configured = false;
+	}
+
+	ab->ppeds_handle = ppe_ds_wlan_inst_alloc(&ppeds_ops, sizeof(struct ath12k_base *));
+	if (!ab->ppeds_handle) {
+		ath12k_err(ab, "Failed to allocate ppeds soc instance\n");
+		ath12k_ppeds_detach(ab);
+		return -1;
+	}
+
+	WARN_ON(ab->ppeds_node_idx != -1);
+	/* dec ppeds_node_idx to start from 0 */
+	ab->ppeds_node_idx = atomic_inc_return(&num_ppeds_nodes) - 1;
+
+	ath12k_dbg(ab, ATH12K_DBG_PPE,
+		   "PPEDS attach ab %px ppeds_handle %px ppeds_node_idx %d num_ppeds_nodes %d\n",
+		   ab, ab->ppeds_handle, ab->ppeds_node_idx, atomic_read(&num_ppeds_nodes));
+
+	ret = ath12k_dp_ppeds_add_napi_ctxt(ab);
+	if (ret)
+		return -ENOSR;
+
+	abptr = (struct ath12k_base **)ppe_ds_wlan_priv(ab->ppeds_handle);
+	*abptr = ab;
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "PPEDS attach success\n");
+
+	return 0;
+}
+
+int ath12k_ppeds_detach(struct ath12k_base *ab)
+{
+	int i;
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return 0;
+
+	if (!ab->ppeds_handle)
+		return 0;
+
+	ath12k_dp_ppeds_del_napi_ctxt(ab);
+	ath12k_dp_cc_ppeds_desc_cleanup(ab);
+
+	/* free ppe-ds interrupts before freeing the instance */
+	ath12k_hif_ppeds_free_interrupts(ab);
+	ppe_ds_wlan_inst_free(ab->ppeds_handle);
+	ab->ppeds_handle = NULL;
+	ab->ppeds_node_idx = -1;
+	atomic_dec(&num_ppeds_nodes);
+
+	for (i = 0; i < PPE_VP_ENTRIES_MAX; i++) {
+		ab->ppe_vp_tbl_registered[i] = 0;
+		ab->ppe_vp_search_idx_tbl_set[i] = 0;
+		ab->dp.ppe_vp_profile[i].is_configured = false;
+	}
+
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "PPEDS detach success\n");
+
+	return 0;
+}
+
+int ath12k_dp_ppeds_start(struct ath12k_base *ab)
+{
+	struct ath12k_ppeds_napi *napi_ctxt = &ab->ppeds_napi_ctxt;
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return 0;
+
+	if (!ab->ppeds_handle) {
+		ath12k_err(ab, "ppeds_handle is null");
+		return -EINVAL;
+	}
+
+	napi_enable(&napi_ctxt->napi);
+
+	ab->ppeds_stopped = 0;
+
+	if (ppe_ds_wlan_inst_start(ab->ppeds_handle) != 0)
+		return -EINVAL;
+
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "PPEDS start success\n");
+	return 0;
+}
+
+void ath12k_dp_ppeds_stop(struct ath12k_base *ab)
+{
+	struct ath12k_ppeds_napi *napi_ctxt = &ab->ppeds_napi_ctxt;
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return;
+
+	if (!ab->ppeds_handle || ab->ppeds_stopped) {
+		ath12k_warn(ab, "PPE DS aleady stopped!\n");
+		return;
+	}
+
+	ab->ppeds_stopped = 1;
+	napi_disable(&napi_ctxt->napi);
+
+	ppe_ds_wlan_inst_stop(ab->ppeds_handle);
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "PPEDS stop success\n");
+
+}
+
+int ath12k_dp_ppeds_register_soc(struct ath12k_dp *dp)
+{
+	struct ath12k_base *ab = dp->ab;
+	struct hal_srng *ppe2tcl_ring, *reo2ppe_ring;
+	struct ppe_ds_wlan_reg_info reg_info = {0};
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return 0;
+
+	if (!ab->ppeds_handle) {
+		ath12k_err(ab, "ppeds not attached");
+		return -EINVAL;
+	}
+
+	ppe2tcl_ring = &ab->hal.srng_list[dp->ppe2tcl_ring.ring_id];
+	reo2ppe_ring =  &ab->hal.srng_list[dp->reo2ppe_ring.ring_id];
+
+	reg_info.ppe2tcl_ba = dp->ppe2tcl_ring.paddr;
+	reg_info.reo2ppe_ba = dp->reo2ppe_ring.paddr;
+	reg_info.ppe2tcl_num_desc = ppe2tcl_ring->num_entries;
+	reg_info.reo2ppe_num_desc = reo2ppe_ring->num_entries;
+	if (ppe_ds_wlan_inst_register(ab->ppeds_handle, &reg_info) != true) {
+	        ath12k_err(ab, "ppeds not attached");
+		return -EINVAL;
+	}
+
+	ab->ppeds_int_mode_enabled = reg_info.ppe_ds_int_mode_enabled;
+
+	ath12k_dbg(ab, ATH12K_DBG_PPE, "PPEDS register soc-success");
+
+        return 0;
+}
+
+int ath12k_dp_srng_ppeds_setup(struct ath12k_base *ab)
+{
+	struct ath12k_dp *dp = &ab->dp;
+	int ret, size;
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return 0;
+
+	/* TODO: retain and use ring idx fetched from ppe for avoiding edma hang during SSR */
+	ret = ath12k_dp_srng_setup(ab, &dp->reo2ppe_ring, HAL_REO2PPE,
+			0, 0, DP_REO2PPE_RING_SIZE);
+	if (ret) {
+		ath12k_warn(ab, "failed to set up reo2ppe ring :%d\n", ret);
+		goto err;
+	}
+
+	ath12k_hal_reo_config_reo2ppe_dest_info(ab);
+
+	/* TODO: retain and use ring idx fetched from ppe for avoiding edma hang during SSR */
+	ret = ath12k_dp_srng_setup(ab, &dp->ppe2tcl_ring, HAL_PPE2TCL,
+			0, 0, DP_PPE2TCL_RING_SIZE);
+	if (ret) {
+		ath12k_warn(ab, "failed to set up ppe2tcl ring :%d\n", ret);
+		goto err;
+	}
+
+	/* TODO: retain and use ring idx fetched from ppe for avoiding edma hang during SSR */
+	ret = ath12k_dp_srng_setup(ab, &dp->ppeds_comp_ring.ppe_wbm2sw_ring,
+				   HAL_WBM2SW_RELEASE,
+				   HAL_WBM2SW_PPEDS_TX_CMPLN_RING_NUM, 0,
+				   DP_PPE_WBM2SW_RING_SIZE);
+	if (ret) {
+		ath12k_warn(ab,
+			    "failed to set up wbm2sw ippeds tx completion ring :%d\n",
+			    ret);
+		goto err;
+	}
+	ath12k_hal_tx_config_rbm_mapping(ab, 0,
+					 HAL_WBM2SW_PPEDS_TX_CMPLN_MAP_ID,
+					 HAL_PPE2TCL);
+
+	size = sizeof(struct hal_wbm_release_ring_tx) * DP_TX_COMP_RING_SIZE;
+	dp->ppeds_comp_ring.tx_status_head = 0;
+	dp->ppeds_comp_ring.tx_status_tail = DP_TX_COMP_RING_SIZE - 1;
+	dp->ppeds_comp_ring.tx_status = kmalloc(size, GFP_KERNEL);
+	if (!dp->ppeds_comp_ring.tx_status) {
+		ath12k_err(ab, "PPE tx status completion buffer alloc failed\n");
+		goto err;
+	}
+
+	ret = ath12k_dp_ppeds_register_soc(dp);
+	if (ret) {
+		ath12k_err(ab, "ppeds registration failed\n");
+		goto err;
+	}
+
+err:
+	/* caller takes care of calling ath12k_dp_srng_ppeds_cleanup */
+	return ret;
+}
+
+void ath12k_dp_srng_ppeds_cleanup(struct ath12k_base *ab)
+{
+	struct ath12k_dp *dp = &ab->dp;
+
+	if (!test_bit(ATH12K_FLAG_PPE_DS_ENABLED, &ab->dev_flags))
+		return;
+
+	ath12k_dp_srng_cleanup(ab, &dp->ppe2tcl_ring);
+	ath12k_dp_srng_cleanup(ab, &dp->reo2ppe_ring);
+	ath12k_dp_srng_cleanup(ab, &dp->ppeds_comp_ring.ppe_wbm2sw_ring);
+}
--- /dev/null
+++ b/drivers/net/wireless/ath/ath12k/ppe.h
@@ -0,0 +1,43 @@
+/* SPDX-License-Identifier: BSD-3-Clause-Clear */
+/*
+ * Copyright (c) 2023 Qualcomm Innovation Center, Inc. All rights reserved.
+ */
+
+#ifndef ATH12K_PPE_H
+#define ATH12K_PPE_H
+
+struct ath12k_dp_ppe_vp_profile {
+        bool is_configured;
+        u8 vp_num;
+        u8 ppe_vp_num_idx;
+        u8 search_idx_reg_num;
+        u8 drop_prec_enable;
+        u8 to_fw;
+        u8 use_ppe_int_pri;
+};
+
+#define ATH12K_PPEDS_DEFAULT_POOL_ID 0
+
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+void ath12k_dp_srng_ppeds_cleanup(struct ath12k_base *ab);
+int ath12k_dp_srng_ppeds_setup(struct ath12k_base *ab);
+int ath12k_dp_ppeds_register_soc(struct ath12k_dp *dp);
+void ath12k_dp_ppeds_stop(struct ath12k_base *ab);
+int ath12k_dp_ppeds_start(struct ath12k_base *ab);
+int ath12k_ppeds_detach( struct ath12k_base *ab);
+int ath12k_ppeds_attach( struct ath12k_base *ab);
+int ath12k_mac_op_ppeds_attach_vdev(struct ieee80211_hw *hw,
+				       struct ieee80211_vif *vif,
+				       void *vp_arg, int *ppe_vp_num,
+				       struct ieee80211_ppe_vp_ds_params *vp_params);
+void ath12k_mac_op_ppeds_detach_vdev(struct ieee80211_hw *hw,
+				     struct ieee80211_vif *vif,
+				     struct ieee80211_ppe_vp_ds_params *vp_params);
+void ath12k_dp_peer_ppeds_route_setup(struct ath12k *ar, struct ath12k_link_vif *arvif,
+				      struct ath12k_link_sta *arsta);
+void *ath12k_dp_get_ppe_ds_ctxt(struct ath12k_base *ab);
+irqreturn_t ath12k_ds_ppe2tcl_irq_handler(int irq, void *ctxt);
+irqreturn_t ath12k_ds_reo2ppe_irq_handler(int irq, void *ctxt);
+irqreturn_t ath12k_dp_ppeds_handle_tx_comp(int irq, void *ctxt);
+#endif
+#endif
--- a/drivers/net/wireless/ath/ath12k/wmi.c
+++ b/drivers/net/wireless/ath/ath12k/wmi.c
@@ -1414,6 +1414,88 @@ int ath12k_wmi_send_peer_delete_cmd(stru
 	return ret;
 }
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+int ath12k_wmi_config_peer_ppeds_routing(struct ath12k *ar,
+					 const u8 *peer_addr, u8 vdev_id,
+					 u32 service_code, u32 priority_valid,
+					 u32 src_info, bool ppe_routing_enable)
+{
+	struct ath12k_pdev_wmi *wmi = ar->wmi;
+	struct sk_buff *skb;
+	struct wmi_peer_config_ppeds_cmd *cmd;
+	int ret;
+
+	skb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));
+	if (!skb)
+		return -ENOMEM;
+
+	cmd =(struct wmi_peer_config_ppeds_cmd *)skb->data;
+	cmd->tlv_header  = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PEER_CONFIG_PPEDS_ROUTING,
+			   sizeof(*cmd));
+
+	ether_addr_copy(cmd->peer_macaddr.addr, peer_addr);
+	cmd->vdev_id = cpu_to_le32(vdev_id);
+	cmd->ppe_routing_enable = cpu_to_le32(ppe_routing_enable);
+	cmd->service_code = cpu_to_le32(service_code);
+	cmd->priority_valid = cpu_to_le32(priority_valid);
+	cmd->src_info = cpu_to_le32(src_info);
+
+	ret = ath12k_wmi_cmd_send(wmi, skb, WMI_PEER_CONFIG_PPE_DS_CMDID);
+	if (ret) {
+		ath12k_warn(ar->ab, "failed to send WMI_PEER_CONFIG_PPE_DS cmd"
+			   " peer_addr %pM num_peer : %d\n",
+			    peer_addr, ar->num_peers);
+		dev_kfree_skb(skb);
+	}
+	ath12k_dbg(ar->ab, ATH12K_DBG_PPE,
+		   "ppe ds routing cmd peer_addr %pM vdev_id %d service_code %d " \
+		   "priority_valid %d src_info %d ppe_routing_enable %d \n",
+		   peer_addr, vdev_id, service_code, priority_valid,
+		   src_info, ppe_routing_enable);
+
+	return ret;
+}
+#endif
+
+int ath12k_wmi_send_pdev_pkt_route(struct ath12k *ar,
+				   struct ath12k_wmi_pkt_route_param *param)
+{
+	struct ath12k_pdev_wmi *wmi = ar->wmi;
+	struct wmi_pdev_pkt_route_cmd *cmd;
+	struct sk_buff *skb;
+	int ret;
+
+	skb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));
+	if (!skb)
+		return -ENOMEM;
+
+	cmd = (struct wmi_pdev_pkt_route_cmd *)skb->data;
+	cmd->tlv_header = FIELD_PREP(WMI_TLV_TAG,
+			WMI_TAG_PDEV_UPDATE_PKT_ROUTING_CMD) |
+			FIELD_PREP(WMI_TLV_LEN, sizeof(*cmd) - TLV_HDR_SIZE);
+
+	cmd->pdev_id = ar->pdev->pdev_id;
+	cmd->opcode = param->opcode;
+	cmd->route_type_bmap = param->route_type_bmap;
+	cmd->dst_ring = param->dst_ring;
+	cmd->meta_data = param->meta_data;
+	cmd->dst_ring_handler = param->dst_ring_handler;
+
+	ath12k_dbg(ar->ab, ATH12K_DBG_WMI,
+		   "CCE PPE WMI pdev pkt route opcode %d route_bmap %d dst_ring %d meta_data %d" \
+		   "dst_ring_handler %d\n", param->opcode, param->route_type_bmap,
+		   param->dst_ring, param->meta_data, param->dst_ring_handler);
+
+	ret = ath12k_wmi_cmd_send(wmi, skb, WMI_PDEV_UPDATE_PKT_ROUTING_CMDID);
+	if (ret) {
+		ath12k_warn(ar->ab,
+			"failed to send WMI_PDEV_UPDATE_PKT_ROUTING cmd\n");
+		dev_kfree_skb(skb);
+	}
+
+	return ret;
+}
+
 int ath12k_wmi_send_pdev_set_regdomain(struct ath12k *ar,
 				       struct pdev_set_regdomain_params *param)
 {
--- a/drivers/net/wireless/ath/ath12k/wmi.h
+++ b/drivers/net/wireless/ath/ath12k/wmi.h
@@ -417,6 +417,15 @@ enum wmi_tlv_cmd_id {
 	WMI_PEER_REORDER_QUEUE_REMOVE_CMDID,
 	WMI_PEER_SET_RX_BLOCKSIZE_CMDID,
 	WMI_PEER_ANTDIV_INFO_REQ_CMDID,
+	WMI_PEER_RESERVED0_CMDID,
+	WMI_PEER_TID_MSDUQ_QDEPTH_THRESH_UPDATE_CMDID,
+	WMI_PEER_TID_CONFIGURATIONS_CMDID,
+	WMI_PEER_CFR_CAPTURE_CMDID,
+	WMI_PEER_CHAN_WIDTH_SWITCH_CMDID,
+	WMI_PEER_TX_PN_REQUEST_CMDID,
+	WMI_PEER_UNMAP_RESPONSE_CMDID,
+	WMI_PEER_CONFIG_VLAN_CMDID,
+	WMI_PEER_CONFIG_PPE_DS_CMDID,
 	WMI_BCN_TX_CMDID = WMI_TLV_CMD(WMI_GRP_MGMT),
 	WMI_PDEV_SEND_BCN_CMDID,
 	WMI_BCN_TMPL_CMDID,
@@ -2046,6 +2055,7 @@ enum wmi_tlv_tag {
 	WMI_TAG_TPC_STATS_RATES_ARRAY,
 	WMI_TAG_TPC_STATS_CTL_PWR_TABLE_EVENT,
 	WMI_TAG_BCN_TMPL_ML_PARAMS_CMD = 0x3E6,
+	WMI_TAG_PEER_CONFIG_PPEDS_ROUTING = 0x3EA,
 	WMI_TAG_SAWF_SERVICE_CLASS_CFG_CMD_FIXED_PARAM = 0x40A,
 	WMI_TAG_SAWF_SERVICE_CLASS_DISABLE_CMD_FIXED_PARAM = 0x40B,
 	WMI_TAG_BCN_TMPL_ML_INFO_CMD = 0x436,
@@ -3145,6 +3155,25 @@ struct channel_param {
 	u8  reg_class_id;
 } __packed;
 
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+struct wmi_peer_config_ppeds_cmd {
+	__le32 tlv_header;
+	struct wmi_mac_addr peer_macaddr;
+	__le32 ppe_routing_enable;
+	__le32 service_code;
+	__le32 priority_valid;
+	__le32 src_info;
+	__le32 vdev_id;
+};
+
+enum wmi_ppeds_routing_type {
+	WMI_PPE_ROUTING_DISABLED = 0,
+	WMI_AST_USE_PPE_ENABLED  = 1,
+	WMI_AST_USE_PPE_DISABLED = 2,
+	WMI_PPE_ROUTING_TYPE_MAX,
+};
+#endif
+
 enum wmi_phy_mode {
 	MODE_11A        = 0,
 	MODE_11G        = 1,   /* 11b/g Mode */
@@ -3354,6 +3383,27 @@ struct pdev_set_regdomain_params {
 	u32 pdev_id;
 };
 
+/* Defines various options for routing policy */
+enum wmi_pdev_dest_ring_handler_type {
+	ATH12K_WMI_PKTROUTE_USE_CCE  = 0,
+	ATH12K_WMI_PKTROUTE_USE_ASPT = 1,
+	ATH12K_WMI_PKTROUTE_USE_FSE  = 2,
+	ATH12K_WMI_PKTROUTE_USE_CCE2 = 3,
+};
+
+enum ath12k_wmi_pkt_route_opcode {
+	ATH12K_WMI_PKTROUTE_ADD,
+	ATH12K_WMI_PKTROUTE_DEL,
+};
+
+struct ath12k_wmi_pkt_route_param {
+	enum ath12k_wmi_pkt_route_opcode opcode;
+	u32 route_type_bmap;
+	u32 dst_ring_handler;
+	u32 dst_ring;
+	u32 meta_data;
+};
+
 struct rx_reorder_queue_remove_params {
 	u8 *peer_macaddr;
 	u16 vdev_id;
@@ -3603,6 +3653,16 @@ struct wmi_pdev_set_regdomain_cmd {
 	__le32 dfs_domain;
 } __packed;
 
+struct wmi_pdev_pkt_route_cmd {
+	u32 tlv_header;
+	u32 pdev_id;
+	u32 opcode;
+	u32 route_type_bmap;
+	u32 dst_ring;
+	u32 meta_data;
+	u32 dst_ring_handler;
+} __packed;
+
 struct wmi_peer_set_param_cmd {
 	__le32 tlv_header;
 	__le32 vdev_id;
@@ -8247,6 +8307,8 @@ int ath12k_wmi_peer_rx_reorder_queue_set
 int
 ath12k_wmi_rx_reord_queue_remove(struct ath12k *ar,
 				 struct rx_reorder_queue_remove_params *param);
+int ath12k_wmi_send_pdev_pkt_route(struct ath12k *ar,
+				   struct ath12k_wmi_pkt_route_param *param);
 int ath12k_wmi_send_pdev_set_regdomain(struct ath12k *ar,
 				       struct pdev_set_regdomain_params *param);
 int ath12k_wmi_pull_fw_stats(struct ath12k_base *ab, struct sk_buff *skb,
@@ -8337,4 +8399,10 @@ int
 ath12k_mgmt_rx_reo_init_context(struct ath12k_base *ab);
 int
 ath12k_mgmt_rx_reo_deinit_context(struct ath12k_base *ab);
+#ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
+int ath12k_wmi_config_peer_ppeds_routing(struct ath12k *ar,
+					 const u8 *peer_addr, u8 vdev_id,
+					 u32 service_code, u32 priority_valid,
+					 u32 src_info, bool ppe_routing_enable);
+#endif
 #endif
--- a/local-symbols
+++ b/local-symbols
@@ -143,3 +143,4 @@ ATH12K_DEBUGFS=
 ATH12K_TRACING=
 ATH12K_SPECTRAL=
 ATH12K_PKTLOG=
+ATH12K_PPE_DS_SUPPORT=
--- a/net/mac80211/iface.c
+++ b/net/mac80211/iface.c
@@ -766,7 +766,9 @@ void ieee80211_stop_mbssid(struct ieee80
 static int ieee80211_stop(struct net_device *dev)
 {
 	struct ieee80211_sub_if_data *sdata = IEEE80211_DEV_TO_SUB_IF(dev);
+#ifdef CPTCFG_MAC80211_PPE_SUPPORT
 	struct ieee80211_ppe_vp_ds_params vp_params = {0};
+#endif
 
 	/* close dependent VLAN interfaces before locking wiphy */
 	if (sdata->vif.type == NL80211_IFTYPE_AP) {
@@ -1946,7 +1948,9 @@ static void ieee80211_setup_sdata(struct
 	/* and set some type-dependent values */
 	sdata->vif.type = type;
 	sdata->vif.p2p = false;
+#ifdef CPTCFG_MAC80211_PPE_SUPPORT
 	sdata->vif.ppe_vp_num = -1;
+#endif
 	sdata->wdev.iftype = type;
 
 	sdata->control_port_protocol = cpu_to_be16(ETH_P_PAE);
