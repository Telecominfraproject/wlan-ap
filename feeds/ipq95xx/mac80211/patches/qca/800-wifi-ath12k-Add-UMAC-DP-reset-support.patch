From 55d2d854cc8bce739732d162a98bfbc52164a998 Mon Sep 17 00:00:00 2001
From: Ramya Gnanasekar <quic_rgnanase@quicinc.com>
Date: Wed, 21 Jun 2023 23:10:07 +0530
Subject: [PATCH] wifi: ath12k: Add UMAC DP reset support

The code changes are to add support for umac dp
reset of partner SOC when one SOC crashes in MLO
as a part of MODE 1 SSR

In this process shared memory will be used by Host and
Firmware to communicate the sequence of events. Host will
clear the data structures such as tx/rx descriptors and
re-initialize the rings and reset hp/tp to 0.

Signed-off-by: Ramya Gnanasekar <quic_rgnanase@quicinc.com>
---
 drivers/net/wireless/ath/ath12k/Makefile     |   3 +-
 drivers/net/wireless/ath/ath12k/core.c       |   7 +
 drivers/net/wireless/ath/ath12k/core.h       |  13 +
 drivers/net/wireless/ath/ath12k/debug.h      |   1 +
 drivers/net/wireless/ath/ath12k/dp.c         | 209 ++++++++--
 drivers/net/wireless/ath/ath12k/dp.h         | 183 +++++++++
 drivers/net/wireless/ath/ath12k/dp_rx.c      |   3 +-
 drivers/net/wireless/ath/ath12k/dp_tx.c      |   3 +-
 drivers/net/wireless/ath/ath12k/hif.h        |  13 +
 drivers/net/wireless/ath/ath12k/hw.c         |  61 ++-
 drivers/net/wireless/ath/ath12k/hw.h         |   7 +-
 drivers/net/wireless/ath/ath12k/pci.c        |  60 ++-
 drivers/net/wireless/ath/ath12k/umac_reset.c | 411 +++++++++++++++++++
 13 files changed, 933 insertions(+), 41 deletions(-)
 create mode 100644 drivers/net/wireless/ath/ath12k/umac_reset.c

--- a/drivers/net/wireless/ath/ath12k/Makefile
+++ b/drivers/net/wireless/ath/ath12k/Makefile
@@ -21,7 +21,8 @@ ath12k-y += core.o \
 	    mhi.o \
 	    pci.o \
 	    dp_mon.o \
-	    vendor.o
+	    vendor.o \
+	    umac_reset.o
 
 ath12k-$(CPTCFG_ATH12K_DEBUGFS) += debugfs.o debugfs_htt_stats.o debugfs_sta.o
 ath12k-$(CPTCFG_NL80211_TESTMODE) += testmode.o
--- a/drivers/net/wireless/ath/ath12k/core.c
+++ b/drivers/net/wireless/ath/ath12k/core.c
@@ -1347,9 +1347,14 @@ static int ath12k_core_hw_group_start(st
 	struct ath12k_base *ab = ag->ab[0];
 	int ret, i;
 	bool is_registered = false;
+	struct ath12k_mlo_dp_umac_reset *mlo_umac_reset;
 
 	lockdep_assert_held(&ag->mutex_lock);
 
+	mlo_umac_reset = &ag->mlo_umac_reset;
+	if (ab->hw_params->support_umac_reset)
+		spin_lock_init(&mlo_umac_reset->lock);
+
 	/* Check If already registered or not, since same flow
 	 * execute for HW restart case.
 	 */
@@ -1421,6 +1426,13 @@ static int ath12k_core_hw_group_start(st
 			}
 		}
 
+		ret = ath12k_dp_umac_reset_init(ab);
+		if (ret) {
+			mutex_unlock(&ab->core_lock);
+			ath12k_warn(ab, "Failed to initialize UMAC RESET: %d\n", ret);
+			goto pdev_cleanup;
+		}
+
 		set_bit(ATH12K_FLAG_REGISTERED, &ab->dev_flags);
 
 		mutex_unlock(&ab->core_lock);
@@ -1439,6 +1451,7 @@ pdev_cleanup:
 
 		ath12k_core_pdev_deinit(ab);
 		ath12k_hif_irq_disable(ab);
+		ath12k_dp_umac_reset_deinit(ab);
 
 		mutex_unlock(&ab->core_lock);
 	}
@@ -1767,6 +1780,7 @@ static int ath12k_core_reconfigure_on_cr
 
 	ath12k_dp_free(ab);
 	ath12k_hal_srng_deinit(ab);
+	ath12k_umac_reset_completion(ab);
 
 	ab->free_vdev_map = (1LL << (ab->num_radios * TARGET_NUM_VDEVS)) - 1;
 	ab->num_db_cap = 0;
@@ -2438,6 +2452,7 @@ static void ath12k_core_hw_group_stop(st
 		ath12k_hif_irq_disable(ab);
 		ath12k_core_pdev_destroy(ab);
 		ath12k_core_stop(ab);
+		ath12k_dp_umac_reset_deinit(ab);
 		clear_bit(ATH12K_FLAG_CORE_REGISTERED, &ab->dev_flags);
 
 		mutex_unlock(&ab->core_lock);
--- a/drivers/net/wireless/ath/ath12k/core.h
+++ b/drivers/net/wireless/ath/ath12k/core.h
@@ -252,6 +252,8 @@ enum ath12k_dev_flags {
 	ATH12K_FLAG_FTM_SEGMENTED,
 	ATH12K_FLAG_PPE_DS_ENABLED,
 	ATH12K_FLAG_WMI_INIT_DONE,
+	ATH12K_FLAG_UMAC_PRERESET_START,
+	ATH12K_FLAG_UMAC_RESET_COMPLETE,
 };
 
 enum ath12k_monitor_flags {
@@ -1255,6 +1257,18 @@ enum ath12k_mlo_recovery_mode {
 	ATH12K_MLO_RECOVERY_MODE0,
 };
 
+struct ath12k_mlo_dp_umac_reset {
+        atomic_t response_chip;
+        spinlock_t lock;
+        u8 umac_reset_info;
+        u8 initiator_chip;
+	u8 is_intr_bkup;
+	struct ath12k_hw_ring_mask intr_bkup;
+};
+
+#define ATH12K_UMAC_RESET_IPC	451
+#define ATH12K_IS_UMAC_RESET_IN_PROGRESS	BIT(0)
+
 /* Holds info on the group of SOCs that are registered as a single wiphy
  * or single SOC where each radio registered as separate wiphy in non-MLO
  */
@@ -1278,6 +1292,7 @@ struct ath12k_hw_group {
 	struct ath12k_mgmt_rx_reo_context rx_reo;
 	struct ath12k_host_mlo_mem_arena mlomem_arena;
 	atomic_t num_dp_tx_pending;
+	struct ath12k_mlo_dp_umac_reset mlo_umac_reset;
 };
 
 /* Master structure to hold the hw data which may be used in core module */
@@ -1357,7 +1372,7 @@ struct ath12k_base {
 	bool pdevs_macaddr_valid;
 	int bd_api;
 
-	const struct ath12k_hw_params *hw_params;
+	struct ath12k_hw_params *hw_params;
 	struct ath12k_bus_params bus_params;
 	bool is_qdss_tracing;
 
@@ -1458,6 +1473,7 @@ struct ath12k_base {
 	int userpd_id;
 
 	u32 chwidth_num_peer_caps;
+	struct ath12k_dp_umac_reset dp_umac_reset;
 
 	/* must be last */
 	u8 drv_priv[0] __aligned(sizeof(void *));
@@ -1628,6 +1644,10 @@ int ath12k_sawf_send_disable_soc(u8 svc_
 int ath12k_core_sawf_ul_config(struct net_device *dev, struct ath12k_sawf_wmi_peer_latency_param *latency_info);
 void *ath12k_get_ab_nd_peer_from_peer_mac(u8 *peer_mac, struct ath12k_base **ab_ref);
 #endif /* CPTCFG_ATH12K_SAWF */
+void ath12k_dp_umac_reset_handle(struct ath12k_base *ab);
+int ath12k_dp_umac_reset_init(struct ath12k_base *ab);
+void ath12k_dp_umac_reset_deinit(struct ath12k_base *ab);
+void ath12k_umac_reset_completion(struct ath12k_base *ab);
 
 static inline const char *ath12k_scan_state_str(enum ath12k_scan_state state)
 {
--- a/drivers/net/wireless/ath/ath12k/debug.h
+++ b/drivers/net/wireless/ath/ath12k/debug.h
@@ -33,6 +33,7 @@ enum ath12k_debug_mask {
 	/* keep last*/
 	ATH12K_DBG_SAWF		= 0x00040000,
 	ATH12K_DBG_PPE          = 0x00080000,
+	ATH12K_DBG_DP_UMAC_RESET= 0x00100000,
 	ATH12K_DBG_ANY		= 0xffffffff,
 };
 
--- a/drivers/net/wireless/ath/ath12k/dp.c
+++ b/drivers/net/wireless/ath/ath12k/dp.c
@@ -189,49 +189,76 @@ static int ath12k_dp_srng_find_ring_in_m
 	return -ENOENT;
 }
 
+bool ath12k_dp_umac_reset_in_progress(struct ath12k_base *ab)
+{
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *mlo_umac_reset = &ag->mlo_umac_reset;
+	bool umac_in_progress = false;
+
+	if (!ab->hw_params->support_umac_reset)
+		return umac_in_progress;
+
+	spin_lock_bh(&mlo_umac_reset->lock);
+	if (mlo_umac_reset->umac_reset_info &
+	    ATH12K_IS_UMAC_RESET_IN_PROGRESS)
+		umac_in_progress = true;
+	spin_unlock_bh(&mlo_umac_reset->lock);
+
+	return umac_in_progress;
+}
+
 static int ath12k_dp_srng_calculate_msi_group(struct ath12k_base *ab,
 					      enum hal_ring_type type, int ring_num)
 {
 	const u8 *grp_mask;
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *umac_reset;
+	struct ath12k_hw_ring_mask *ring_mask;
+
+	umac_reset = &ag->mlo_umac_reset;
+	if (ath12k_dp_umac_reset_in_progress(ab) && umac_reset)
+		ring_mask = &umac_reset->intr_bkup;
+	else
+		ring_mask = ab->hw_params->ring_mask;
 
 	switch (type) {
 	case HAL_WBM2SW_RELEASE:
 		if (ring_num == HAL_WBM2SW_REL_ERR_RING_NUM) {
-			grp_mask = &ab->hw_params->ring_mask->rx_wbm_rel[0];
+			grp_mask = &ring_mask->rx_wbm_rel[0];
 			ring_num = 0;
 #ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
 		} else if (ring_num == HAL_WBM2SW_PPEDS_TX_CMPLN_RING_NUM) {
-			grp_mask = &ab->hw_params->ring_mask->wbm2sw6_ppeds_tx_cmpln[0];
+			grp_mask = &ring_mask->wbm2sw6_ppeds_tx_cmpln[0];
 			ring_num = 0;
 #endif
 		} else {
-			grp_mask = &ab->hw_params->ring_mask->tx[0];
+			grp_mask = &ring_mask->tx[0];
 		}
 		break;
 	case HAL_REO_EXCEPTION:
-		grp_mask = &ab->hw_params->ring_mask->rx_err[0];
+		grp_mask = &ring_mask->rx_err[0];
 		break;
 	case HAL_REO_DST:
-		grp_mask = &ab->hw_params->ring_mask->rx[0];
+		grp_mask = &ring_mask->rx[0];
 		break;
 	case HAL_REO_STATUS:
-		grp_mask = &ab->hw_params->ring_mask->reo_status[0];
+		grp_mask = &ring_mask->reo_status[0];
 		break;
 	case HAL_RXDMA_MONITOR_STATUS:
 	case HAL_RXDMA_MONITOR_DST:
-		grp_mask = &ab->hw_params->ring_mask->rx_mon_dest[0];
+		grp_mask = &ring_mask->rx_mon_dest[0];
 		break;
 	case HAL_TX_MONITOR_DST:
-		grp_mask = &ab->hw_params->ring_mask->tx_mon_dest[0];
+		grp_mask = &ring_mask->tx_mon_dest[0];
 		break;
 	case HAL_RXDMA_BUF:
-		grp_mask = &ab->hw_params->ring_mask->host2rxdma[0];
+		grp_mask = &ring_mask->host2rxdma[0];
 		break;
 	case HAL_PPE2TCL:
-		grp_mask = &ab->hw_params->ring_mask->ppe2tcl[0];
+		grp_mask = &ring_mask->ppe2tcl[0];
 		break;
 	case HAL_REO2PPE:
-		grp_mask = &ab->hw_params->ring_mask->reo2ppe[0];
+		grp_mask = &ring_mask->reo2ppe[0];
 		break;
 	case HAL_RXDMA_MONITOR_BUF:
 	case HAL_TCL_DATA:
@@ -498,24 +525,29 @@ int ath12k_dp_srng_setup(struct ath12k_b
 		default:
 			cached = false;
 		}
-
-		if (cached) {
-			ring->vaddr_unaligned = kzalloc(ring->size, GFP_KERNEL);
-			ring->paddr_unaligned = virt_to_phys(ring->vaddr_unaligned);
-		}
 	}
-	if (!cached)
+
+	if (ath12k_dp_umac_reset_in_progress(ab))
+		goto skip_dma_alloc;
+
+	if (cached) {
+		ring->vaddr_unaligned = kzalloc(ring->size, GFP_KERNEL);
+		ring->paddr_unaligned = virt_to_phys(ring->vaddr_unaligned);
+	} else {
 		ring->vaddr_unaligned = dma_alloc_coherent(ab->dev, ring->size,
 							   &ring->paddr_unaligned,
 							   GFP_KERNEL);
+	}
+
 	if (!ring->vaddr_unaligned)
 		return -ENOMEM;
 
-	memset(ring->vaddr_unaligned, 0, ring->size);
 	ring->vaddr = PTR_ALIGN(ring->vaddr_unaligned, HAL_RING_BASE_ALIGN);
 	ring->paddr = ring->paddr_unaligned + ((unsigned long)ring->vaddr -
 		      (unsigned long)ring->vaddr_unaligned);
 
+skip_dma_alloc:
+	memset(ring->vaddr_unaligned, 0, ring->size);
 	params.ring_base_vaddr = ring->vaddr;
 	params.ring_base_paddr = ring->paddr;
 	params.num_entries = num_entries;
@@ -758,6 +790,50 @@ static int ath12k_dp_init_bank_profiles(
 	return 0;
 }
 
+static void ath12k_dp_srng_hw_disable(struct ath12k_base *ab, struct dp_srng *ring)
+{
+	struct hal_srng *srng = &ab->hal.srng_list[ring->ring_id];
+	u32 reg_base, val, addr;
+
+	reg_base = srng->hwreg_base[HAL_SRNG_REG_GRP_R0];
+	if (srng->ring_dir == HAL_SRNG_DIR_SRC) {
+		if (srng->ring_id == HAL_SRNG_RING_ID_WBM_IDLE_LINK)
+			addr = HAL_SEQ_WCSS_UMAC_WBM_REG +
+			       HAL_WBM_IDLE_LINK_RING_MISC_ADDR(ab);
+		else
+			addr = reg_base + HAL_TCL1_RING_MISC_OFFSET(ab);
+		val = ath12k_hif_read32(ab, addr);
+		val &= ~HAL_TCL1_RING_MISC_SRNG_ENABLE;
+		ath12k_hif_write32(ab, addr, val);
+	} else {
+		val = ath12k_hif_read32(ab, reg_base + HAL_REO1_RING_MISC_OFFSET);
+		val &= ~HAL_REO1_RING_MISC_SRNG_ENABLE;
+		ath12k_hif_write32(ab , reg_base + HAL_REO1_RING_MISC_OFFSET, val);
+	}
+}
+
+void ath12k_dp_srng_hw_ring_disable(struct ath12k_base *ab)
+{
+	struct ath12k_dp *dp = &ab->dp;
+	int i;
+
+	for (i = 0; i < DP_REO_DST_RING_MAX; i++)
+		ath12k_dp_srng_hw_disable(ab, &dp->reo_dst_ring[i]);
+	ath12k_dp_srng_hw_disable(ab, &dp->wbm_desc_rel_ring);
+	ath12k_dp_srng_hw_disable(ab, &dp->tcl_cmd_ring);
+
+	for(i = 0; i < ab->hw_params->max_tx_ring; i++) {
+		ath12k_dp_srng_hw_disable(ab, &dp->tx_ring[i].tcl_data_ring);
+		ath12k_dp_srng_hw_disable(ab, &dp->tx_ring[i].tcl_comp_ring);
+	}
+	ath12k_dp_srng_hw_disable(ab, &dp->reo_reinject_ring);
+	ath12k_dp_srng_hw_disable(ab, &dp->rx_rel_ring);
+	ath12k_dp_srng_hw_disable(ab, &dp->reo_except_ring);
+	ath12k_dp_srng_hw_disable(ab, &dp->reo_cmd_ring);
+	ath12k_dp_srng_hw_disable(ab, &dp->reo_status_ring);
+	ath12k_dp_srng_hw_disable(ab, &dp->wbm_idle_ring);
+}
+
 static void ath12k_dp_srng_common_cleanup(struct ath12k_base *ab)
 {
 	struct ath12k_dp *dp = &ab->dp;
@@ -806,11 +882,13 @@ static int ath12k_dp_srng_common_setup(s
 		goto err;
 	}
 
-	ret = ath12k_dp_srng_setup(ab, &dp->tcl_status_ring, HAL_TCL_STATUS,
-				   0, 0, DP_TCL_STATUS_RING_SIZE);
-	if (ret) {
-		ath12k_warn(ab, "failed to set up tcl_status ring :%d\n", ret);
-		goto err;
+	if (!ath12k_dp_umac_reset_in_progress(ab)) {
+		ret = ath12k_dp_srng_setup(ab, &dp->tcl_status_ring, HAL_TCL_STATUS,
+					   0, 0, DP_TCL_STATUS_RING_SIZE);
+		if (ret) {
+			ath12k_warn(ab, "failed to set up tcl_status ring :%d\n", ret);
+			goto err;
+		}
 	}
 
 	for (i = 0; i < ab->hw_params->max_tx_ring; i++) {
@@ -879,6 +957,9 @@ static int ath12k_dp_srng_common_setup(s
 		goto err;
 	}
 
+	if (ath12k_dp_umac_reset_in_progress(ab))
+		goto skip_reo_setup;
+
 	/* When hash based routing of rx packet is enabled, 32 entries to map
 	 * the hash values to the ring will be configured. Each hash entry uses
 	 * four bits to map to a particular ring. The ring mapping will be
@@ -896,6 +977,7 @@ static int ath12k_dp_srng_common_setup(s
 
 	ath12k_hal_reo_hw_setup(ab, ring_hash_map);
 
+skip_reo_setup:
 #ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
 	ret = ath12k_dp_srng_ppeds_setup(ab);
 	if (ret) {
@@ -955,13 +1037,15 @@ static int ath12k_dp_scatter_idle_link_d
 	if (num_scatter_buf > DP_IDLE_SCATTER_BUFS_MAX)
 		return -EINVAL;
 
-	for (i = 0; i < num_scatter_buf; i++) {
-		slist[i].vaddr = dma_alloc_coherent(ab->dev,
-						    HAL_WBM_IDLE_SCATTER_BUF_SIZE_MAX,
-						    &slist[i].paddr, GFP_KERNEL);
-		if (!slist[i].vaddr) {
-			ret = -ENOMEM;
-			goto err;
+	if (!ath12k_dp_umac_reset_in_progress(ab)) {
+		for (i = 0; i < num_scatter_buf; i++) {
+			slist[i].vaddr = dma_alloc_coherent(ab->dev,
+							    HAL_WBM_IDLE_SCATTER_BUF_SIZE_MAX,
+							    &slist[i].paddr, GFP_KERNEL);
+			if (!slist[i].vaddr) {
+				ret = -ENOMEM;
+				goto err;
+			}
 		}
 	}
 
@@ -1143,10 +1227,12 @@ int ath12k_dp_link_desc_setup(struct ath
 	if (n_link_desc_bank > DP_LINK_DESC_BANKS_MAX)
 		return -EINVAL;
 
-	ret = ath12k_dp_link_desc_bank_alloc(ab, link_desc_banks,
-					     n_link_desc_bank, last_bank_sz);
-	if (ret)
-		return ret;
+	if (!ath12k_dp_umac_reset_in_progress(ab)) {
+		ret = ath12k_dp_link_desc_bank_alloc(ab, link_desc_banks,
+						     n_link_desc_bank, last_bank_sz);
+		if (ret)
+			return ret;
+	}
 
 	/* Setup link desc idle list for HW internal usage */
 	entry_sz = ath12k_hal_srng_get_entrysize(ab, ring_type);
@@ -1522,6 +1608,61 @@ void ath12k_dp_vdev_tx_attach(struct ath
 #endif
 }
 
+void ath12k_dp_umac_txrx_desc_cleanup(struct ath12k_base *ab)
+{
+	struct ath12k_rx_desc_info *desc_info, *tmp;
+	struct ath12k_tx_desc_info *tx_desc_info, *tmp1;
+	struct ath12k_dp *dp = &ab->dp;
+	struct sk_buff *skb;
+	int i;
+
+	/* RX Descriptor cleanup */
+	spin_lock_bh(&dp->rx_desc_lock);
+
+	list_for_each_entry_safe(desc_info, tmp, &dp->rx_desc_used_list, list) {
+		list_move_tail(&desc_info->list, &ab->dp.rx_desc_free_list);
+		skb = desc_info->skb;
+		desc_info->skb = NULL;
+
+		if (!skb)
+			continue;
+
+		dma_unmap_single(ab->dev, ATH12K_SKB_RXCB(skb)->paddr,
+				 skb->len + skb_tailroom(skb), DMA_FROM_DEVICE);
+		dev_kfree_skb_any(skb);
+	}
+
+	spin_unlock_bh(&dp->rx_desc_lock);
+
+	/* TX Descriptor cleanup */
+	for (i = 0; i < ATH12K_HW_MAX_QUEUES; i++) {
+		spin_lock_bh(&dp->tx_desc_lock[i]);
+
+		list_for_each_entry_safe(tx_desc_info, tmp1, &dp->tx_desc_used_list[i],
+					 list) {
+			list_move_tail(&tx_desc_info->list, &ab->dp.tx_desc_free_list);
+			skb = tx_desc_info->skb;
+			tx_desc_info->skb = NULL;
+
+			if (!skb)
+				continue;
+
+			dma_unmap_single(ab->dev, ATH12K_SKB_CB(skb)->paddr,
+					 skb->len, DMA_TO_DEVICE);
+
+			if (tx_desc_info->skb_ext_desc) {
+				dma_unmap_single(ab->dev, ATH12K_SKB_CB(skb)->paddr_ext_desc,
+						 tx_desc_info->skb_ext_desc->len, DMA_TO_DEVICE);
+				dev_kfree_skb_any(tx_desc_info->skb_ext_desc);
+			}
+
+			dev_kfree_skb_any(skb);
+		}
+
+		spin_unlock_bh(&dp->tx_desc_lock[i]);
+	}
+}
+
 static void ath12k_dp_cc_cleanup(struct ath12k_base *ab)
 {
 	struct ath12k_rx_desc_info *desc_info, *tmp;
@@ -1566,7 +1707,7 @@ static void ath12k_dp_cc_cleanup(struct
 			continue;
 
 		kfree(dp->spt_info->rxbaddr[i]);
-        }
+	}
 
 	spin_unlock_bh(&dp->rx_desc_lock);
 
@@ -2273,3 +2414,81 @@ fail_link_desc_cleanup:
 
 	return ret;
 }
+
+int ath12k_dp_rxdma_ring_setup(struct ath12k_base *ab)
+{
+	struct ath12k_dp *dp = &ab->dp;
+	int num_entries, ret;
+	struct dp_rxdma_ring *rx_ring = &dp->rx_refill_buf_ring;
+
+	ret = ath12k_dp_srng_setup(ab,
+				   &dp->rx_refill_buf_ring.refill_buf_ring,
+				   HAL_RXDMA_BUF, 0, 0,
+				   DP_RXDMA_BUF_RING_SIZE);
+
+	if (ret) {
+		ath12k_warn(ab, "failed to setup rx_refill_buf_ring\n");
+		return ret;
+	}
+
+	num_entries = rx_ring->refill_buf_ring.size /
+			ath12k_hal_srng_get_entrysize(ab, HAL_RXDMA_BUF);
+
+	ath12k_dp_rx_bufs_replenish(ab, rx_ring, num_entries,
+				    ab->hw_params->hal_params->rx_buf_rbm,
+				    true);
+	return 0;
+}
+
+void ath12k_umac_reset_handle_post_reset_start(struct ath12k_base *ab)
+{
+	struct ath12k_dp *dp = &ab->dp;
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *mlo_umac_reset = &ag->mlo_umac_reset;
+	int i, n_link_desc, ret;
+	struct hal_srng *srng = NULL;
+	unsigned long end;
+
+	ath12k_dp_srng_hw_ring_disable(ab);
+
+	/* Busy wait for 2 ms to make sure the rings are
+	 * in idle state before enabling it
+	 */
+	end = jiffies + msecs_to_jiffies(2);
+	while (time_before(jiffies, end))
+		;
+
+	ret = ath12k_wbm_idle_ring_setup(ab, &n_link_desc);
+
+	if (ret)
+		ath12k_warn(ab, "failed to setup wbm_idle_ring: %d\n", ret);
+
+	srng = &ab->hal.srng_list[dp->wbm_idle_ring.ring_id];
+
+	ret = ath12k_dp_link_desc_setup(ab, dp->link_desc_banks,
+				  HAL_WBM_IDLE_LINK, srng, n_link_desc);
+	if (ret)
+		ath12k_warn(ab, "failed to setup link desc: %d\n", ret);
+
+	ath12k_dp_srng_common_setup(ab);
+	ath12k_dp_umac_txrx_desc_cleanup(ab);
+
+	ath12k_dp_rxdma_ring_setup(ab);
+
+	for (i = 0; i < DP_REO_DST_RING_MAX; i++) {
+		ret = ath12k_dp_srng_setup(ab, &dp->reo_dst_ring[i],
+					   HAL_REO_DST, i, 0,
+					   DP_REO_DST_RING_SIZE);
+		if (ret)
+			ath12k_warn(ab, "failed to setup reo_dst_ring\n");
+	}
+
+	ath12k_dp_rx_reo_cmd_list_cleanup(ab);
+
+	ath12k_dp_tid_cleanup(ab);
+
+	atomic_inc(&mlo_umac_reset->response_chip);
+	ath12k_umac_reset_notify_target_sync_and_send(ab, ATH12K_UMAC_RESET_TX_CMD_POST_RESET_START_DONE);
+
+	return;
+}
--- a/drivers/net/wireless/ath/ath12k/dp.h
+++ b/drivers/net/wireless/ath/ath12k/dp.h
@@ -538,6 +538,8 @@ enum htt_h2t_msg_type {
 	HTT_H2T_MSG_TYPE_SAWF_DEF_Q_UNMAP_REQ	= 0x1d,
 	HTT_H2T_MSG_TYPE_SAWF_DEF_Q_MAP_REPORT_REQ = 0x1e,
 	HTT_H2T_MSG_TYPE_STREAMING_STATS_REQ	= 0x20,
+	HTT_H2T_MSG_TYPE_UMAC_RESET_PREREQUISITE_SETUP = 0x21,
+	HTT_H2T_MSG_TYPE_UMAC_RESET_START_PRE_RESET = 0x22,
 };
 
 #define HTT_VER_REQ_INFO_MSG_ID		GENMASK(7, 0)
@@ -2357,6 +2359,211 @@ struct ath12k_dp_htt_rxdma_ppe_cfg_param
 	u8 ip_frag_override;
 };
 
+#define HTT_ATH12K_UMAC_RESET_T2H_DO_PRE_RESET	BIT(0)
+#define HTT_ATH12K_UMAC_RESET_T2H_DO_POST_RESET_START	BIT(1)
+#define HTT_ATH12K_UMAC_RESET_T2H_DO_POST_RESET_COMPLETE	BIT(2)
+#define HTT_ATH12K_UMAC_RESET_T2H_INIT_UMAC_RECOVERY	BIT(3)
+#define HTT_ATH12K_UMAC_RESET_T2H_INIT_TARGET_RECOVERY_SYNC_USING_UMAC	BIT(4)
+
+enum dp_umac_reset_recover_action {
+	ATH12K_UMAC_RESET_RX_EVENT_NONE,
+	ATH12K_UMAC_RESET_INIT_UMAC_RECOVERY,
+	ATH12K_UMAC_RESET_INIT_TARGET_RECOVERY_SYNC_USING_UMAC,
+	ATH12K_UMAC_RESET_DO_PRE_RESET,
+	ATH12K_UMAC_RESET_DO_POST_RESET_START,
+	ATH12K_UMAC_RESET_DO_POST_RESET_COMPLETE,
+};
+
+enum dp_umac_reset_tx_cmd {
+	ATH12K_UMAC_RESET_TX_CMD_TRIGGER_DONE,
+	ATH12K_UMAC_RESET_TX_CMD_PRE_RESET_DONE,
+	ATH12K_UMAC_RESET_TX_CMD_POST_RESET_START_DONE,
+	ATH12K_UMAC_RESET_TX_CMD_POST_RESET_COMPLETE_DONE,
+};
+
+#define ATH12K_HTT_UMAC_RESET_MSG_SHMEM_PRE_RESET_DONE_SET	BIT(0)
+#define ATH12K_HTT_UMAC_RESET_MSG_SHMEM_POST_RESET_START_DONE_SET BIT(1)
+#define ATH12K_HTT_UMAC_RESET_MSG_SHMEM_POST_RESET_COMPLETE_DONE BIT(2)
+
+struct ath12k_dp_htt_umac_reset_recovery_msg_shmem_t {
+	u32 magic_num;
+	union {
+		/*
+		 * BIT [0]        :- T2H msg to do pre-reset
+		 * BIT [1]        :- T2H msg to do post-reset start
+		 * BIT [2]        :- T2H msg to do post-reset complete
+		 * BIT [3]        :- T2H msg to indicate to Host that
+		 *                   a trigger request for MLO UMAC Recovery
+		 *                   is received for UMAC hang.
+		 * BIT [4]        :- T2H msg to indicate to Host that
+		 *                   a trigger request for MLO UMAC Recovery
+		 *                   is received for Mode-1 Target Recovery.
+		 * BIT [31 : 5]   :- reserved
+		 */
+		u32 t2h_msg;
+		u32 recovery_action;
+	};
+	union {
+		/*
+		 * BIT [0]        :- H2T msg to send pre-reset done
+		 * BIT [1]        :- H2T msg to send post-reset start done
+		 * BIT [2]        :- H2T msg to send post-reset complete done
+		 * BIT [3]        :- H2T msg to start pre-reset. This is deprecated.
+		 * BIT [31 : 4]   :- reserved
+		 */
+		u32 h2t_msg;
+		u32 recovery_action_done;
+	};
+};
+
+struct ath12k_umac_reset_ts {
+	u64 trigger_start;
+	u64 trigger_done;
+	u64 pre_reset_start;
+	u64 pre_reset_done;
+	u64 post_reset_start;
+	u64 post_reset_done;
+	u64 post_reset_complete_start;
+	u64 post_reset_complete_done;
+};
+
+struct ath12k_dp_umac_reset {
+	dma_addr_t shmem_paddr_unaligned;
+	void *shmem_vaddr_unaligned;
+	dma_addr_t shmem_paddr_aligned;
+	struct ath12k_dp_htt_umac_reset_recovery_msg_shmem_t *shmem_vaddr_aligned;
+	size_t shmem_size;
+	uint32_t magic_num;
+	int intr_offset;
+	struct tasklet_struct intr_tq;
+	int irq_num;
+	struct ath12k_umac_reset_ts ts;
+};
+
+struct ath12k_htt_umac_reset_setup_cmd_params {
+	uint32_t msi_data;
+	uint32_t addr_lo;
+	uint32_t addr_hi;
+};
+
+struct htt_h2t_paddr_size {
+	u32 size;
+	u32 addr_lo;
+	u32 addr_hi;
+};
+
+#define HTT_H2T_MSG_TYPE_SET	GENMASK(7, 0)
+#define HTT_H2T_MSG_METHOD	GENMASK(11, 8)
+#define HTT_T2H_MSG_METHOD	GENMASK(15, 12)
+
+#define ATH12K_DP_UMAC_RESET_SHMEM_MAGIC_NUM	0xDEADBEEF
+#define ATH12K_DP_UMAC_RESET_SHMEM_ALIGN 	8
+
+/**
+ * @brief HTT_H2T_MSG_TYPE_UMAC_RESET_PREREQUISITE_SETUP message
+ *
+ * @details
+ *  The HTT_H2T_MSG_TYPE_UMAC_HANG_RECOVERY_PREREQUISITE_SETUP message is sent
+ *  by the host to provide prerequisite info to target for the UMAC hang
+ *  recovery feature.
+ *  The info sent in this H2T message are T2H message method, H2T message
+ *  method, T2H MSI interrupt number and physical start address, size of
+ *  the shared memory (refers to the shared memory dedicated for messaging
+ *  between host and target when the DUT is in UMAC hang recovery mode).
+ *  This H2T message is expected to be only sent if the WMI service bit
+ *  WMI_SERVICE_UMAC_HANG_RECOVERY_SUPPORT was firstly indicated by the target.
+ *
+ * |31                           16|15          12|11           8|7          0|
+ * |-------------------------------+--------------+--------------+------------|
+ * |            reserved           |h2t msg method|t2h msg method|  msg_type  |
+ * |--------------------------------------------------------------------------|
+ * |                           t2h msi interrupt number                       |
+ * |--------------------------------------------------------------------------|
+ * |                           shared memory area size                        |
+ * |--------------------------------------------------------------------------|
+ * |                     shared memory area physical address low              |
+ * |--------------------------------------------------------------------------|
+ * |                     shared memory area physical address high             |
+ * |--------------------------------------------------------------------------|
+  * The message is interpreted as follows:
+ * dword0 - b'0:7   - msg_type
+ *                    (HTT_H2T_MSG_TYPE_UMAC_RESET_PREREQUISITE_SETUP)
+ *          b'8:11  - t2h_msg_method: indicates method to be used for
+ *                    T2H communication in UMAC hang recovery mode.
+ *                    Value zero indicates MSI interrupt (default method).
+ *                    Refer to htt_umac_hang_recovery_msg_method enum.
+ *          b'12:15 - h2t_msg_method: indicates method to be used for
+ *                    H2T communication in UMAC hang recovery mode.
+ *                    Value zero indicates polling by target for this h2t msg
+ *                    during UMAC hang recovery mode.
+ *                    Refer to htt_umac_hang_recovery_msg_method enum.
+ *          b'16:31 - reserved.
+ * dword1 - b'0:31  - t2h_msi_data: MSI data to be used for
+ *                    T2H communication in UMAC hang recovery mode.
+ * dword2 - b'0:31  - size: size of shared memory dedicated for messaging
+ *                    only when in UMAC hang recovery mode.
+ *                    This refers to size in bytes.
+ * dword3 - b'0:31  - physical_address_lo: lower 32 bit physical address
+ *                    of the shared memory dedicated for messaging only when
+ *                    in UMAC hang recovery mode.
+ * dword4 - b'0:31  - physical_address_hi: higher 32 bit physical address
+ *                    of the shared memory dedicated for messaging only when
+ *                    in UMAC hang recovery mode.
+ */
+
+struct htt_dp_umac_reset_setup_req_cmd {
+	u32 msg_info;
+	u32 msi_data;
+	struct htt_h2t_paddr_size msg_shared_mem;
+}__packed;
+
+/**
+ * @brief HTT_H2T_MSG_TYPE_UMAC_RESET_START_PRE_RESET message
+ *
+ * @details
+ *  The HTT_H2T_MSG_TYPE_UMAC_HANG_RECOVERY_SOC_START_PRE_RESET is a SOC level
+ *  HTT message sent by the host to indicate that the target needs to start the
+ *  UMAC hang recovery feature from the point of pre-reset routine.
+ *  The purpose of this H2T message is to have host synchronize and trigger
+ *  UMAC recovery across all targets.
+ *  The info sent in this H2T message is the flag to indicate whether the
+ *  target needs to execute UMAC-recovery in context of the Initiator or
+ *  Non-Initiator.
+ *  This H2T message is expected to be sent as response to the
+ *  initiate_umac_recovery indication from the Initiator target attached to
+ *  this same host.
+ *  This H2T message is expected to be only sent if the WMI service bit
+ *  WMI_SERVICE_UMAC_HANG_RECOVERY_SUPPORT was firstly indicated by the target
+ *  and HTT_H2T_MSG_TYPE_UMAC_HANG_RECOVERY_PREREQUISITE_SETUP was sent
+ *  beforehand.
+ *
+ * |31                                    10|9|8|7            0|
+ * |-----------------------------------------------------------|
+ * |                 reserved               |U|I|   msg_type   |
+ * |-----------------------------------------------------------|
+ * Where:
+ *     I = is_initiator
+ *     U = is_umac_hang
+ *
+ * The message is interpreted as follows:
+ * dword0 - b'0:7   - msg_type
+ *                    (HTT_H2T_MSG_TYPE_UMAC_RESET_START_PRE_RESET)
+ *	    b'8     - is_initiator: indicates whether the target needs to
+ *                    execute the UMAC-recovery in context of the Initiator or
+ *                    Non-Initiator.
+ *                    The value zero indicates this target is Non-Initiator.
+ *          b'9     - is_umac_hang: indicates whether MLO UMAC recovery
+ *                    executed in context of UMAC hang or Target recovery.
+ *          b'10:31 - reserved.
+ */
+struct h2t_umac_hang_recovery_start_pre_reset {
+	u8 hdr;
+} __packed;
+
+#define HTT_H2T_UMAC_RESET_MSG_TYPE	GENMASK(7, 0)
+#define HTT_H2T_UMAC_RESET_IS_INITIATOR_SET	BIT(8)
+#define HTT_H2T_UMAC_RESET_IS_TARGET_RECOVERY_SET	BIT(9)
+
 int ath12k_dp_service_srng(struct ath12k_base *ab,
 			   struct ath12k_ext_irq_grp *irq_grp,
 			   int budget);
@@ -2406,4 +2613,9 @@ int ath12k_dp_cc_ppeds_desc_init(struct
 int ath12k_dp_cc_ppeds_desc_cleanup(struct ath12k_base *ab);
 void ath12k_dp_ppeds_tx_cmem_init(struct ath12k_base *ab, struct ath12k_dp *dp);
 #endif
+void ath12k_umac_reset_handle_post_reset_start(struct ath12k_base *ab);
+void ath12k_umac_reset_notify_target_sync_and_send(struct ath12k_base *ab,
+					       enum dp_umac_reset_tx_cmd tx_event);
+void ath12k_dp_reset_interrupt_mask(struct ath12k_base *ab);
+void ath12k_dp_restore_interrupt_mask(struct ath12k_base *ab);
 #endif
--- a/drivers/net/wireless/ath/ath12k/dp_rx.c
+++ b/drivers/net/wireless/ath/ath12k/dp_rx.c
@@ -572,6 +572,28 @@ static void ath12k_peer_rx_tid_qref_rese
 	qref->info1 = u32_encode_bits(0, BUFFER_ADDR_INFO1_ADDR);
 }
 
+void ath12k_dp_tid_cleanup(struct ath12k_base *ab)
+{
+	struct ath12k_peer *peer;
+	struct ath12k_dp_rx_tid *rx_tid;
+	int tid;
+	void *vaddr;
+	u32 *addr_aligned;
+
+	spin_lock_bh(&ab->base_lock);
+	list_for_each_entry(peer, &ab->peers, list) {
+		for (tid = 0; tid <= IEEE80211_NUM_TIDS; tid++) {
+			rx_tid = &peer->rx_tid[tid];
+			if (rx_tid->active) {
+				vaddr = rx_tid->vaddr;
+				addr_aligned = PTR_ALIGN(vaddr, HAL_LINK_DESC_ALIGN);
+				ath12k_dp_reset_rx_reo_tid_q(addr_aligned, rx_tid->ba_win_sz, tid);
+			}
+		}
+	}
+	spin_unlock_bh(&ab->base_lock);
+}
+
 static int ath12k_dp_reo_cmd_send(struct ath12k_base *ab, struct ath12k_dp_rx_tid *rx_tid,
 				  enum hal_reo_cmd_type type,
 				  struct ath12k_hal_reo_cmd *cmd,
@@ -583,7 +605,8 @@ static int ath12k_dp_reo_cmd_send(struct
 	struct hal_srng *cmd_ring;
 	int cmd_num;
 
-	if (test_bit(ATH12K_FLAG_CRASH_FLUSH, &ab->dev_flags))
+	if (test_bit(ATH12K_FLAG_CRASH_FLUSH, &ab->dev_flags) ||
+	    test_bit(ATH12K_FLAG_UMAC_PRERESET_START, &ab->dev_flags))
 		return -ESHUTDOWN;
 
 	cmd_ring = &ab->hal.srng_list[dp->reo_cmd_ring.ring_id];
@@ -988,7 +1011,7 @@ void ath12k_dp_rx_peer_tid_cleanup(struc
 	}
 }
 
-static int ath12k_peer_rx_tid_reo_update(struct ath12k *ar,
+static int ath12k_peer_rx_tid_reo_update(struct ath12k_base *ab,
 					 struct ath12k_peer *peer,
 					 struct ath12k_dp_rx_tid *rx_tid,
 					 u32 ba_win_sz, u16 ssn,
@@ -1008,11 +1031,11 @@ static int ath12k_peer_rx_tid_reo_update
 		cmd.upd2 = u32_encode_bits(ssn, HAL_REO_CMD_UPD2_SSN);
 	}
 
-	ret = ath12k_dp_reo_cmd_send(ar->ab, rx_tid,
+	ret = ath12k_dp_reo_cmd_send(ab, rx_tid,
 				     HAL_REO_CMD_UPDATE_RX_QUEUE, &cmd,
 				     NULL);
 	if (ret) {
-		ath12k_warn(ar->ab, "failed to update rx tid queue, tid %d (%d)\n",
+		ath12k_warn(ab, "failed to update rx tid queue, tid %d (%d)\n",
 			    rx_tid->tid, ret);
 		return ret;
 	}
@@ -1022,6 +1045,68 @@ static int ath12k_peer_rx_tid_reo_update
 	return 0;
 }
 
+void ath12k_dp_peer_reo_tid_setup(struct ath12k_base *ab,
+				  struct ath12k_link_sta *arsta)
+{
+	struct ath12k_dp_rx_tid *rx_tid;
+	struct ath12k_peer *peer;
+	u8 tid;
+	int ret;
+
+	spin_lock_bh(&ab->base_lock);
+	peer = ath12k_peer_find_by_addr(ab, arsta->addr);
+	if (peer) {
+		for (tid = 0; tid <= IEEE80211_NUM_TIDS; tid++) {
+			rx_tid = &peer->rx_tid[tid];
+			if (rx_tid->active) {
+				ret = ath12k_peer_rx_tid_reo_update(ab, peer, rx_tid,
+								    rx_tid->ba_win_sz, 0, false);
+				if (ret) {
+					ath12k_warn(ab, "failed to update reo for peer %pM rx tid %d\n",
+						    peer->addr, tid);
+				}
+			}
+		}
+	}
+	spin_unlock_bh(&ab->base_lock);
+}
+
+void ath12k_dp_tid_setup(void *data, struct ieee80211_sta *sta)
+{
+	struct ath12k_sta *ahsta = (struct ath12k_sta *)sta->drv_priv;
+	struct ath12k_base *ab = data;
+	struct ath12k_link_sta *arsta;
+	struct ath12k_link_vif *arvif;
+	u8 link_id;
+	u16 links_map;
+
+	if (sta->mlo)
+		return;
+
+	links_map = ahsta->links_map;
+	for_each_set_bit(link_id, &links_map, IEEE80211_MLD_MAX_NUM_LINKS) {
+		arsta = ahsta->link[link_id];
+		if (!arsta)
+			continue;
+		arvif = arsta->arvif;
+		if (arvif->ab == ab)
+			ath12k_dp_peer_reo_tid_setup(ab, arsta);
+	}
+}
+
+void ath12k_dp_peer_tid_setup(struct ath12k_base *ab)
+{
+	struct ath12k *ar;
+	int i;
+
+	for (i = 0; i <  ab->num_radios; i++) {
+		ar = ab->pdevs[i].ar;
+		ieee80211_iterate_stations_atomic(ar->ah->hw,
+						  ath12k_dp_tid_setup,
+						  ab);
+	}
+}
+
 int ath12k_dp_rx_peer_tid_setup(struct ath12k *ar, u8 tid, u32 ba_win_sz, u16 ssn,
 				enum hal_pn_type pn_type, struct ath12k_peer *peer)
 {
@@ -1049,7 +1134,7 @@ int ath12k_dp_rx_peer_tid_setup(struct a
 	/* Update the tid queue if it is already setup */
 	if (rx_tid->active) {
 		paddr = rx_tid->paddr;
-		ret = ath12k_peer_rx_tid_reo_update(ar, peer, rx_tid,
+		ret = ath12k_peer_rx_tid_reo_update(ab, peer, rx_tid,
 						    ba_win_sz, ssn, true);
 		if (ret) {
 			ath12k_warn(ab, "failed to update reo for peer %pM rx tid %d\n",
@@ -1195,7 +1280,7 @@ int ath12k_dp_rx_ampdu_stop(struct ath12
 		return 0;
 	}
 
-	ret = ath12k_peer_rx_tid_reo_update(ar, peer, peer->rx_tid, 1, 0, false);
+	ret = ath12k_peer_rx_tid_reo_update(ab, peer, peer->rx_tid, 1, 0, false);
 	spin_unlock_bh(&ab->base_lock);
 	if (ret) {
 		ath12k_warn(ab, "failed to update reo for rx tid %d: %d\n",
--- a/drivers/net/wireless/ath/ath12k/dp_tx.c
+++ b/drivers/net/wireless/ath/ath12k/dp_tx.c
@@ -437,7 +437,8 @@ int ath12k_dp_tx(struct ath12k *ar, stru
 	bool is_diff_encap = false;
 	u8 align_pad, htt_meta_size = 0;
 
-	if (unlikely(test_bit(ATH12K_FLAG_CRASH_FLUSH, &ar->ab->dev_flags)))
+	if (unlikely(test_bit(ATH12K_FLAG_CRASH_FLUSH, &ar->ab->dev_flags)) ||
+	    unlikely(test_bit(ATH12K_FLAG_UMAC_PRERESET_START, &ab->dev_flags)))
 		return -ESHUTDOWN;
 
 	if (unlikely(!(skb_cb->flags & ATH12K_SKB_HW_80211_ENCAP) &&
--- a/drivers/net/wireless/ath/ath12k/hif.h
+++ b/drivers/net/wireless/ath/ath12k/hif.h
@@ -43,6 +43,9 @@ struct ath12k_hif_ops {
 	void (*ppeds_irq_enable)(struct ath12k_base *ab, enum ppeds_irq_type type);
 	void (*ppeds_irq_disable)(struct ath12k_base *ab, enum ppeds_irq_type type);
 #endif
+	int (*dp_umac_reset_irq_config)(struct ath12k_base *ab);
+	void (*dp_umac_reset_enable_irq)(struct ath12k_base *ab);
+	void (*dp_umac_reset_free_irq)(struct ath12k_base *ab);
 };
 
 #ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
@@ -228,4 +231,27 @@ static inline void ath12k_hif_power_down
 	ab->hif.ops->power_down(ab);
 }
 
+static inline int ath12k_hif_dp_umac_reset_irq_config(struct ath12k_base *ab)
+{
+	if (ab->hif.ops->dp_umac_reset_irq_config)
+		return ab->hif.ops->dp_umac_reset_irq_config(ab);
+
+	return 0;
+}
+
+static inline void ath12k_hif_dp_umac_reset_enable_irq(struct ath12k_base *ab)
+{
+	if (ab->hif.ops->dp_umac_reset_enable_irq)
+		return ab->hif.ops->dp_umac_reset_enable_irq(ab);
+
+	return;
+}
+
+static inline void ath12k_hif_dp_umac_reset_free_irq(struct ath12k_base *ab)
+{
+	if (ab->hif.ops->dp_umac_reset_free_irq)
+		return ab->hif.ops->dp_umac_reset_free_irq(ab);
+
+	return;
+}
 #endif /* ATH12K_HIF_H */
--- a/drivers/net/wireless/ath/ath12k/hw.c
+++ b/drivers/net/wireless/ath/ath12k/hw.c
@@ -161,6 +161,8 @@ static const struct ath12k_hw_ops ipq533
 #define ATH12K_PPE2TCL_RING_MASK_0 0x1
 #define ATH12K_REO2PPE_RING_MASK_0 0x1
 #define ATH12K_PPE_WBM2SW_RELEASE_RING_MASK_0 0x1
+#define ATH12K_PPE_WBM2SW_RELEASE_RING_MASK_0 0x1
+#define ATH12K_UMAC_RESET_INTR_MASK_0	0x1
 
 /* Target firmware's Copy Engine configuration. */
 static const struct ce_pipe_config ath12k_target_ce_config_wlan_qcn9274[] = {
@@ -790,7 +792,7 @@ static const struct service_to_pipe ath1
 	},
 };
 
-static const struct ath12k_hw_ring_mask ath12k_hw_ring_mask_qcn9274 = {
+static struct ath12k_hw_ring_mask ath12k_hw_ring_mask_qcn9274 = {
 	.tx  = {
 		ATH12K_TX_RING_MASK_0,
 		ATH12K_TX_RING_MASK_1,
@@ -859,9 +861,13 @@ static const struct ath12k_hw_ring_mask
 		0, 0, ATH12K_PPE_WBM2SW_RELEASE_RING_MASK_0
 	},
 #endif
+	.umac_dp_reset = {
+		0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+		ATH12K_UMAC_RESET_INTR_MASK_0
+	},
 };
 
-static const struct ath12k_hw_ring_mask ath12k_hw_ring_mask_ipq5332 = {
+static struct ath12k_hw_ring_mask ath12k_hw_ring_mask_ipq5332 = {
 	.tx  = {
 		ATH12K_TX_RING_MASK_0,
 		ATH12K_TX_RING_MASK_1,
@@ -909,7 +915,7 @@ static const struct ath12k_hw_ring_mask
 	},
 };
 
-static const struct ath12k_hw_ring_mask ath12k_hw_ring_mask_wcn7850 = {
+static struct ath12k_hw_ring_mask ath12k_hw_ring_mask_wcn7850 = {
 	.tx  = {
 		ATH12K_TX_RING_MASK_0,
 		ATH12K_TX_RING_MASK_2,
@@ -1422,7 +1428,7 @@ static const struct ath12k_hw_hal_params
 			    HAL_WBM_SW_COOKIE_CONV_CFG_WBM2SW4_EN,
 };
 
-static const struct ath12k_hw_params ath12k_hw_params[] = {
+static struct ath12k_hw_params ath12k_hw_params[] = {
 	{
 		.name = "qcn9274 hw1.0",
 		.hw_rev = ATH12K_HW_QCN9274_HW10,
@@ -1499,6 +1505,7 @@ static const struct ath12k_hw_params ath
 		.compact_rx_tlv = true,
 		.send_platform_model = false,
 		.en_fwlog = true,
+		.support_umac_reset = false,
 	},
 	{
 		.name = "wcn7850 hw2.0",
@@ -1568,6 +1575,7 @@ static const struct ath12k_hw_params ath
 		.compact_rx_tlv = false,
 		.send_platform_model = false,
 		.en_fwlog = true,
+		.support_umac_reset = false,
 	},
 	{
 		.name = "qcn9274 hw2.0",
@@ -1645,6 +1653,7 @@ static const struct ath12k_hw_params ath
 		.compact_rx_tlv = true,
 		.send_platform_model = false,
 		.en_fwlog = true,
+		.support_umac_reset = true,
 	},
 	{
 		.name = "ipq5332 hw1.0",
@@ -1725,9 +1734,69 @@ static const struct ath12k_hw_params ath
 		.pmm_remap = &ath12k_pmm_ipq5332,
 		.send_platform_model = true,
 		.en_fwlog = true,
+		.support_umac_reset = false,
 	},
 };
 
+void ath12k_dp_reset_interrupt_mask(struct ath12k_base *ab)
+{
+	struct ath12k_hw_ring_mask *ring_mask = ab->hw_params->ring_mask;
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *umac_reset = &ag->mlo_umac_reset;
+	int i;
+
+	if (ag->mlo_umac_reset.is_intr_bkup)
+		return;
+
+	for (i = 0; i < ATH12K_EXT_IRQ_GRP_NUM_MAX; i++) {
+		umac_reset->intr_bkup.tx[i] = ring_mask->tx[i];
+
+		umac_reset->intr_bkup.rx_mon_dest[i] = ring_mask->rx_mon_dest[i];
+		umac_reset->intr_bkup.rx[i] = ring_mask->rx[i];
+		umac_reset->intr_bkup.rx_err[i] = ring_mask->rx_err[i];
+		umac_reset->intr_bkup.rx_wbm_rel[i] = ring_mask->rx_wbm_rel[i];
+		umac_reset->intr_bkup.reo_status[i] = ring_mask->reo_status[i];
+		umac_reset->intr_bkup.host2rxdma[i] = ring_mask->host2rxdma[i];
+		umac_reset->intr_bkup.tx_mon_dest[i] = ring_mask->tx_mon_dest[i];
+
+		ring_mask->tx[i] = 0;
+		ring_mask->rx_mon_dest[i] = 0;
+		ring_mask->rx[i] = 0;
+		ring_mask->rx_err[i] = 0;
+		ring_mask->rx_wbm_rel[i] = 0;
+		ring_mask->reo_status[i] = 0;
+		ring_mask->host2rxdma[i] = 0;
+		ring_mask->tx_mon_dest[i] = 0;
+	}
+
+	ag->mlo_umac_reset.is_intr_bkup = true;
+}
+
+void ath12k_dp_restore_interrupt_mask(struct ath12k_base *ab)
+{
+	struct ath12k_hw_ring_mask *ring_mask = ab->hw_params->ring_mask;
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *umac_reset = &ag->mlo_umac_reset;
+	int i;
+
+	if (!ag->mlo_umac_reset.is_intr_bkup)
+		return;
+
+	for (i = 0; i < ATH12K_EXT_IRQ_GRP_NUM_MAX; i++) {
+		ring_mask->tx[i] = umac_reset->intr_bkup.tx[i];
+		ring_mask->rx_mon_dest[i] = umac_reset->intr_bkup.rx_mon_dest[i];
+		ring_mask->rx[i] = umac_reset->intr_bkup.rx[i];
+		ring_mask->rx_err[i] = umac_reset->intr_bkup.rx_err[i];
+		ring_mask->rx_wbm_rel[i] = umac_reset->intr_bkup.rx_wbm_rel[i];
+		ring_mask->reo_status[i] = umac_reset->intr_bkup.reo_status[i];
+		ring_mask->host2rxdma[i] = umac_reset->intr_bkup.host2rxdma[i];
+		ring_mask->tx_mon_dest[i] = umac_reset->intr_bkup.tx_mon_dest[i];
+	}
+
+	ag->mlo_umac_reset.is_intr_bkup = false;
+
+}
+
 int ath12k_hw_init(struct ath12k_base *ab)
 {
 	const struct ath12k_hw_params *hw_params = NULL;
--- a/drivers/net/wireless/ath/ath12k/hw.h
+++ b/drivers/net/wireless/ath/ath12k/hw.h
@@ -117,8 +117,8 @@ enum ath12k_bus {
 	ATH12K_BUS_AHB,
 };
 
-/* Regular 12 Host DP interrupts + 3 PPEDS interrupts */
-#define ATH12K_EXT_IRQ_DP_NUM_VECTORS 15
+/* Regular 12 Host DP interrupts + 3 PPEDS interrupts + 1 DP UMAC RESET interrupt*/
+#define ATH12K_EXT_IRQ_DP_NUM_VECTORS 16
 #define ATH12K_EXT_IRQ_GRP_NUM_MAX 12
 struct hal_rx_desc;
 struct hal_tcl_data_cmd;
@@ -139,6 +139,7 @@ struct ath12k_hw_ring_mask {
 #ifdef CPTCFG_ATH12K_PPE_DS_SUPPORT
 	u8 wbm2sw6_ppeds_tx_cmpln[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
 #endif
+	u8 umac_dp_reset[ATH12K_EXT_IRQ_DP_NUM_VECTORS];
 };
 
 struct ath12k_hw_hal_params {
@@ -163,7 +164,7 @@ struct ath12k_hw_params {
 	bool internal_sleep_clock;
 
 	const struct ath12k_hw_ops *hw_ops;
-	const struct ath12k_hw_ring_mask *ring_mask;
+	struct ath12k_hw_ring_mask *ring_mask;
 	const struct ath12k_hw_regs *regs;
 
 	const struct ce_attr *host_ce_config;
@@ -231,6 +232,7 @@ struct ath12k_hw_params {
 	const struct cmem_remap *cmem_remap;
 	bool compact_rx_tlv;
 	const struct pmm_remap *pmm_remap;
+	bool support_umac_reset;
 };
 
 /* BRINGUP: move to dp.h */
--- a/drivers/net/wireless/ath/ath12k/pci.c
+++ b/drivers/net/wireless/ath/ath12k/pci.c
@@ -95,7 +95,7 @@ static const struct ath12k_msi_config at
 		.users = (struct ath12k_msi_user[]) {
 			{ .name = "MHI", .num_vectors = 3, .base_vector = 0 },
 			{ .name = "CE", .num_vectors = 5, .base_vector = 3 },
-			{ .name = "DP", .num_vectors = 15, .base_vector = 8 },
+			{ .name = "DP", .num_vectors = 16, .base_vector = 8 },
 		},
 	},
 };
@@ -742,6 +742,70 @@ static int ath12k_pci_config_irq(struct
 	return 0;
 }
 
+static void ath12k_umac_reset_tasklet_handler(struct tasklet_struct *t)
+{
+	struct ath12k_dp_umac_reset *umac_reset = from_tasklet(umac_reset, t, intr_tq);
+	struct ath12k_base *ab = container_of(umac_reset, struct ath12k_base, dp_umac_reset);
+
+	ath12k_dp_umac_reset_handle(ab);
+	enable_irq(umac_reset->irq_num);
+}
+
+static irqreturn_t ath12k_dp_umac_reset_interrupt_handler(int irq, void *arg)
+{
+	struct ath12k_base *ab = arg;
+	struct ath12k_dp_umac_reset *umac_reset = &ab->dp_umac_reset;
+
+	disable_irq_nosync(umac_reset->irq_num);
+	tasklet_schedule(&umac_reset->intr_tq);
+	return IRQ_HANDLED;
+}
+
+static void ath12k_dp_umac_reset_enable_irq(struct ath12k_base *ab)
+{
+	struct ath12k_dp_umac_reset *umac_reset = &ab->dp_umac_reset;
+
+	enable_irq(umac_reset->irq_num);
+}
+
+static int ath12k_dp_umac_pci_config_irq(struct ath12k_base *ab)
+{
+        u32 msi_data_start, msi_data_count, msi_irq_start;
+        unsigned int msi_data;
+        int irq, ret;
+	struct ath12k_dp_umac_reset *umac_reset = &ab->dp_umac_reset;
+
+        ret = ath12k_pci_get_user_msi_assignment(ab,
+                                                 "DP", &msi_data_count,
+                                                 &msi_data_start, &msi_irq_start);
+        if (ret)
+                return ret;
+
+	msi_data = (umac_reset->intr_offset % msi_data_count) + msi_irq_start;
+	irq = ath12k_pci_get_msi_irq(ab->dev, msi_data);
+	umac_reset->irq_num = irq;
+	tasklet_setup(&umac_reset->intr_tq, ath12k_umac_reset_tasklet_handler);
+
+	ret = request_irq(irq, ath12k_dp_umac_reset_interrupt_handler,
+			  IRQF_NO_SUSPEND, "umac_dp_reset", ab);
+	if (ret) {
+		ath12k_err(ab, "failed to request irq for umac dp reset %d\n", ret);
+		return ret;
+	}
+
+	disable_irq_nosync(umac_reset->irq_num);
+
+	return 0;
+}
+
+static void ath12k_dp_umac_reset_free_irq(struct ath12k_base *ab)
+{
+	struct ath12k_dp_umac_reset *umac_reset = &ab->dp_umac_reset;
+
+	disable_irq_nosync(umac_reset->irq_num);
+	free_irq(umac_reset->irq_num, ab);
+}
+
 static void ath12k_pci_init_qmi_ce_config(struct ath12k_base *ab)
 {
 	struct ath12k_qmi_ce_cfg *cfg = &ab->qmi.ce_cfg;
@@ -1373,6 +1437,9 @@ static const struct ath12k_hif_ops ath12
 	.ppeds_irq_enable = ath12k_pci_ppeds_irq_enable,
 	.ppeds_irq_disable = ath12k_pci_ppeds_irq_disable,
 #endif
+	.dp_umac_reset_irq_config = ath12k_dp_umac_pci_config_irq,
+	.dp_umac_reset_enable_irq = ath12k_dp_umac_reset_enable_irq,
+	.dp_umac_reset_free_irq = ath12k_dp_umac_reset_free_irq,
 };
 
 static int ath12k_pci_probe(struct pci_dev *pdev,
--- /dev/null
+++ b/drivers/net/wireless/ath/ath12k/umac_reset.c
@@ -0,0 +1,468 @@
+/* SPDX-License-Identifier: BSD-3-Clause-Clear */
+/*
+ * Copyright (c) 2023 Qualcomm Innovation Center, Inc. All rights reserved.
+ */
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/remoteproc.h>
+#include <linux/firmware.h>
+#include <linux/of.h>
+#include <linux/of_platform.h>
+
+#include "core.h"
+#include "coredump.h"
+#include "dp_tx.h"
+#include "dp_rx.h"
+#include "debug.h"
+#include "hif.h"
+
+int ath12k_htt_umac_reset_msg_send(struct ath12k_base *ab,
+				   struct ath12k_htt_umac_reset_setup_cmd_params *params)
+{
+	struct sk_buff *skb;
+	struct htt_dp_umac_reset_setup_req_cmd *cmd;
+	int ret;
+	int len = sizeof(*cmd);
+
+	skb = ath12k_htc_alloc_skb(ab, len);
+	if (!skb)
+		return -ENOMEM;
+
+	skb_put(skb, len);
+	cmd = (struct htt_dp_umac_reset_setup_req_cmd *)skb->data;
+	cmd->msg_info = u32_encode_bits(HTT_H2T_MSG_TYPE_UMAC_RESET_PREREQUISITE_SETUP,
+					HTT_H2T_MSG_TYPE_SET);
+	cmd->msg_info |= u32_encode_bits(0, HTT_H2T_MSG_METHOD);
+	cmd->msg_info |= u32_encode_bits(0, HTT_T2H_MSG_METHOD);
+	cmd->msi_data = params->msi_data;
+	cmd->msg_shared_mem.size = sizeof(struct htt_h2t_paddr_size);
+	cmd->msg_shared_mem.addr_lo = params->addr_lo;
+	cmd->msg_shared_mem.addr_hi = params->addr_hi;
+
+
+	ret = ath12k_htc_send(&ab->htc, ab->dp.eid, skb);
+
+	if (ret) {
+		ath12k_warn(ab, "DP UMAC INIT msg send failed ret:%d\n", ret);
+		goto err_free;
+	}
+
+	ath12k_dbg(ab, ATH12K_DBG_DP_UMAC_RESET, "DP UMAC INIT msg sent from host\n");
+	return 0;
+
+err_free:
+	dev_kfree_skb_any(skb);
+	return ret;
+}
+
+int ath12k_htt_umac_reset_send_start_pre_reset_cmd(struct ath12k_base *ab, int is_initiator,
+						   int is_target_recovery)
+{
+	struct sk_buff *skb;
+	struct h2t_umac_hang_recovery_start_pre_reset *cmd;
+	int ret;
+	int len = sizeof(*cmd);
+
+	skb = ath12k_htc_alloc_skb(ab, len);
+	if (!skb)
+		return -ENOMEM;
+
+	skb_put(skb, len);
+	cmd = (struct h2t_umac_hang_recovery_start_pre_reset*)skb->data;
+	memset(cmd, 0, sizeof(*cmd));
+	cmd->hdr = u32_encode_bits(HTT_H2T_MSG_TYPE_UMAC_RESET_START_PRE_RESET,
+				   HTT_H2T_UMAC_RESET_MSG_TYPE);
+	cmd->hdr |= u32_encode_bits(is_initiator, HTT_H2T_UMAC_RESET_IS_INITIATOR_SET);
+	cmd->hdr |= u32_encode_bits(is_target_recovery, HTT_H2T_UMAC_RESET_IS_TARGET_RECOVERY_SET);
+
+	ret = ath12k_htc_send(&ab->htc, ab->dp.eid, skb);
+	if (ret) {
+                ath12k_warn(ab, "failed to send htt umac reset pre reset start: %d\n",
+			    ret);
+		dev_kfree_skb_any(skb);
+		return ret;
+	}
+
+	return 0;
+}
+
+int ath12k_get_umac_reset_intr_offset(struct ath12k_base *ab)
+{
+	int i;
+
+	for (i = 0; i < ATH12K_EXT_IRQ_NUM_MAX; i++) {
+		if (ab->hw_params->ring_mask->umac_dp_reset[i])
+			return i;
+	}
+	return 0;
+}
+
+int ath12k_htt_umac_reset_setup_cmd(struct ath12k_base *ab)
+{
+	int msi_data_count;
+	struct ath12k_htt_umac_reset_setup_cmd_params params = {};
+	u32 msi_data_start, msi_irq_start;
+	int ret, intr_ctxt;
+	struct ath12k_dp_umac_reset *umac_reset = &ab->dp_umac_reset;
+
+	intr_ctxt = ath12k_get_umac_reset_intr_offset(ab);
+	ret = ath12k_hif_get_user_msi_vector(ab, "DP",
+					     &msi_data_count, &msi_data_start,
+					     &msi_irq_start);
+	if (ret)
+		params.msi_data = ATH12K_UMAC_RESET_IPC;
+	else
+		params.msi_data = (intr_ctxt % msi_data_count) + msi_data_start;
+	params.addr_lo = umac_reset->shmem_paddr_aligned & HAL_ADDR_LSB_REG_MASK;
+	params.addr_hi = (u64)umac_reset->shmem_paddr_aligned >> HAL_ADDR_MSB_REG_SHIFT;
+
+	return ath12k_htt_umac_reset_msg_send(ab, &params);
+}
+
+int ath12k_dp_umac_reset_init(struct ath12k_base *ab)
+{
+	struct ath12k_dp_umac_reset *umac_reset;
+	int alloc_size, ret;
+
+	if (!ab->hw_params->support_umac_reset)
+		return 0;
+
+	umac_reset = &ab->dp_umac_reset;
+	umac_reset->magic_num = ATH12K_DP_UMAC_RESET_SHMEM_MAGIC_NUM;
+
+	alloc_size = sizeof(struct ath12k_dp_htt_umac_reset_recovery_msg_shmem_t) +
+			    ATH12K_DP_UMAC_RESET_SHMEM_ALIGN - 1;
+
+	umac_reset->shmem_vaddr_unaligned = dma_alloc_coherent(ab->dev,
+                                                     alloc_size,
+                                                     &umac_reset->shmem_paddr_unaligned,
+                                                     GFP_KERNEL);
+	if (!umac_reset->shmem_vaddr_unaligned) {
+		ath12k_warn(ab, "Failed to allocate memory with size:%u\n", alloc_size);
+		return -ENOMEM;
+	}
+
+	umac_reset->shmem_vaddr_aligned =
+		PTR_ALIGN(umac_reset->shmem_vaddr_unaligned, ATH12K_DP_UMAC_RESET_SHMEM_ALIGN);
+	umac_reset->shmem_paddr_aligned =
+		umac_reset->shmem_paddr_unaligned + ((unsigned long)umac_reset->shmem_vaddr_aligned -
+				(unsigned long)umac_reset->shmem_vaddr_unaligned);
+	umac_reset->shmem_size = alloc_size;
+	umac_reset->shmem_vaddr_aligned->magic_num = ATH12K_DP_UMAC_RESET_SHMEM_MAGIC_NUM;
+	umac_reset->intr_offset = ath12k_get_umac_reset_intr_offset(ab);
+
+	ret = ath12k_hif_dp_umac_reset_irq_config(ab);
+	if (ret) {
+		ath12k_warn(ab, "Failed to register interrupt for UMAC RECOVERY\n");
+		goto shmem_free;
+	}
+
+	ret = ath12k_htt_umac_reset_setup_cmd(ab);
+	if (ret) {
+		ath12k_warn(ab, "Unable to setup UMAC RECOVERY\n");
+		goto free_irq;
+	}
+
+	ath12k_hif_dp_umac_reset_enable_irq(ab);
+	return 0;
+
+free_irq:
+	ath12k_hif_dp_umac_reset_free_irq(ab);
+shmem_free:
+	dma_free_coherent(ab->dev,
+			  umac_reset->shmem_size,
+			  umac_reset->shmem_vaddr_unaligned,
+			  umac_reset->shmem_paddr_unaligned);
+	umac_reset->shmem_vaddr_unaligned = NULL;
+	return ret;
+}
+
+void ath12k_umac_reset_pre_reset_validation(struct ath12k_base *ab, bool *is_initiator,
+					    bool *is_target_recovery)
+{
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *mlo_umac_reset;
+	*is_initiator = *is_target_recovery = false;
+
+	if (!ag)
+		return;
+
+	mlo_umac_reset = &ag->mlo_umac_reset;
+
+	spin_lock_bh(&mlo_umac_reset->lock);
+	if (mlo_umac_reset->initiator_chip == ab->chip_id)
+		*is_initiator = true;
+	if (mlo_umac_reset->umac_reset_info & BIT(1))
+		*is_target_recovery = true;
+	spin_unlock_bh(&mlo_umac_reset->lock);
+}
+
+void ath12k_umac_reset_completion(struct ath12k_base *ab)
+{
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *mlo_umac_reset = &ag->mlo_umac_reset;
+
+	if (!mlo_umac_reset)
+		return;
+
+	if (!(mlo_umac_reset->umac_reset_info & BIT(0)))
+		return;
+
+	spin_lock_bh(&mlo_umac_reset->lock);
+	mlo_umac_reset->umac_reset_info = 0;
+	mlo_umac_reset->initiator_chip = 0;
+	spin_unlock_bh(&mlo_umac_reset->lock);
+}
+
+void ath12k_umac_reset_send_htt(struct ath12k_base *ab, int tx_event)
+{
+	struct ath12k_dp_umac_reset *umac_reset = &ab->dp_umac_reset;
+	struct ath12k_dp_htt_umac_reset_recovery_msg_shmem_t *shmem_vaddr_aligned;
+	bool is_initiator, is_target_recovery;
+	int ret;
+
+	shmem_vaddr_aligned = umac_reset->shmem_vaddr_aligned;
+
+	switch(tx_event) {
+	case ATH12K_UMAC_RESET_TX_CMD_TRIGGER_DONE:
+		ath12k_umac_reset_pre_reset_validation(ab, &is_initiator,
+						       &is_target_recovery);
+		ret = ath12k_htt_umac_reset_send_start_pre_reset_cmd(ab,
+								     is_initiator,
+								     is_target_recovery);
+		ab->dp_umac_reset.ts.trigger_done = jiffies_to_msecs(jiffies);
+		if (ret)
+			ath12k_warn(ab, "Unable to send umac trigger\n");
+		break;
+	case ATH12K_UMAC_RESET_TX_CMD_PRE_RESET_DONE:
+		shmem_vaddr_aligned->h2t_msg = u32_encode_bits(1,
+						ATH12K_HTT_UMAC_RESET_MSG_SHMEM_PRE_RESET_DONE_SET);
+		ab->dp_umac_reset.ts.pre_reset_done = jiffies_to_msecs(jiffies);
+		break;
+	case ATH12K_UMAC_RESET_TX_CMD_POST_RESET_START_DONE:
+		shmem_vaddr_aligned->h2t_msg = u32_encode_bits(1,
+						ATH12K_HTT_UMAC_RESET_MSG_SHMEM_POST_RESET_START_DONE_SET);
+		ab->dp_umac_reset.ts.post_reset_done = jiffies_to_msecs(jiffies);
+		break;
+	case ATH12K_UMAC_RESET_TX_CMD_POST_RESET_COMPLETE_DONE:
+		shmem_vaddr_aligned->h2t_msg = u32_encode_bits(1,
+				ATH12K_HTT_UMAC_RESET_MSG_SHMEM_POST_RESET_COMPLETE_DONE);
+		ab->dp_umac_reset.ts.post_reset_complete_done = jiffies_to_msecs(jiffies);
+		break;
+        }
+
+	if (tx_event == ATH12K_UMAC_RESET_TX_CMD_POST_RESET_COMPLETE_DONE) {
+		ath12k_info(ab, "MLO UMAC Recovery completed\n");
+		ath12k_umac_reset_completion(ab);
+		ath12k_dbg(ab, ATH12K_DBG_DP_UMAC_RESET, "Time taken for trigger_start:%llums "
+			   "trigger_done: %llums pre_reset:%llums post_reset:%llums "
+			   "post_reset_complete:%llums",
+			   ab->dp_umac_reset.ts.trigger_start, ab->dp_umac_reset.ts.trigger_done,
+			   ab->dp_umac_reset.ts.pre_reset_done - ab->dp_umac_reset.ts.pre_reset_start,
+			   ab->dp_umac_reset.ts.post_reset_done - ab->dp_umac_reset.ts.post_reset_start,
+			   ab->dp_umac_reset.ts.post_reset_complete_done - ab->dp_umac_reset.ts.post_reset_complete_start);
+		memset(&umac_reset->ts, 0, sizeof(struct ath12k_umac_reset_ts));
+	}
+
+	return;
+}
+
+int ath12k_umac_reset_notify_target(struct ath12k_base *ab, int tx_event)
+{
+	struct ath12k_base *partner_ab;
+	struct ath12k_hw_group *ag = ab->ag;
+	int i;
+
+	for (i = 0; i < ag->num_chip; i++) {
+		partner_ab = ag->ab[i];
+
+		if (test_bit(ATH12K_FLAG_RECOVERY, &partner_ab->dev_flags))
+			continue;
+
+		ath12k_umac_reset_send_htt(partner_ab, tx_event);
+	}
+
+	return 0;
+}
+
+void ath12k_umac_reset_initiate_recovery(struct ath12k_base *ab)
+{
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *mlo_umac_reset = &ag->mlo_umac_reset;
+
+	if (!mlo_umac_reset)
+		return;
+
+	spin_lock_bh(&mlo_umac_reset->lock);
+
+	if (mlo_umac_reset->umac_reset_info &
+	    ATH12K_IS_UMAC_RESET_IN_PROGRESS) {
+		spin_unlock_bh(&mlo_umac_reset->lock);
+		ath12k_warn(ab, "UMAC RECOVERY IS IN PROGRESS\n");
+		return;
+	}
+	mlo_umac_reset->umac_reset_info = BIT(0); /* UMAC recovery is in progress */
+	mlo_umac_reset->umac_reset_info |= BIT(1); /* Target recovery */
+	atomic_set(&mlo_umac_reset->response_chip, 0);
+	mlo_umac_reset->initiator_chip = ab->chip_id;
+	spin_unlock_bh(&mlo_umac_reset->lock);
+}
+
+void ath12k_umac_reset_notify_target_sync_and_send(struct ath12k_base *ab,
+						   enum dp_umac_reset_tx_cmd tx_event)
+{
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *mlo_umac_reset = &ag->mlo_umac_reset;
+
+	if (atomic_read(&mlo_umac_reset->response_chip) >= ab->ag->num_started) {
+		ath12k_dbg(ab, ATH12K_DBG_DP_UMAC_RESET, "response chip:%d num_started:%d sending notify\n",
+			   atomic_read(&mlo_umac_reset->response_chip), ab->ag->num_started);
+		ath12k_umac_reset_notify_target(ab, tx_event);
+		atomic_set(&mlo_umac_reset->response_chip, 0);
+	} else {
+		ath12k_dbg(ab, ATH12K_DBG_DP_UMAC_RESET, "response_chip:%d num_started:%d not matching.. hold on notify\n",
+			   atomic_read(&mlo_umac_reset->response_chip), ab->ag->num_started);
+	}
+	return;
+}
+
+void ath12k_umac_reset_handle_pre_reset(struct ath12k_base *ab)
+{
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *mlo_umac_reset = &ag->mlo_umac_reset;
+
+	set_bit(ATH12K_FLAG_UMAC_PRERESET_START, &ab->dev_flags);
+	ath12k_dp_reset_interrupt_mask(ab);
+	atomic_inc(&mlo_umac_reset->response_chip);
+
+	ath12k_umac_reset_notify_target_sync_and_send(ab, ATH12K_UMAC_RESET_TX_CMD_PRE_RESET_DONE);
+	return;
+}
+
+void ath12k_umac_reset_handle_post_reset_complete(struct ath12k_base *ab)
+{
+	struct ath12k_hw_group *ag = ab->ag;
+	struct ath12k_mlo_dp_umac_reset *mlo_umac_reset = &ag->mlo_umac_reset;
+
+	clear_bit(ATH12K_FLAG_UMAC_PRERESET_START, &ab->dev_flags);
+
+	atomic_inc(&mlo_umac_reset->response_chip);
+	ath12k_dp_restore_interrupt_mask(ab);
+	ath12k_umac_reset_notify_target_sync_and_send(ab, ATH12K_UMAC_RESET_TX_CMD_POST_RESET_COMPLETE_DONE);
+	ath12k_dp_peer_tid_setup(ab);
+	return;
+}
+
+void ath12k_dp_umac_reset_action(struct ath12k_base *ab,
+				 enum dp_umac_reset_recover_action rx_event)
+{
+	switch(rx_event) {
+	case ATH12K_UMAC_RESET_INIT_UMAC_RECOVERY:
+	case ATH12K_UMAC_RESET_INIT_TARGET_RECOVERY_SYNC_USING_UMAC:
+		ath12k_umac_reset_initiate_recovery(ab);
+		ab->dp_umac_reset.ts.trigger_start = jiffies_to_msecs(jiffies);
+		ath12k_umac_reset_notify_target(ab, ATH12K_UMAC_RESET_TX_CMD_TRIGGER_DONE);
+		break;
+	case ATH12K_UMAC_RESET_DO_POST_RESET_COMPLETE:
+		ab->dp_umac_reset.ts.post_reset_complete_start = jiffies_to_msecs(jiffies);
+		ath12k_umac_reset_handle_post_reset_complete(ab);
+		break;
+	case ATH12K_UMAC_RESET_DO_POST_RESET_START:
+		ab->dp_umac_reset.ts.post_reset_start = jiffies_to_msecs(jiffies);
+		ath12k_umac_reset_handle_post_reset_start(ab);
+		break;
+	case ATH12K_UMAC_RESET_DO_PRE_RESET:
+		ab->dp_umac_reset.ts.pre_reset_start = jiffies_to_msecs(jiffies);
+		ath12k_umac_reset_handle_pre_reset(ab);
+		break;
+	default:
+		ath12k_dbg(ab, ATH12K_DBG_DP_UMAC_RESET, "Unknown UMAC RESET event received\n");
+		break;
+	}
+	return;
+}
+
+void ath12k_dp_umac_reset_handle(struct ath12k_base *ab)
+{
+	struct ath12k_dp_umac_reset *umac_reset = &ab->dp_umac_reset;
+	struct ath12k_dp_htt_umac_reset_recovery_msg_shmem_t *shmem_vaddr;
+	int rx_event, num_event = 0;
+	u32 t2h_msg;
+
+	shmem_vaddr = umac_reset->shmem_vaddr_aligned;
+	if (!shmem_vaddr) {
+		ath12k_dbg(ab, ATH12K_DBG_DP_UMAC_RESET, "Shared memory address NULL\n");
+		return;
+	}
+
+	if (shmem_vaddr->magic_num != umac_reset->magic_num) {
+		ath12k_dbg(ab, ATH12K_DBG_DP_UMAC_RESET, "Shared memory address is invalid shmem:0x%x u:0x%x\n",
+			   shmem_vaddr->magic_num, umac_reset->magic_num);
+		return;
+	}
+
+	t2h_msg = shmem_vaddr->t2h_msg;
+	shmem_vaddr->t2h_msg = 0;
+
+	rx_event = ATH12K_UMAC_RESET_RX_EVENT_NONE;
+
+	if (u32_get_bits(t2h_msg, HTT_ATH12K_UMAC_RESET_T2H_INIT_UMAC_RECOVERY)) {
+		rx_event |= ATH12K_UMAC_RESET_INIT_UMAC_RECOVERY;
+		num_event++;
+	}
+
+	if (u32_get_bits(t2h_msg, HTT_ATH12K_UMAC_RESET_T2H_INIT_TARGET_RECOVERY_SYNC_USING_UMAC)) {
+		rx_event |= ATH12K_UMAC_RESET_INIT_TARGET_RECOVERY_SYNC_USING_UMAC;
+		num_event++;
+	}
+
+	if (u32_get_bits(t2h_msg, HTT_ATH12K_UMAC_RESET_T2H_DO_PRE_RESET)) {
+		rx_event |= ATH12K_UMAC_RESET_DO_PRE_RESET;
+		num_event++;
+	}
+
+	if (u32_get_bits(t2h_msg, HTT_ATH12K_UMAC_RESET_T2H_DO_POST_RESET_START)) {
+		rx_event |= ATH12K_UMAC_RESET_DO_POST_RESET_START;
+		num_event++;
+	}
+
+	if (u32_get_bits(t2h_msg, HTT_ATH12K_UMAC_RESET_T2H_DO_POST_RESET_COMPLETE)) {
+		rx_event |= ATH12K_UMAC_RESET_DO_POST_RESET_COMPLETE;
+		num_event++;
+	}
+
+	ath12k_dbg(ab, ATH12K_DBG_DP_UMAC_RESET, "Deduced rx event:%d num:%d\n", rx_event, num_event);
+
+	if (num_event > 1) {
+		ath12k_dbg(ab, ATH12K_DBG_DP_UMAC_RESET, "Multiple event notified in single msg\n");
+		WARN_ON_ONCE(1);
+		return;
+	}
+
+	ath12k_dp_umac_reset_action(ab, rx_event);
+	return;
+}
+
+void ath12k_dp_umac_reset_deinit(struct ath12k_base *ab)
+{
+	struct ath12k_dp_umac_reset *umac_reset;
+
+	if (!ab->hw_params->support_umac_reset)
+		return;
+
+	umac_reset = &ab->dp_umac_reset;
+
+	if (!umac_reset)
+		return;
+
+	ath12k_hif_dp_umac_reset_free_irq(ab);
+
+	if (umac_reset->shmem_vaddr_unaligned) {
+		dma_free_coherent(ab->dev,
+				  umac_reset->shmem_size,
+				  umac_reset->shmem_vaddr_unaligned,
+				  umac_reset->shmem_paddr_unaligned);
+		umac_reset->shmem_vaddr_unaligned = NULL;
+
+	}
+}
--- a/drivers/net/wireless/ath/ath12k/dp_rx.h
+++ b/drivers/net/wireless/ath/ath12k/dp_rx.h
@@ -228,4 +228,10 @@ ath12k_dp_rx_htt_rxdma_rxole_ppe_cfg_set
 int ath12k_dp_rx_pkt_type_filter(struct ath12k *ar,
 				 enum ath12k_routing_pkt_type pkt_type,
 				 u32 meta_data);
+void ath12k_dp_tid_cleanup(struct ath12k_base *ab);
+void ath12k_dp_peer_tid_setup(struct ath12k_base *ab);
+void ath12k_dp_peer_reo_tid_setup(struct ath12k_base *ab, struct ath12k_link_sta *arsta);
+void ath12k_dp_tid_setup(void *data, struct ieee80211_sta *sta);
+void ath12k_dp_reset_rx_reo_tid_q(void *vaddr, u32 ba_window_size,
+				  u8 tid);
 #endif /* ATH12K_DP_RX_H */
--- a/drivers/net/wireless/ath/ath12k/hal_rx.c
+++ b/drivers/net/wireless/ath/ath12k/hal_rx.c
@@ -964,3 +964,51 @@ void ath12k_hal_reo_shared_qaddr_cache_c
 	ath12k_hif_write32(ab, HAL_SEQ_WCSS_UMAC_REO_REG +
 			   HAL_REO1_QDESC_ADDR_READ(ab), val);
 }
+
+void ath12k_dp_reset_rx_reo_tid_q(void *vaddr, u32 ba_window_size,
+				  u8 tid)
+{
+	struct hal_rx_reo_queue *qdesc = (struct hal_rx_reo_queue *)vaddr;
+	struct hal_rx_reo_queue_ext *ext_desc;
+	u32 size, info0, info1, rx_queue_num;
+
+	size = ath12k_hal_reo_qdesc_size(ba_window_size, tid);
+
+	rx_queue_num = qdesc->rx_queue_num;
+	info0 = qdesc->info0;
+	info1 = qdesc->info1;
+
+	memset(qdesc, 0, size);
+
+	ath12k_hal_reo_set_desc_hdr(&qdesc->desc_hdr, HAL_DESC_REO_OWNED,
+				    HAL_DESC_REO_QUEUE_DESC,
+				    REO_QUEUE_DESC_MAGIC_DEBUG_PATTERN_0);
+
+	qdesc->rx_queue_num = rx_queue_num;
+	qdesc->info0 = info0;
+	qdesc->info1 = info1;
+
+	qdesc->info1 |= u32_encode_bits(0, HAL_RX_REO_QUEUE_INFO1_SVLD);
+	qdesc->info1 |= u32_encode_bits(0,
+				       HAL_RX_REO_QUEUE_INFO1_SSN);
+
+	if (tid == HAL_DESC_REO_NON_QOS_TID)
+		return;
+
+	ext_desc = qdesc->ext_desc;
+	memset(ext_desc, 0, 3 * sizeof(*ext_desc));
+
+	ath12k_hal_reo_set_desc_hdr(&ext_desc->desc_hdr, HAL_DESC_REO_OWNED,
+				    HAL_DESC_REO_QUEUE_EXT_DESC,
+				    REO_QUEUE_DESC_MAGIC_DEBUG_PATTERN_1);
+	ext_desc++;
+
+	ath12k_hal_reo_set_desc_hdr(&ext_desc->desc_hdr, HAL_DESC_REO_OWNED,
+				    HAL_DESC_REO_QUEUE_EXT_DESC,
+				    REO_QUEUE_DESC_MAGIC_DEBUG_PATTERN_2);
+	ext_desc++;
+
+	ath12k_hal_reo_set_desc_hdr(&ext_desc->desc_hdr, HAL_DESC_REO_OWNED,
+				    HAL_DESC_REO_QUEUE_EXT_DESC,
+				    REO_QUEUE_DESC_MAGIC_DEBUG_PATTERN_3);
+}
--- a/drivers/net/wireless/ath/ath12k/hal.c
+++ b/drivers/net/wireless/ath/ath12k/hal.c
@@ -2233,6 +2233,12 @@ int ath12k_hal_srng_setup_idx(struct ath
 	memset(srng->ring_base_vaddr, 0,
 	       (srng->entry_size * srng->num_entries) << 2);
 
+	if (srng->flags & HAL_SRNG_FLAGS_CACHED) {
+		dmac_inv_range_no_dsb(srng->ring_base_vaddr,
+				      srng->ring_base_vaddr +
+				      ((srng->entry_size * srng->num_entries)));
+	}
+
 	/* TODO: Add comments on these swap configurations */
 	if (IS_ENABLED(CONFIG_CPU_BIG_ENDIAN))
 		srng->flags |= HAL_SRNG_FLAGS_MSI_SWAP | HAL_SRNG_FLAGS_DATA_TLV_SWAP |
@@ -2247,6 +2253,10 @@ int ath12k_hal_srng_setup_idx(struct ath
 		srng->u.src_ring.tp_addr = (void *)(hal->rdp.vaddr + ring_id);
 		srng->u.src_ring.low_threshold = params->low_threshold *
 						 srng->entry_size;
+
+		if (srng->u.src_ring.tp_addr)
+			*srng->u.src_ring.tp_addr = 0;
+
 		if (srng_config->mac_type == ATH12K_HAL_SRNG_UMAC) {
 			if (!ab->hw_params->supports_shadow_regs) {
 				srng->u.src_ring.hp_addr =
@@ -2273,6 +2283,10 @@ int ath12k_hal_srng_setup_idx(struct ath
 			idx = ring_id - HAL_SRNG_RING_ID_DMAC_CMN_ID_START;
 			srng->u.src_ring.hp_addr = (void *)(hal->wrp.vaddr +
 						   idx);
+
+			if (srng->u.src_ring.hp_addr)
+				*srng->u.src_ring.hp_addr = 0;
+
 			srng->flags |= HAL_SRNG_FLAGS_LMAC_RING;
 		}
 	} else {
@@ -2288,6 +2302,10 @@ int ath12k_hal_srng_setup_idx(struct ath
 		srng->u.dst_ring.tp = 0;
 		srng->u.dst_ring.cached_hp = 0;
 		srng->u.dst_ring.hp_addr = (void *)(hal->rdp.vaddr + ring_id);
+
+		if (srng->u.dst_ring.hp_addr)
+			*srng->u.dst_ring.hp_addr = 0;
+
 		if (srng_config->mac_type == ATH12K_HAL_SRNG_UMAC) {
 			if (!ab->hw_params->supports_shadow_regs) {
 				srng->u.dst_ring.tp_addr =
@@ -2319,6 +2337,10 @@ int ath12k_hal_srng_setup_idx(struct ath
 			idx = ring_id - HAL_SRNG_RING_ID_DMAC_CMN_ID_START;
 			srng->u.dst_ring.tp_addr = (void *)(hal->wrp.vaddr +
 						   idx);
+
+			if (srng->u.dst_ring.tp_addr)
+				*srng->u.dst_ring.tp_addr = 0;
+
 			srng->flags |= HAL_SRNG_FLAGS_LMAC_RING;
 		}
 	}
--- a/drivers/net/wireless/ath/ath12k/debugfs_htt_stats.h
+++ b/drivers/net/wireless/ath/ath12k/debugfs_htt_stats.h
@@ -193,6 +193,7 @@ enum htt_tlv_tag_t {
 	HTT_STATS_PDEV_MBSSID_CTRL_FRAME_STATS_TAG	    = 176,
 	HTT_STATS_TX_PDEV_MLO_ABORT_TAG			    = 177,
 	HTT_STATS_TX_PDEV_MLO_TXOP_ABORT_TAG		    = 178,
+	HTT_STATS_UMAC_SSR_TAG				    = 179,
 	HTT_STATS_MAX_TAG,
 };
 
@@ -4235,4 +4236,30 @@ struct htt_pdev_sched_algo_ofdma_stats_t
 	u32 dlofdma_disabled_consec_no_mpdus_success[HTT_NUM_AC_WMM];
 };
 
+struct htt_umac_ssr_stats_tlv {
+	u32 total_done;
+	u32 trigger_requests_count;
+	u32 total_trig_dropped;
+	u32 umac_disengaged_count;
+	u32 umac_soft_reset_count;
+	u32 umac_engaged_count;
+	u32 last_trigger_request_ms;
+	u32 last_start_ms;
+	u32 last_start_disengage_umac_ms;
+	u32 last_enter_ssr_platform_thread_ms;
+	u32 last_exit_ssr_platform_thread_ms;
+	u32 last_start_engage_umac_ms;
+	u32 last_done_successful_ms;
+	u32 last_e2e_delta_ms;
+	u32 max_e2e_delta_ms;
+	u32 trigger_count_for_umac_hang;
+	u32 trigger_count_for_mlo_quick_ssr;
+	u32 trigger_count_for_unknown_signature;
+	u32 post_reset_tqm_sync_cmd_completion_ms;
+	u32 htt_sync_mlo_initiate_umac_recovery_ms;
+	u32 htt_sync_do_pre_reset_ms;
+	u32 htt_sync_do_post_reset_start_ms;
+	u32 htt_sync_do_post_reset_complete_ms;
+};
+
 #endif
--- a/drivers/net/wireless/ath/ath12k/debugfs.h
+++ b/drivers/net/wireless/ath/ath12k/debugfs.h
@@ -74,6 +74,7 @@ enum ath12k_dbg_htt_ext_stats_type {
 	ATH12K_DBG_HTT_DBG_EXT_PHY_PROF_CAL_STATS	    =  52,
 	ATH12K_DGB_HTT_DBG_EXT_STATS_PDEV_BW_MGR	    =  53,
 	ATH12K_DGB_HTT_DBG_PDEV_MBSSID_CTRL_FRAME_STATS	    =  54,
+	ATH12K_DBG_HTT_UMAC_RESET_SSR_STATS		    =  55,
 	/* keep this last */
 	ATH12K_DBG_HTT_NUM_EXT_STATS,
 };
--- a/drivers/net/wireless/ath/ath12k/debugfs_htt_stats.c
+++ b/drivers/net/wireless/ath/ath12k/debugfs_htt_stats.c
@@ -8145,6 +8145,68 @@ static inline void htt_print_histogram_s
 	stats_req->buf_len = len;
 }
 
+static void htt_print_umac_ssr_stats_tlv(const void *tag_buf,
+					 struct debug_htt_stats_req *stats_req)
+{
+	const struct htt_umac_ssr_stats_tlv *htt_stats_buf = tag_buf;
+	u32 buf_len = ATH12K_HTT_STATS_BUF_SIZE;
+	u32 len = stats_req->buf_len;
+	u8 *buf = stats_req->buf;
+
+	len += scnprintf(buf + len, buf_len - len, "HTT_UMAC_SSR_STATS_TLV:\n");
+	len += scnprintf(buf + len, buf_len - len, "total_done = %u\n",
+			 htt_stats_buf->total_done);
+	len += scnprintf(buf + len, buf_len - len, "trigger_requests_count = %u\n",
+			 htt_stats_buf->trigger_requests_count);
+	len += scnprintf(buf + len, buf_len - len, "total_trig_dropped = %u\n",
+			 htt_stats_buf->total_trig_dropped);
+	len += scnprintf(buf + len, buf_len - len, "umac_disengaged_count = %u\n",
+			 htt_stats_buf->umac_disengaged_count);
+	len += scnprintf(buf + len, buf_len - len, "umac_soft_reset_count = %u\n",
+			 htt_stats_buf->umac_soft_reset_count);
+	len += scnprintf(buf + len, buf_len - len, "umac_engaged_count = %u\n",
+			 htt_stats_buf->umac_engaged_count);
+	len += scnprintf(buf + len, buf_len - len, "last_trigger_request_ms = %u\n",
+			 htt_stats_buf->last_trigger_request_ms);
+	len += scnprintf(buf + len, buf_len - len, "last_start_ms = %u\n",
+			 htt_stats_buf->last_start_ms);
+	len += scnprintf(buf + len, buf_len - len, "last_start_disengage_umac_ms = %u\n",
+			 htt_stats_buf->last_start_disengage_umac_ms);
+	len += scnprintf(buf + len, buf_len - len, "last_enter_ssr_platform_thread_ms = %u\n",
+			 htt_stats_buf->last_enter_ssr_platform_thread_ms);
+	len += scnprintf(buf + len, buf_len - len, "last_exit_ssr_platform_thread_ms = %u\n",
+			 htt_stats_buf->last_exit_ssr_platform_thread_ms);
+	len += scnprintf(buf + len, buf_len - len, "last_start_engage_umac_ms = %u\n",
+			 htt_stats_buf->last_start_engage_umac_ms);
+	len += scnprintf(buf + len, buf_len - len, "post_reset_tqm_sync_cmd_completion_ms = %u\n",
+			 htt_stats_buf->post_reset_tqm_sync_cmd_completion_ms);
+	len += scnprintf(buf + len, buf_len - len, "last_done_successful_ms = %u\n",
+			 htt_stats_buf->last_done_successful_ms);
+	len += scnprintf(buf + len, buf_len - len, "last_e2e_delta_ms = %u\n",
+			 htt_stats_buf->last_e2e_delta_ms);
+	len += scnprintf(buf + len, buf_len - len, "max_e2e_delta_ms = %u\n",
+			 htt_stats_buf->max_e2e_delta_ms);
+	len += scnprintf(buf + len, buf_len - len, "trigger_count_for_umac_hang = %u\n",
+			 htt_stats_buf->trigger_count_for_umac_hang);
+	len += scnprintf(buf + len, buf_len - len, "trigger_count_for_mlo_quick_ssr = %u\n",
+			 htt_stats_buf->trigger_count_for_mlo_quick_ssr);
+	len += scnprintf(buf + len, buf_len - len, "trigger_count_for_unknown_signature = %u\n",
+			 htt_stats_buf->trigger_count_for_unknown_signature);
+	len += scnprintf(buf + len, buf_len - len, "htt_sync_mlo_initiate_umac_recovery_ms = %u\n",
+			 htt_stats_buf->htt_sync_mlo_initiate_umac_recovery_ms);
+	len += scnprintf(buf + len, buf_len - len, "htt_sync_do_pre_reset_ms = %u\n",
+			 htt_stats_buf->htt_sync_do_pre_reset_ms);
+	len += scnprintf(buf + len, buf_len - len, "htt_sync_do_post_reset_start_ms = %u\n",
+			 htt_stats_buf->htt_sync_do_post_reset_start_ms);
+	len += scnprintf(buf + len, buf_len - len, "htt_sync_do_post_reset_complete_ms = %u\n",
+			 htt_stats_buf->htt_sync_do_post_reset_complete_ms);
+
+	len += scnprintf(buf + len, buf_len - len,
+			 "=================================================\n");
+
+	stats_req->buf_len = len;
+}
+
 static int ath12k_dbg_htt_ext_stats_parse(struct ath12k_base *ab,
 					  u16 tag, u16 len, const void *tag_buf,
 					  void *user_data)
@@ -8775,6 +8837,10 @@ static int ath12k_dbg_htt_ext_stats_pars
 		break;
 	case HTT_STATS_TX_PDEV_SAWF_RATE_STATS_TAG:
 		htt_print_histogram_stats_tlv(tag_buf, stats_req);
+		break;
+	case HTT_STATS_UMAC_SSR_TAG:
+		htt_print_umac_ssr_stats_tlv(tag_buf, stats_req);
+		break;
 	default:
 		break;
 	}
