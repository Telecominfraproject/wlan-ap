From a6e92e6fa3bbfedf264e5304c01660a9863ad0a3 Mon Sep 17 00:00:00 2001
From: Avula Sri Charan <quic_asrichar@quicinc.com>
Date: Thu, 18 May 2023 16:43:58 +0530
Subject: [Patch] wifi: ath12k: Add peer rhash table support

When more clients (128) are connected, the UL data traffic
KPI measurement is low compared to single client. This issue
is due to more CPU cycles spent on the peer lookup operation
with more clients. So reduce the peer lookup operation by
modifying the linear based lookup operation into the rhash
based lookup operation.

Cherry-picked from : https://patchwork.kernel.org/project/linux-wireless/patch/20220603164559.27769-1-ansuelsmth@gmail.com/
Cherry-picked from : https://patchwork.kernel.org/project/linux-wireless/patch/20230209222622.1751-1-ansuelsmth@gmail.com/

Signed-off-by: Christian Marangi <ansuelsmth@gmail.com>
Signed-off-by: Avula Sri Charan <quic_asrichar@quicinc.com>
---
 drivers/net/wireless/ath/ath12k/core.c |   1 +
 drivers/net/wireless/ath/ath12k/core.h |  13 +
 drivers/net/wireless/ath/ath12k/mac.c  |  10 +
 drivers/net/wireless/ath/ath12k/peer.c | 407 ++++++++++++++++++++++---
 drivers/net/wireless/ath/ath12k/peer.h |  10 +
 5 files changed, 392 insertions(+), 49 deletions(-)

--- a/drivers/net/wireless/ath/ath12k/core.c
+++ b/drivers/net/wireless/ath/ath12k/core.c
@@ -2503,6 +2503,7 @@ struct ath12k_base *ath12k_core_alloc(st
 		goto err_free_wq;
 
 	mutex_init(&ab->core_lock);
+	mutex_init(&ab->tbl_mtx_lock);
 	spin_lock_init(&ab->base_lock);
 	init_completion(&ab->reset_complete);
 
--- a/drivers/net/wireless/ath/ath12k/core.h
+++ b/drivers/net/wireless/ath/ath12k/core.h
@@ -12,6 +12,7 @@
 #include <linux/irq.h>
 #include <linux/bitfield.h>
 #include <linux/average.h>
+#include <linux/rhashtable.h>
 #include "qmi.h"
 #include "htc.h"
 #include "wmi.h"
@@ -1256,6 +1257,18 @@ struct ath12k_base {
 	struct ath12k_wmi_hal_reg_capabilities_ext_arg hal_reg_cap[MAX_RADIOS];
 	unsigned long long free_vdev_map;
 	unsigned long long free_vdev_stats_id_map;
+
+	/* To synchronize rhash tbl write operation */
+	struct mutex tbl_mtx_lock;
+
+	/* The rhashtable containing struct ath12k_peer keyed by mac addr */
+	struct rhashtable *rhead_peer_addr;
+	struct rhashtable_params rhash_peer_addr_param;
+
+	/* The rhashtable containing struct ath12k_peer keyed by id  */
+	struct rhashtable *rhead_peer_id;
+	struct rhashtable_params rhash_peer_id_param;
+
 	struct list_head peers;
 	wait_queue_head_t peer_mapping_wq;
 	u8 mac_addr[ETH_ALEN];
--- a/drivers/net/wireless/ath/ath12k/mac.c
+++ b/drivers/net/wireless/ath/ath12k/mac.c
@@ -1169,13 +1169,16 @@ void ath12k_mac_peer_cleanup_all(struct
 
 	lockdep_assert_held(&ar->conf_mutex);
 
+	mutex_lock(&ab->tbl_mtx_lock);
 	spin_lock_bh(&ab->base_lock);
 	list_for_each_entry_safe(peer, tmp, &ab->peers, list) {
 		ath12k_dp_rx_peer_tid_cleanup(ar, peer);
+		ath12k_peer_rhash_delete(ab, peer);
 		list_del(&peer->list);
 		kfree(peer);
 	}
 	spin_unlock_bh(&ab->base_lock);
+	mutex_unlock(&ab->tbl_mtx_lock);
 
 	if (!list_empty(&ab->neighbor_peers))
 		ath12k_debugfs_nrp_cleanup_all(ar);
@@ -6812,17 +6815,20 @@ static void ath12k_mac_station_post_remo
 
 	ath12k_mac_dec_num_stations(arvif, arsta);
 
+	mutex_lock(&ar->ab->tbl_mtx_lock);
 	spin_lock_bh(&ar->ab->base_lock);
 	peer = ath12k_peer_find(ar->ab, arvif->vdev_id, arsta->addr);
 	if (peer && peer->sta == sta) {
 		ath12k_warn(ar->ab, "Found peer entry %pM n vdev %i after it was supposedly removed\n",
 			    arsta->addr, arvif->vdev_id);
+		ath12k_peer_rhash_delete(ar->ab, peer);
 		peer->sta = NULL;
 		list_del(&peer->list);
 		kfree(peer);
 		ar->num_peers--;
 	}
 	spin_unlock_bh(&ar->ab->base_lock);
+	mutex_unlock(&ar->ab->tbl_mtx_lock);
 
 	kfree(arsta->tx_stats);
 	arsta->tx_stats = NULL;
@@ -16023,6 +16029,9 @@ int ath12k_mac_allocate(struct ath12k_hw
 				spin_lock_bh(&ab->base_lock);
 				ab->free_vdev_map = (1LL << (ab->num_radios * TARGET_NUM_VDEVS)) - 1;
 				spin_unlock_bh(&ab->base_lock);
+				ret = ath12k_peer_rhash_tbl_init(ab);
+				if (ret)
+					goto err_mac_destroy;
 
 				ath12k_dp_pdev_pre_alloc(ab);
 			}
@@ -16071,6 +16080,7 @@ void ath12k_mac_destroy(struct ath12k_hw
 
 			pdev->ar = NULL;
 		}
+		ath12k_peer_rhash_tbl_destroy(ab);
 	}
 
 	for (i = 0; i < ag->num_hw; i++) {
--- a/drivers/net/wireless/ath/ath12k/peer.c
+++ b/drivers/net/wireless/ath/ath12k/peer.c
@@ -66,18 +66,15 @@ static struct ath12k_peer *ath12k_peer_f
 struct ath12k_peer *ath12k_peer_find_by_addr(struct ath12k_base *ab,
 					     const u8 *addr)
 {
-	struct ath12k_peer *peer;
 
 	lockdep_assert_held(&ab->base_lock);
 
-	list_for_each_entry(peer, &ab->peers, list) {
-		if (!ether_addr_equal(peer->addr, addr))
-			continue;
+	if (!ab->rhead_peer_addr)
+		return NULL;
 
-		return peer;
-	}
+	return rhashtable_lookup_fast(ab->rhead_peer_addr, addr,
+				      ab->rhash_peer_addr_param);
 
-	return NULL;
 }
 
 static struct ath12k_peer *ath12k_peer_find_by_ml_id(struct ath12k_base *ab,
@@ -94,21 +91,39 @@ static struct ath12k_peer *ath12k_peer_f
 	return NULL;
 }
 
-struct ath12k_peer *ath12k_peer_find_by_id(struct ath12k_base *ab,
-					   int peer_id)
+struct ath12k_peer *ath12k_peer_find_list_by_id(struct ath12k_base *ab,
+						int peer_id)
 {
 	struct ath12k_peer *peer;
 
 	lockdep_assert_held(&ab->base_lock);
 
-	if (peer_id & ATH12K_ML_PEER_ID_VALID)
+	if (peer_id & ATH12K_ML_PEER_ID_VALID) {
 		return ath12k_peer_find_by_ml_id(ab, peer_id);
+	} else {
+		list_for_each_entry(peer, &ab->peers, list) {
+			if (peer->peer_id == peer_id)
+				return peer;
+			}
 
-	list_for_each_entry(peer, &ab->peers, list)
-		if (peer_id == peer->peer_id)
-			return peer;
+		return NULL;
+	}
+}
 
-	return NULL;
+struct ath12k_peer *ath12k_peer_find_by_id(struct ath12k_base *ab,
+					    int peer_id)
+{
+	lockdep_assert_held(&ab->base_lock);
+
+	if (peer_id & ATH12K_ML_PEER_ID_VALID) {
+		return ath12k_peer_find_by_ml_id(ab, peer_id);
+	} else {
+		if (!ab->rhead_peer_id)
+			return NULL;
+
+		return rhashtable_lookup_fast(ab->rhead_peer_id, &peer_id,
+		  			      ab->rhash_peer_id_param);
+	}
 }
 
 bool ath12k_peer_exist_by_vdev_id(struct ath12k_base *ab, int vdev_id)
@@ -133,7 +148,7 @@ void ath12k_peer_unmap_event(struct ath1
 
 	spin_lock_bh(&ab->base_lock);
 
-	peer = ath12k_peer_find_by_id(ab, peer_id);
+	peer = ath12k_peer_find_list_by_id(ab, peer_id);
 	if (!peer) {
 		ath12k_warn(ab, "peer-unmap-event: unknown peer id %d\n",
 			    peer_id);
@@ -194,7 +209,7 @@ void ath12k_peer_mlo_map_event(struct at
 	ml_peer_id |= ATH12K_ML_PEER_ID_VALID;
 
 	spin_lock_bh(&ab->base_lock);
-	peer = ath12k_peer_find_by_id(ab, ml_peer_id);
+	peer = ath12k_peer_find_list_by_id(ab, ml_peer_id);
 
 	/* TODO a sync wait to check ml peer map success or delete
 	 * ml peer info in all link peers and make peer assoc failure
@@ -255,6 +270,80 @@ static int ath12k_wait_for_peer_common(s
 	return 0;
 }
 
+static inline int ath12k_peer_rhash_insert(struct ath12k_base *ab,
+                                           struct rhashtable *rtbl,
+                                           struct rhash_head *rhead,
+                                           struct rhashtable_params *params,
+                                           void *key)
+{
+        struct ath12k_peer *tmp;
+
+        lockdep_assert_held(&ab->tbl_mtx_lock);
+
+        tmp = rhashtable_lookup_get_insert_fast(rtbl, rhead, *params);
+
+        if (!tmp)
+                return 0;
+        else if (IS_ERR(tmp))
+                return PTR_ERR(tmp);
+        else
+                return -EEXIST;
+}
+static inline int ath12k_peer_rhash_remove(struct ath12k_base *ab,
+                                           struct rhashtable *rtbl,
+                                           struct rhash_head *rhead,
+                                           struct rhashtable_params *params)
+{
+	int ret;
+
+	lockdep_assert_held(&ab->tbl_mtx_lock);
+
+	ret = rhashtable_remove_fast(rtbl, rhead, *params);
+	if (ret && ret != -ENOENT)
+		return ret;
+
+	return 0;
+}
+
+static int ath12k_peer_rhash_add(struct ath12k_base *ab, struct ath12k_peer *peer)
+{
+	int ret;
+
+	lockdep_assert_held(&ab->base_lock);
+	lockdep_assert_held(&ab->tbl_mtx_lock);
+
+	if (!ab->rhead_peer_id || !ab->rhead_peer_addr)
+		return -EPERM;
+
+	if (peer->rhash_done)
+		return 0;
+
+	ret = ath12k_peer_rhash_insert(ab, ab->rhead_peer_id, &peer->rhash_id,
+                                       &ab->rhash_peer_id_param, &peer->peer_id);
+	if (ret) {
+                ath12k_warn(ab, "failed to add peer %pM with id %d in rhash_id ret %d\n",
+                            peer->addr, peer->peer_id, ret);
+                return ret;
+        }
+
+        ret = ath12k_peer_rhash_insert(ab, ab->rhead_peer_addr, &peer->rhash_addr,
+                                       &ab->rhash_peer_addr_param, &peer->addr);
+        if (ret) {
+                ath12k_warn(ab, "failed to add peer %pM with id %d in rhash_addr ret %d\n",
+                            peer->addr, peer->peer_id, ret);
+                goto err_clean;
+        }
+
+	peer->rhash_done = true;
+        return 0;
+
+err_clean:
+        ath12k_peer_rhash_remove(ab, ab->rhead_peer_id, &peer->rhash_id,
+                                 &ab->rhash_peer_id_param);
+	return ret;
+}
+
+
 void ath12k_peer_cleanup(struct ath12k *ar, u32 vdev_id)
 {
 	struct ath12k_peer *peer, *tmp;
@@ -262,6 +351,7 @@ void ath12k_peer_cleanup(struct ath12k *
 
 	lockdep_assert_held(&ar->conf_mutex);
 
+	mutex_lock(&ab->tbl_mtx_lock);
 	spin_lock_bh(&ab->base_lock);
 	list_for_each_entry_safe(peer, tmp, &ab->peers, list) {
 		if (peer->vdev_id != vdev_id)
@@ -269,13 +359,14 @@ void ath12k_peer_cleanup(struct ath12k *
 
 		ath12k_warn(ab, "removing stale peer %pM from vdev_id %d\n",
 			    peer->addr, vdev_id);
-
+		ath12k_peer_rhash_delete(ab, peer);
 		list_del(&peer->list);
 		kfree(peer);
 		ar->num_peers--;
 	}
 
 	spin_unlock_bh(&ab->base_lock);
+	mutex_unlock(&ab->tbl_mtx_lock);
 }
 
 static int ath12k_wait_for_peer_deleted(struct ath12k *ar, int vdev_id, const u8 *addr)
@@ -308,15 +399,41 @@ int ath12k_wait_for_peer_delete_done(str
 
 static int ath12k_peer_delete_send(struct ath12k *ar, u32 vdev_id, u8 *addr)
 {
+	struct ath12k_peer *peer;
+	struct ath12k_base *ab = ar->ab;
 	int ret;
 
 	lockdep_assert_held(&ar->conf_mutex);
 
+	mutex_lock(&ab->tbl_mtx_lock);
+	spin_lock_bh(&ab->base_lock);
+
+	peer = ath12k_peer_find_by_addr(ab, addr);
+	if (peer && peer->vdev_id == vdev_id)
+		ath12k_peer_rhash_delete(ab, peer);
+
+	if (!peer)
+		peer = ath12k_peer_find(ab, vdev_id, addr);
+
+	if (!peer) {
+		spin_unlock_bh(&ab->base_lock);
+		mutex_unlock(&ab->tbl_mtx_lock);
+
+		ath12k_warn(ab,
+			    "failed to find peer vdev_id %d addr %pM in delete\n",
+			    vdev_id, addr);
+			return -EINVAL;
+	}
+
+	spin_unlock_bh(&ab->base_lock);
+	mutex_unlock(&ab->tbl_mtx_lock);
+
+
 	reinit_completion(&ar->peer_delete_done);
 
 	ret = ath12k_wmi_send_peer_delete_cmd(ar, addr, vdev_id);
 	if (ret) {
-		ath12k_warn(ar->ab,
+		ath12k_warn(ab,
 			    "failed to delete peer vdev_id %d addr %pM ret %d\n",
 			    vdev_id, addr, ret);
 		return ret;
@@ -453,7 +570,7 @@ int ath12k_peer_create(struct ath12k *ar
 	u8 link_id = arvif->link_id;
 	struct ieee80211_vif *vif = arvif->ahvif->vif;
 	struct ath12k_ml_peer *ml_peer;
-	int ret;
+	int ret, fbret;
 
 	lockdep_assert_held(&ar->conf_mutex);
 
@@ -481,13 +598,28 @@ int ath12k_peer_create(struct ath12k *ar
 		spin_unlock_bh(&ar->ah->data_lock);
 	}
 
+	mutex_lock(&ar->ab->tbl_mtx_lock);
 	spin_lock_bh(&ar->ab->base_lock);
-	peer = ath12k_peer_find_by_pdev_idx(ar->ab, ar->pdev_idx, arg->peer_addr);
+ 	peer = ath12k_peer_find_by_pdev_idx(ar->ab, ar->pdev_idx, arg->peer_addr);
 	if (peer) {
+		ath12k_warn(ar->ab, "Peer %pM already found in pdev_idx %d vdev %d\n",
+			    arg->peer_addr, ar->pdev_idx, peer->vdev_id);
 		spin_unlock_bh(&ar->ab->base_lock);
+		mutex_unlock(&ar->ab->tbl_mtx_lock);
 		return -EINVAL;
 	}
+
+	/* In case of Split PHY and roaming scenario, pdev idx
+	 * might differ but both the pdev will share same rhash
+	 * table. In that case update the rhash table if peer is
+	 * already present
+	 */
+	peer = ath12k_peer_find_by_addr(ar->ab, arg->peer_addr);
+	if (peer)
+		ath12k_peer_rhash_delete(ar->ab, peer);
+
 	spin_unlock_bh(&ar->ab->base_lock);
+	mutex_unlock(&ar->ab->tbl_mtx_lock);
 
 	ret = ath12k_wmi_send_peer_create_cmd(ar, arg);
 	if (ret) {
@@ -502,21 +634,24 @@ int ath12k_peer_create(struct ath12k *ar
 	if (ret)
 		return ret;
 
+	mutex_lock(&ar->ab->tbl_mtx_lock);
 	spin_lock_bh(&ar->ab->base_lock);
 
 	peer = ath12k_peer_find(ar->ab, arg->vdev_id, arg->peer_addr);
 	if (!peer) {
 		spin_unlock_bh(&ar->ab->base_lock);
+		mutex_unlock(&ar->ab->tbl_mtx_lock);
 		ath12k_warn(ar->ab, "failed to find peer %pM on vdev %i after creation\n",
 			    arg->peer_addr, arg->vdev_id);
 
-		ret = __ath12k_peer_delete(ar, arg->vdev_id, arg->peer_addr);
-		if (ret)
-			ath12k_warn(ar->ab, "failed to delete peer vdev_id %d addr %pM\n",
-				    arg->vdev_id, arg->peer_addr);
-
-		return -ENOENT;
+		goto cleanup;
 	}
+	ret = ath12k_peer_rhash_add(ar->ab, peer);
+	if (ret) {
+		spin_unlock_bh(&ar->ab->base_lock);
+		mutex_unlock(&ar->ab->tbl_mtx_lock);
+		goto cleanup;
+        }
 
 	peer->pdev_idx = ar->pdev_idx;
 	peer->sta = sta;
@@ -563,8 +698,18 @@ int ath12k_peer_create(struct ath12k *ar
 	ath12k_dbg(ar->ab, ATH12K_DBG_PEER, "peer created %pM\n", arg->peer_addr);
 
 	spin_unlock_bh(&ar->ab->base_lock);
+	mutex_unlock(&ar->ab->tbl_mtx_lock);
 
 	return 0;
+
+cleanup:
+	fbret = __ath12k_peer_delete(ar, arg->vdev_id, arg->peer_addr);
+	if (fbret)
+		ath12k_warn(ar->ab, "failed peer %pM delete vdev_id %d fallback ret %d\n",
+			    arg->peer_addr, arg->vdev_id, fbret);
+
+	return ret;
+
 }
 
 static u16 ath12k_mac_alloc_ml_peer_id(struct ath12k_hw *ah)
@@ -664,3 +809,204 @@ int ath12k_ml_peer_delete(struct ath12k_
 		   sta->addr);
 	return 0;
 }
+int ath12k_peer_rhash_delete(struct ath12k_base *ab, struct ath12k_peer *peer)
+{
+		int ret;
+
+		lockdep_assert_held(&ab->base_lock);
+		lockdep_assert_held(&ab->tbl_mtx_lock);
+
+		if (!ab->rhead_peer_id || !ab->rhead_peer_addr)
+				return -EPERM;
+
+		if (!peer->rhash_done)
+                        return 0;
+
+		ret = ath12k_peer_rhash_remove(ab, ab->rhead_peer_addr, &peer->rhash_addr,
+									   &ab->rhash_peer_addr_param);
+		if (ret) {
+				ath12k_warn(ab, "failed to remove peer %pM id %d in rhash_addr ret %d\n",
+							peer->addr, peer->peer_id, ret);
+				return ret;
+		}
+
+		ret = ath12k_peer_rhash_remove(ab, ab->rhead_peer_id, &peer->rhash_id,
+									   &ab->rhash_peer_id_param);
+		if (ret) {
+				ath12k_warn(ab, "failed to remove peer %pM id %d in rhash_id ret %d\n",
+							peer->addr, peer->peer_id, ret);
+				return ret;
+		}
+
+		peer->rhash_done=false;
+
+		return 0;
+}
+
+static int ath12k_peer_rhash_id_tbl_init(struct ath12k_base *ab)
+{
+		struct rhashtable_params *param;
+		struct rhashtable *rhash_id_tbl;
+		int ret;
+		size_t size;
+
+		lockdep_assert_held(&ab->tbl_mtx_lock);
+
+		if (ab->rhead_peer_id)
+				return 0;
+
+		size = sizeof(*ab->rhead_peer_id);
+		rhash_id_tbl = kzalloc(size, GFP_KERNEL);
+		if (!rhash_id_tbl) {
+				ath12k_warn(ab, "failed to init rhash id table due to no mem (size %zu)\n",
+							size);
+				return -ENOMEM;
+		}
+
+		param = &ab->rhash_peer_id_param;
+
+		param->key_offset = offsetof(struct ath12k_peer, peer_id);
+		param->head_offset = offsetof(struct ath12k_peer, rhash_id);
+		param->key_len = sizeof_field(struct ath12k_peer, peer_id);
+		param->automatic_shrinking = true;
+		param->nelem_hint = ab->num_radios * TARGET_NUM_PEERS_PDEV;
+
+		ret = rhashtable_init(rhash_id_tbl, param);
+		if (ret) {
+			ath12k_warn(ab, "failed to init peer id rhash table %d\n", ret);
+			goto err_free;
+		}
+
+		spin_lock_bh(&ab->base_lock);
+
+		if (!ab->rhead_peer_id) {
+				ab->rhead_peer_id = rhash_id_tbl;
+		} else {
+				spin_unlock_bh(&ab->base_lock);
+				goto cleanup_tbl;
+		}
+
+		spin_unlock_bh(&ab->base_lock);
+
+		return 0;
+
+cleanup_tbl:
+		rhashtable_destroy(rhash_id_tbl);
+err_free:
+		kfree(rhash_id_tbl);
+
+		return ret;
+}
+
+static int ath12k_peer_rhash_addr_tbl_init(struct ath12k_base *ab)
+{
+		struct rhashtable_params *param;
+		struct rhashtable *rhash_addr_tbl;
+		int ret;
+		size_t size;
+
+		lockdep_assert_held(&ab->tbl_mtx_lock);
+
+		if (ab->rhead_peer_addr)
+				return 0;
+
+		size = sizeof(*ab->rhead_peer_addr);
+		rhash_addr_tbl = kzalloc(size, GFP_KERNEL);
+		if (!rhash_addr_tbl) {
+				ath12k_warn(ab, "failed to init rhash addr table due to no mem (size %zu)\n",
+							size);
+				return -ENOMEM;
+		}
+		param = &ab->rhash_peer_addr_param;
+
+		param->key_offset = offsetof(struct ath12k_peer, addr);
+		param->head_offset = offsetof(struct ath12k_peer, rhash_addr);
+		param->key_len = sizeof_field(struct ath12k_peer, addr);
+		param->automatic_shrinking = true;
+		param->nelem_hint = ab->num_radios * TARGET_NUM_PEERS_PDEV;
+
+		ret = rhashtable_init(rhash_addr_tbl, param);
+		if (ret) {
+				ath12k_warn(ab, "failed to init peer addr rhash table %d\n", ret);
+				goto err_free;
+		}
+
+		spin_lock_bh(&ab->base_lock);
+
+		if (!ab->rhead_peer_addr) {
+				ab->rhead_peer_addr = rhash_addr_tbl;
+		} else {
+				spin_unlock_bh(&ab->base_lock);
+				goto cleanup_tbl;
+		}
+
+		spin_unlock_bh(&ab->base_lock);
+
+		return 0;
+
+cleanup_tbl:
+		rhashtable_destroy(rhash_addr_tbl);
+err_free:
+		kfree(rhash_addr_tbl);
+
+		return ret;
+}
+
+static inline void ath12k_peer_rhash_id_tbl_destroy(struct ath12k_base *ab)
+{
+		lockdep_assert_held(&ab->tbl_mtx_lock);
+
+		if (!ab->rhead_peer_id)
+				return;
+
+		rhashtable_destroy(ab->rhead_peer_id);
+		kfree(ab->rhead_peer_id);
+		ab->rhead_peer_id = NULL;
+}
+
+static inline void ath12k_peer_rhash_addr_tbl_destroy(struct ath12k_base *ab)
+{
+		lockdep_assert_held(&ab->tbl_mtx_lock);
+
+		if (!ab->rhead_peer_addr)
+				return;
+
+		rhashtable_destroy(ab->rhead_peer_addr);
+		kfree(ab->rhead_peer_addr);
+		ab->rhead_peer_addr = NULL;
+}
+
+int ath12k_peer_rhash_tbl_init(struct ath12k_base *ab)
+{
+		int ret;
+
+		mutex_lock(&ab->tbl_mtx_lock);
+
+		ret = ath12k_peer_rhash_id_tbl_init(ab);
+		if (ret)
+			goto out;
+
+		ret = ath12k_peer_rhash_addr_tbl_init(ab);
+		if (ret)
+				goto cleanup_tbl;
+
+		mutex_unlock(&ab->tbl_mtx_lock);
+
+		return 0;
+
+cleanup_tbl:
+		ath12k_peer_rhash_id_tbl_destroy(ab);
+out:
+		mutex_unlock(&ab->tbl_mtx_lock);
+		return ret;
+}
+void ath12k_peer_rhash_tbl_destroy(struct ath12k_base *ab)
+{
+		mutex_lock(&ab->tbl_mtx_lock);
+
+		ath12k_peer_rhash_addr_tbl_destroy(ab);
+		ath12k_peer_rhash_id_tbl_destroy(ab);
+
+		mutex_unlock(&ab->tbl_mtx_lock);
+}
+
--- a/drivers/net/wireless/ath/ath12k/peer.h
+++ b/drivers/net/wireless/ath/ath12k/peer.h
@@ -44,6 +44,11 @@ struct ath12k_peer {
 	 */
 	struct ath12k_dp_rx_tid rx_tid[IEEE80211_NUM_TIDS + 1];
 
+	/* peer id based rhashtable list pointer */
+	struct rhash_head rhash_id;
+	/* peer addr based rhashtable list pointer */
+	struct rhash_head rhash_addr;
+
 	/* Info used in MMIC verification of
 	 * RX fragments
 	 */
@@ -70,6 +75,9 @@ struct ath12k_peer {
 	/* To ensure only certain work related to dp is done once */
 	bool primary_link;
 
+	/* To check if the peer entry is part of rhash table or not */
+	bool rhash_done;
+
 	/* any other ML info common for all partners can be added
 	 * here and would be same for all partner peers
 	 */
@@ -87,6 +95,8 @@ void ath12k_peer_map_event(struct ath12k
 			   u8 *mac_addr, u16 ast_hash, u16 hw_peer_id);
 struct ath12k_peer *ath12k_peer_find(struct ath12k_base *ab, int vdev_id,
 				     const u8 *addr);
+struct ath12k_peer *ath12k_peer_find_list_by_id(struct ath12k_base *ab,
+						int peer_id);
 struct ath12k_peer *ath12k_peer_find_by_addr(struct ath12k_base *ab,
 					     const u8 *addr);
 struct ath12k_peer *ath12k_peer_find_by_id(struct ath12k_base *ab, int peer_id);
@@ -101,6 +111,9 @@ int ath12k_peer_create(struct ath12k *ar
 int ath12k_wait_for_peer_delete_done(struct ath12k *ar, u32 vdev_id,
 				     const u8 *addr);
 bool ath12k_peer_exist_by_vdev_id(struct ath12k_base *ab, int vdev_id);
+int ath12k_peer_rhash_tbl_init(struct ath12k_base *ab);
+void ath12k_peer_rhash_tbl_destroy(struct ath12k_base *ab);
+int ath12k_peer_rhash_delete(struct ath12k_base *ab, struct ath12k_peer *peer);
 void ath12k_peer_mlo_map_event(struct ath12k_base *ab, struct sk_buff *skb);
 void ath12k_peer_mlo_unmap_event(struct ath12k_base *ab, struct sk_buff *skb);
 static inline
